{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f69dfd-eb80-4504-8950-8247e590a908",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tools.models import *\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "from argparse import ArgumentParser\n",
    "from tools.plot_utils import show_images, show_forward, generate_new_images\n",
    "from tools.models import Autoencoder\n",
    "from torch.utils.data import Subset\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import tools.sr3 as sr3\n",
    "# from misc.print_diffuse_feats import print_feats\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e506a285113f099a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88bde32-5606-4b1f-935f-2e2761b142d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:33:55.942953Z",
     "start_time": "2024-03-18T16:33:55.921349Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"ddpm-RS-CDHead-LEVIR\",\n",
    "    \"phase\": \"test\", \n",
    "    \"gpu_ids\": [\n",
    "        0\n",
    "    ],\n",
    "     \"path\": {\n",
    "        \"resume_state\": \"./history/pretrained_sr3/sr3_50_100\"\n",
    "    },\n",
    "\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 8,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"val\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"test\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": False,\n",
    "            \"data_len\": -1 \n",
    "        }\n",
    "    },\n",
    "    \"model_cd\": {\n",
    "        \"feat_scales\": [2, 5, 8, 11, 14],\n",
    "        \"out_channels\": 2,\n",
    "        \"loss_type\": \"ce\",\n",
    "        \"output_cm_size\": 256,\n",
    "        \"feat_type\": \"dec\", \n",
    "        \"t\": [50, 100]\n",
    "    },\n",
    "\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\", \n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 3,\n",
    "            \"inner_channel\": 128,\n",
    "            \"channel_multiplier\": [\n",
    "                1,\n",
    "                2,\n",
    "                4,\n",
    "                8,\n",
    "                8\n",
    "            ],\n",
    "            \"attn_res\": [\n",
    "                16\n",
    "            ],\n",
    "            \"res_blocks\": 2,\n",
    "            \"dropout\": 0.2\n",
    "        },\n",
    "        \"beta_schedule\": { \n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"val\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 256,\n",
    "            \"channels\": 3, \n",
    "            \"loss\": \"l2\", \n",
    "            \"conditional\": False \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e31a885-d47a-461e-b1df-511530aa3272",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:00.598239Z",
     "start_time": "2024-03-18T16:34:00.549409Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Resize256' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m input_channel \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m      6\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m----> 7\u001B[0m resize \u001B[38;5;241m=\u001B[39m \u001B[43mResize256\u001B[49m\n\u001B[1;32m      9\u001B[0m data_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom_n_pins_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m transformed_dataset \u001B[38;5;241m=\u001B[39m PinDataset(csv_file\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/processed/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/pins.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m                              root_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/processed/images/\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m                              transform\u001B[38;5;241m=\u001B[39mCompose([ToTensor(), resize(), Lambda()]))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Resize256' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset = \"Building\"\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "batch_size = 16\n",
    "input_channel = 3\n",
    "n = 10\n",
    "resize = Resize256\n",
    "\n",
    "data_folder = f\"random_n_pins_{n}\"\n",
    "transformed_dataset = PinDataset(csv_file=f\"./data/{dataset}/processed/{data_folder}/pins.csv\",\n",
    "                             root_dir=f\"./data/{dataset}/processed/images/\",\n",
    "                             transform=Compose([ToTensor(), resize(), Lambda()]))\n",
    "            \n",
    "data_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# if os.path.exists(f\"./data/{dataset}/train_indices.npy\"):\n",
    "#     train_indices = np.load(f'./data/{dataset}/train_indices.npy')\n",
    "#     val_indices = np.load(f'./data/{dataset}/val_indices.npy')\n",
    "#     test_indices = np.load(f'./data/{dataset}/test_indices.npy')\n",
    "#     train_indices = np.concatenate((train_indices, np.arange(1000, 1697))) # add all un-used images for DDPM training\n",
    "#     # Use the indices to create new datasets\n",
    "#     train_dataset = Subset(transformed_dataset, train_indices)\n",
    "#     val_dataset = Subset(transformed_dataset, val_indices)\n",
    "#     test_dataset = Subset(transformed_dataset, test_indices)\n",
    "# else:\n",
    "#     # Split the dataset into train, validation, and test sets\n",
    "#     train_dataset, val_dataset, test_dataset = random_split(\n",
    "#         transformed_dataset, [train_size, val_size, test_size]\n",
    "#     )\n",
    "#     np.save(f'./data/{dataset}/train_indices.npy', train_dataset.indices)\n",
    "#     np.save(f'./data/{dataset}/val_indices.npy', val_dataset.indices)\n",
    "#     np.save(f'./data/{dataset}/test_indices.npy', test_dataset.indices)\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f420b7-ce1b-4a94-83ba-b3148fb9c789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:02.254775Z",
     "start_time": "2024-03-18T16:34:02.244764Z"
    }
   },
   "outputs": [],
   "source": [
    "def concat_feature_maps(feature_maps, layers=[5, 6, 7, 8]):\n",
    "    # Define empty list to store upsampled feature maps for specific layers\n",
    "    upsampled_maps = []\n",
    "    \n",
    "    # Upsample and store feature maps for specified layers\n",
    "    for t in range(len(f_A)):\n",
    "        for layer_idx in layers:\n",
    "            fmap = feature_maps[t][layer_idx]\n",
    "            upsampled_fmap = torch.nn.functional.interpolate(fmap, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "            upsampled_maps.append(upsampled_fmap)\n",
    "    \n",
    "    # Concatenate the upsampled feature maps along the channel dimension\n",
    "    concatenated_maps = torch.cat(upsampled_maps, dim=1)\n",
    "    \n",
    "    return concatenated_maps\n",
    "\n",
    "def save_fm_by_batch(opt, data_loader, images_directory, output_directory):\n",
    "    f_A = []\n",
    "    opt = sr3.dict_to_nonedict(opt)\n",
    "    # Loading diffusion model\n",
    "    diffusion = sr3.DDPM(opt)\n",
    "    # Set noise schedule for the diffusion model\n",
    "    diffusion.set_new_noise_schedule(\n",
    "        opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])   \n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    images_directory = os.path.join(images_directory, 'images')\n",
    "\n",
    "    # Create subdirectories for images and count labels\n",
    "    os.makedirs(images_directory, exist_ok=True)\n",
    "\n",
    "    # Save images as \"0.png\" or \"0.npy\", \"1.png\" or \"1.npy\", etc., and dump data to CSV\n",
    "    with open(os.path.join(output_directory, 'pins.csv'), 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row\n",
    "        csv_writer.writerow(['image', 'pins', 'outputs'])\n",
    "\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "            pins = batch['pins']\n",
    "            outputs = batch['outputs']\n",
    "            diffusion.feed_data(train_data)   \n",
    "            for t in opt['model_cd']['t']:\n",
    "                fe_A_t, fd_A_t= diffusion.get_feats(t=t) #np.random.randint(low=2, high=8)\n",
    "                f_A.append(fd_A_t)\n",
    "            concat_fm = concat_feature_maps(f_A)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                # Calculate the overall index\n",
    "                overall_index = batch_idx * len(batch_images) + i\n",
    "\n",
    "                # Save the image as \"overall_index.png\" or \"overall_index.npy\" in the images subdirectory\n",
    "                image_filename = os.path.join(images_directory, f\"{overall_index}\")\n",
    "                # For multi-channel images, save as NPY\n",
    "                image_filename += \".npy\"\n",
    "                if not os.path.exists(image_filename):\n",
    "                    np.save(image_filename, concat_fm[i].detach().cpu().numpy())\n",
    "\n",
    "                # Write data to CSV\n",
    "                csv_writer.writerow([os.path.basename(image_filename), pins[i], outputs[i]])\n",
    "\n",
    "    print(\"Data and images have been saved to the CSV and image files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422475c8-f38e-4cee-8b53-2b168ba11954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:05.979538Z",
     "start_time": "2024-03-18T16:34:05.956502Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m save_fm_by_batch(opt, \u001B[43mdata_loader\u001B[49m, images_directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/Building_ddpm/images\u001B[39m\u001B[38;5;124m\"\u001B[39m, output_directory\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/Building_ddpm/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "save_fm_by_batch(opt, data_loader, images_directory=\"./data/Building_ddpm/images\", output_directory=f\"./data/Building_ddpm/{data_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f6309-022d-4db3-9b22-0bc481d7b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, opt['datasets']['val']['data_len']):\n",
    "    diffusion.test(in_channels=3, img_size=256, continous=True)\n",
    "    visuals = diffusion.get_current_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf741ccb-dba1-47e5-8332-7a8ace92ddd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "count = 0\n",
    "for batch in train_loader:\n",
    "    images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "    pins = batch['pins']\n",
    "    outputs = batch['outputs']\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ce792-3ad7-415c-a9c2-f30cdcea198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "best_model = DDPM(UNet(), n_steps=n_steps, device=device)\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"Model loaded\")\n",
    "\n",
    "print(\"Generating new images\")\n",
    "generated = generate_new_images(\n",
    "        best_model,\n",
    "        n_samples=100,\n",
    "        device=device,\n",
    "        gif_name=\"mnist.gif\"\n",
    "    )\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02adbd-4de1-4b59-8e03-42d94793b676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_forward(model, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1327841-1e33-49dd-9d44-00715ebdedae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visual evaluation on the test set\n",
    "\n",
    "# change for dataset\n",
    "num_kernels_encoder = [16, 8]\n",
    "num_kernels_decoder = [16]\n",
    "input_channel = 1\n",
    "\n",
    "test_dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        # Forward pass through the autoencoder\n",
    "        autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "        outputs = autoencoder(inputs)\n",
    "        \n",
    "        # Reshape the outputs to the original image shape (28x28)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28)\n",
    "        \n",
    "        # Convert Tensors to NumPy arrays for visualization\n",
    "        inputs = inputs.view(inputs.size(0), 1, 28, 28).numpy()\n",
    "        outputs = outputs.numpy()\n",
    "        \n",
    "        # Plot the input and output images\n",
    "        for i in range(inputs.shape[0]):\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title('Input Image')\n",
    "            plt.imshow(np.squeeze(inputs[i]), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title('Output Image')\n",
    "            plt.imshow(np.squeeze(outputs[i]), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "npp",
   "language": "python",
   "display_name": "Neural Point Processes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
