{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f69dfd-eb80-4504-8950-8247e590a908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T00:51:53.678041Z",
     "start_time": "2024-02-18T00:51:51.874885Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tools.models import *\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "from argparse import ArgumentParser\n",
    "from tools.plot_utils import show_images, show_forward, generate_new_images\n",
    "from tools.models import Autoencoder\n",
    "from torch.utils.data import Subset\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import tools.sr3 as sr3\n",
    "# from misc.print_diffuse_feats import print_feats\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88bde32-5606-4b1f-935f-2e2761b142d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"ddpm-RS-CDHead-LEVIR\",\n",
    "    \"phase\": \"test\", \n",
    "    \"gpu_ids\": [\n",
    "        0\n",
    "    ],\n",
    "     \"path\": {\n",
    "        \"resume_state\": \"./history/pretrained_sr3/sr3_50_100\"\n",
    "    },\n",
    "\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 8,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"val\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"test\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": False,\n",
    "            \"data_len\": -1 \n",
    "        }\n",
    "    },\n",
    "    \"model_cd\": {\n",
    "        \"feat_scales\": [2, 5, 8, 11, 14],\n",
    "        \"out_channels\": 2,\n",
    "        \"loss_type\": \"ce\",\n",
    "        \"output_cm_size\": 256,\n",
    "        \"feat_type\": \"dec\", \n",
    "        \"t\": [50, 100]\n",
    "    },\n",
    "\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\", \n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 3,\n",
    "            \"inner_channel\": 128,\n",
    "            \"channel_multiplier\": [\n",
    "                1,\n",
    "                2,\n",
    "                4,\n",
    "                8,\n",
    "                8\n",
    "            ],\n",
    "            \"attn_res\": [\n",
    "                16\n",
    "            ],\n",
    "            \"res_blocks\": 2,\n",
    "            \"dropout\": 0.2\n",
    "        },\n",
    "        \"beta_schedule\": { \n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"val\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 256,\n",
    "            \"channels\": 3, \n",
    "            \"loss\": \"l2\", \n",
    "            \"conditional\": False \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e31a885-d47a-461e-b1df-511530aa3272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dataset = \"Building\"\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "batch_size = 16\n",
    "input_channel = 3\n",
    "n = 10\n",
    "resize = Resize256\n",
    "\n",
    "data_folder = f\"random_n_pins_{n}\"\n",
    "transformed_dataset = PinDataset(csv_file=f\"./data/{dataset}/processed/{data_folder}/pins.csv\",\n",
    "                             root_dir=f\"./data/{dataset}/processed/images/\",\n",
    "                             transform=Compose([ToTensor(), resize(), Lambda()]))\n",
    "            \n",
    "data_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# if os.path.exists(f\"./data/{dataset}/train_indices.npy\"):\n",
    "#     train_indices = np.load(f'./data/{dataset}/train_indices.npy')\n",
    "#     val_indices = np.load(f'./data/{dataset}/val_indices.npy')\n",
    "#     test_indices = np.load(f'./data/{dataset}/test_indices.npy')\n",
    "#     train_indices = np.concatenate((train_indices, np.arange(1000, 1697))) # add all un-used images for DDPM training\n",
    "#     # Use the indices to create new datasets\n",
    "#     train_dataset = Subset(transformed_dataset, train_indices)\n",
    "#     val_dataset = Subset(transformed_dataset, val_indices)\n",
    "#     test_dataset = Subset(transformed_dataset, test_indices)\n",
    "# else:\n",
    "#     # Split the dataset into train, validation, and test sets\n",
    "#     train_dataset, val_dataset, test_dataset = random_split(\n",
    "#         transformed_dataset, [train_size, val_size, test_size]\n",
    "#     )\n",
    "#     np.save(f'./data/{dataset}/train_indices.npy', train_dataset.indices)\n",
    "#     np.save(f'./data/{dataset}/val_indices.npy', val_dataset.indices)\n",
    "#     np.save(f'./data/{dataset}/test_indices.npy', test_dataset.indices)\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f420b7-ce1b-4a94-83ba-b3148fb9c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_feature_maps(feature_maps, layers=[5, 6, 7, 8]):\n",
    "    # Define empty list to store upsampled feature maps for specific layers\n",
    "    upsampled_maps = []\n",
    "    \n",
    "    # Upsample and store feature maps for specified layers\n",
    "    for t in range(len(f_A)):\n",
    "        for layer_idx in layers:\n",
    "            fmap = feature_maps[t][layer_idx]\n",
    "            upsampled_fmap = torch.nn.functional.interpolate(fmap, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "            upsampled_maps.append(upsampled_fmap)\n",
    "    \n",
    "    # Concatenate the upsampled feature maps along the channel dimension\n",
    "    concatenated_maps = torch.cat(upsampled_maps, dim=1)\n",
    "    \n",
    "    return concatenated_maps\n",
    "\n",
    "def save_fm_by_batch(opt, data_loader, images_directory, output_directory):\n",
    "    f_A = []\n",
    "    opt = sr3.dict_to_nonedict(opt)\n",
    "    # Loading diffusion model\n",
    "    diffusion = sr3.DDPM(opt)\n",
    "    # Set noise schedule for the diffusion model\n",
    "    diffusion.set_new_noise_schedule(\n",
    "        opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])   \n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    images_directory = os.path.join(images_directory, 'images')\n",
    "\n",
    "    # Create subdirectories for images and count labels\n",
    "    os.makedirs(images_directory, exist_ok=True)\n",
    "\n",
    "    # Save images as \"0.png\" or \"0.npy\", \"1.png\" or \"1.npy\", etc., and dump data to CSV\n",
    "    with open(os.path.join(output_directory, 'pins.csv'), 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row\n",
    "        csv_writer.writerow(['image', 'pins', 'outputs'])\n",
    "\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "            pins = batch['pins']\n",
    "            outputs = batch['outputs']\n",
    "            diffusion.feed_data(train_data)   \n",
    "            for t in opt['model_cd']['t']:\n",
    "                fe_A_t, fd_A_t= diffusion.get_feats(t=t) #np.random.randint(low=2, high=8)\n",
    "                f_A.append(fd_A_t)\n",
    "            concat_fm = concat_feature_maps(f_A)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                # Calculate the overall index\n",
    "                overall_index = batch_idx * len(batch_images) + i\n",
    "\n",
    "                # Save the image as \"overall_index.png\" or \"overall_index.npy\" in the images subdirectory\n",
    "                image_filename = os.path.join(images_directory, f\"{overall_index}\")\n",
    "                # For multi-channel images, save as NPY\n",
    "                image_filename += \".npy\"\n",
    "                if not os.path.exists(image_filename):\n",
    "                    np.save(image_filename, concat_fm[i].detach().cpu().numpy())\n",
    "\n",
    "                # Write data to CSV\n",
    "                csv_writer.writerow([os.path.basename(image_filename), pins[i], outputs[i]])\n",
    "\n",
    "    print(\"Data and images have been saved to the CSV and image files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422475c8-f38e-4cee-8b53-2b168ba11954",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_fm_by_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/Building_ddpm/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/Building_ddpm/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36msave_fm_by_batch\u001b[0;34m(opt, data_loader, images_directory, output_directory)\u001b[0m\n\u001b[1;32m     19\u001b[0m opt \u001b[38;5;241m=\u001b[39m sr3\u001b[38;5;241m.\u001b[39mdict_to_nonedict(opt)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Loading diffusion model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m \u001b[43msr3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDDPM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Set noise schedule for the diffusion model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m diffusion\u001b[38;5;241m.\u001b[39mset_new_noise_schedule(\n\u001b[1;32m     24\u001b[0m     opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m][opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m'\u001b[39m]], schedule_phase\u001b[38;5;241m=\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase\u001b[39m\u001b[38;5;124m'\u001b[39m])   \n",
      "File \u001b[0;32m/work/DNAL/shi.cheng/NPP/Satellite_Fusion/tools/sr3.py:183\u001b[0m, in \u001b[0;36mDDPM.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28msuper\u001b[39m(DDPM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(opt)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# define network and load pretrained models\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefine_G\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedule_phase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# set loss and load resume state\u001b[39;00m\n",
      "File \u001b[0;32m/work/DNAL/shi.cheng/NPP/Satellite_Fusion/tools/sr3.py:132\u001b[0m, in \u001b[0;36mBaseModel.set_device\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m             item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "save_fm_by_batch(opt, data_loader, images_directory=\"./data/Building_ddpm/images\", output_directory=f\"./data/Building_ddpm/{data_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f6309-022d-4db3-9b22-0bc481d7b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, opt['datasets']['val']['data_len']):\n",
    "    diffusion.test(in_channels=3, img_size=256, continous=True)\n",
    "    visuals = diffusion.get_current_visuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf741ccb-dba1-47e5-8332-7a8ace92ddd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "count = 0\n",
    "for batch in train_loader:\n",
    "    images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "    pins = batch['pins']\n",
    "    outputs = batch['outputs']\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ce792-3ad7-415c-a9c2-f30cdcea198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "best_model = DDPM(UNet(), n_steps=n_steps, device=device)\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"Model loaded\")\n",
    "\n",
    "print(\"Generating new images\")\n",
    "generated = generate_new_images(\n",
    "        best_model,\n",
    "        n_samples=100,\n",
    "        device=device,\n",
    "        gif_name=\"mnist.gif\"\n",
    "    )\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02adbd-4de1-4b59-8e03-42d94793b676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_forward(model, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1327841-1e33-49dd-9d44-00715ebdedae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visual evaluation on the test set\n",
    "\n",
    "# change for dataset\n",
    "num_kernels_encoder = [16, 8]\n",
    "num_kernels_decoder = [16]\n",
    "input_channel = 1\n",
    "\n",
    "test_dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        # Forward pass through the autoencoder\n",
    "        autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "        outputs = autoencoder(inputs)\n",
    "        \n",
    "        # Reshape the outputs to the original image shape (28x28)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28)\n",
    "        \n",
    "        # Convert Tensors to NumPy arrays for visualization\n",
    "        inputs = inputs.view(inputs.size(0), 1, 28, 28).numpy()\n",
    "        outputs = outputs.numpy()\n",
    "        \n",
    "        # Plot the input and output images\n",
    "        for i in range(inputs.shape[0]):\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.title('Input Image')\n",
    "            plt.imshow(np.squeeze(inputs[i]), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.title('Output Image')\n",
    "            plt.imshow(np.squeeze(outputs[i]), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycox",
   "language": "python",
   "name": "pycox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
