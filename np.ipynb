{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd97eb1-5c1b-49cf-ab08-4f19ff72a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import json\n",
    "from tools.data_utils import *\n",
    "from tools.optimization import EarlyStoppingCallback, evaluate_model\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "from tools.NPmodels import *\n",
    "from tools.NPtrain import process_batch, NeuralProcessTrainer, evaluate_np\n",
    "from tabulate import tabulate\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9230efa-c653-44a5-a6f7-76d0ad129aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    images = [sample['image'] for sample in batch]\n",
    "    pins = [sample['pins'] for sample in batch]\n",
    "    outputs = [sample['outputs'] for sample in batch]\n",
    "\n",
    "    return {\n",
    "        'image': torch.stack(images, dim=0),\n",
    "        'pins': pins,\n",
    "        'outputs': outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ee69e7-b091-4ece-8b4e-1ded41e0062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_ci_np(train_loader, val_loader, \n",
    "                    test_loader, input_channel, epochs, val_every_epoch, config, device, num_runs=3, print_freq=2):\n",
    "    test_losses = []\n",
    "    # partial_percent = config['partial_percent']\n",
    "    experiment_id = int(time.time())\n",
    "    best_val_loss_NP = float('inf')\n",
    "    # config['experiment_id'] = experiment_id\n",
    "    experiment_id = config['experiment_id']\n",
    "\n",
    "    r_dim = np_config.r_dim\n",
    "    h_dim = np_config.h_dim\n",
    "    z_dim = np_config.z_dim\n",
    "    lr = config['best_lr']\n",
    "\n",
    "    # Create storage directory and store the experiment configuration\n",
    "    if not os.path.exists(f'./results/neural_processes/{experiment_id}'):\n",
    "        os.makedirs(f'./results/neural_processes/{experiment_id}')\n",
    "    with open(f\"./results/neural_processes/{experiment_id}/config_np.json\", \"w\") as outfile: \n",
    "        json.dump(config, outfile)\n",
    "        \n",
    "    global_val_loss = float('inf')\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        count = 0\n",
    "        GP_test_losses = []\n",
    "        \n",
    "        early_stopping = EarlyStoppingCallback(patience=5, min_delta=0.001)\n",
    "        model = NeuralProcessImg(r_dim, z_dim, h_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        np_trainer = NeuralProcessTrainer(device, model, optimizer, early_stopping, experiment_id, print_freq=print_freq)          \n",
    "\n",
    "        np_trainer.train(train_loader, val_loader, epochs)\n",
    "        if np_trainer.best_val_loss <= global_val_loss:\n",
    "            global_val_loss = np_trainer.best_val_loss \n",
    "            torch.save(np_trainer.neural_process.state_dict(), f'./results/neural_processes/{experiment_id}' + f'/best_{args.dataset}_np.pt')\n",
    "        count += 1\n",
    "\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "# Function to run the pipeline and save data\n",
    "def run_and_save_pipeline_np(train_loader, val_loader, test_loader, input_channel, epochs, val_every_epoch, config, num_runs, device):\n",
    "    test_partial_percents = [0.25, 0.5, 0.75, 1]\n",
    "    test_losses = []\n",
    "    r2_list = []\n",
    "    table = []\n",
    "    table.append(['Dataset', 'Mode', 'd', 'n_pins', 'LR', 'PLP', 'MSE error', 'R2'])\n",
    "    experiment_id = run_pipeline_ci_np(train_loader, val_loader, \n",
    "                    test_loader, input_channel, epochs, val_every_epoch, config, device, num_runs)\n",
    "    # Run final testing\n",
    "    model = NeuralProcessImg(r_dim, z_dim, h_dim).to(device)\n",
    "    # MSE\n",
    "    model.load_state_dict(torch.load(f'./results/neural_processes/{experiment_id}/best_{args.dataset}_np.pt'))\n",
    "    for partial_percent in test_partial_percents:\n",
    "        test_loss, r2 = evaluate_np(model, test_loader, device, partial_percent=partial_percent)\n",
    "        print(f\"pp: {partial_percent} MSE loss: {test_loss} R2 score: {r2}\")\n",
    "        table.append([args.dataset, args.mode, args.d, args.n_pins, config['best_lr'], partial_percent, test_loss, r2])\n",
    "        test_losses.append(test_loss)\n",
    "        r2_list.append(r2)\n",
    "    table = tabulate(table, headers='firstrow', tablefmt='fancy_grid', showindex=True)\n",
    "    print(table)\n",
    "    with open('./results/neural_processes/table.txt', 'a') as f:\n",
    "        f.write('\\n')\n",
    "        f.write(table + '\\n')  # Add a newline character after writing the table\n",
    "        f.write('\\n')  # Add an additional newline character for separation\n",
    "    print(\"saved\")\n",
    "    return test_losses, r2_list, experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc10563-9861-4f04-bfda-77ce67b76c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    dataset = \"PinMNIST\"\n",
    "    n = 1000\n",
    "    mode = \"mesh\"\n",
    "    d = 10\n",
    "    n_pins = 10\n",
    "    r = 3\n",
    "    partial_percent = 0.8\n",
    "    # Set your hyperparameters\n",
    "    epochs = 1000\n",
    "    batch_size = 50\n",
    "    learning_rate = 1e-4\n",
    "    val_every_epoch = 10\n",
    "    num_runs = 1\n",
    "    seed = 4\n",
    "    \n",
    "class NP_config():\n",
    "    r_dim = 512\n",
    "    h_dim = 512\n",
    "    z_dim = 512\n",
    "    lr = 4e-5\n",
    "    epochs = 100\n",
    "\n",
    "np_config = NP_config()\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e35ab4e-0d87-40fc-9591-8b1be2640378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for PyTorch\n",
    "seed = 4  # You can use any integer value as the seed\n",
    "torch.manual_seed(seed)\n",
    "# Set a random seed for NumPy (if you're using NumPy operations)\n",
    "np.random.seed(seed)\n",
    "\n",
    " # Choose datasets\n",
    "dataset = args.dataset \n",
    "n = args.n\n",
    "mode = args.mode\n",
    "d = args.d\n",
    "n_pins = args.n_pins\n",
    "r = args.r\n",
    "partial_percent = args.partial_percent\n",
    "\n",
    "# Set your hyperparameters\n",
    "epochs = args.epochs\n",
    "batch_size = args.batch_size\n",
    "learning_rate = args.learning_rate\n",
    "val_every_epoch = args.val_every_epoch\n",
    "num_runs = args.num_runs\n",
    "   \n",
    "config = {}\n",
    "# np_config = {\"batch_size\": 32,\n",
    "#              \"r_dim\": 512,\n",
    "#              \"h_dim\": 512,\n",
    "#              \"z_dim\": 512,\n",
    "#              \"lr\": 4e-5,\n",
    "#              \"epochs\": 100\n",
    "#             }\n",
    "\n",
    "# config = vars(args)\n",
    "config = {\"experiment_id\":0}\n",
    "\n",
    "input_channel = 1 if dataset == \"PinMNIST\" else 3\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247eb8c4-b9ee-4857-a528-2867abb87b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if feature_extracted:\n",
    "#     folder = f\"{dataset}_ddpm\"\n",
    "# else:\n",
    "folder = f\"{dataset}\"\n",
    "\n",
    "if dataset == \"PinMNIST\":\n",
    "    if mode == \"mesh\":\n",
    "        data_folder = f\"./data/{folder}/mesh_{d}step_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "    else:\n",
    "        data_folder = f\"./data/{folder}/random_fixedTrue_{n_pins}pins_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),         # Convert to tensor (as you were doing)\n",
    "    Resize()  # Resize to 100x100\n",
    "])\n",
    "\n",
    "transformed_dataset = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                      root_dir=f\"./data/{dataset}/images/\",\n",
    "                                      transform=transform)\n",
    "\n",
    "dataset_size = len(transformed_dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    transformed_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87002a7-af7a-4598-b786-d6796423bfea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg_loss: 402.063\n",
      "Epoch: 0, Val_loss 113.709\n",
      "Epoch: 1, Avg_loss: 83.094\n",
      "Epoch: 2, Avg_loss: 47.212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_lr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Run and save the pipeline data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     test_losses, r2, experiment_id \u001b[38;5;241m=\u001b[39m \u001b[43mrun_and_save_pipeline_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43minput_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     experiment_id \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mrun_and_save_pipeline_np\u001b[0;34m(train_loader, val_loader, test_loader, input_channel, epochs, val_every_epoch, config, num_runs, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m table \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     47\u001b[0m table\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_pins\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 48\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline_ci_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Run final testing\u001b[39;00m\n\u001b[1;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralProcessImg(r_dim, z_dim, h_dim)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mrun_pipeline_ci_np\u001b[0;34m(train_loader, val_loader, test_loader, input_channel, epochs, val_every_epoch, config, device, num_runs, print_freq)\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     30\u001b[0m np_trainer \u001b[38;5;241m=\u001b[39m NeuralProcessTrainer(device, model, optimizer, early_stopping, experiment_id, print_freq\u001b[38;5;241m=\u001b[39mprint_freq)          \n\u001b[0;32m---> 32\u001b[0m \u001b[43mnp_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_trainer\u001b[38;5;241m.\u001b[39mbest_val_loss \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m global_val_loss:\n\u001b[1;32m     34\u001b[0m     global_val_loss \u001b[38;5;241m=\u001b[39m np_trainer\u001b[38;5;241m.\u001b[39mbest_val_loss \n",
      "File \u001b[0;32m/work/DNAL/shi.cheng/NPP/Satellite_Fusion/tools/NPtrain.py:179\u001b[0m, in \u001b[0;36mNeuralProcessTrainer.train\u001b[0;34m(self, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m    177\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_batch \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[1;32m    180\u001b[0m         x_context_val, y_context_val, x_target_val, y_target_val \u001b[38;5;241m=\u001b[39m process_batch(val_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    181\u001b[0m         p_y_pred_val, q_target_val, q_context_val \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    182\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneural_process(x_context_val, y_context_val, x_target_val, y_target_val)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/work/DNAL/shi.cheng/NPP/Satellite_Fusion/tools/data_utils.py:334\u001b[0m, in \u001b[0;36mPinDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    332\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(img_name)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m pins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpins_frame\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    336\u001b[0m outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28meval\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpins_frame\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m2\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/skimage/io/_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[0;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/skimage/io/manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/imageio/v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/imageio/core/imopen.py:196\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     plugin_instance \u001b[38;5;241m=\u001b[39m \u001b[43mcandidate_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InitializationError:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# file extension doesn't match file type\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/imageio/plugins/pillow.py:83\u001b[0m, in \u001b[0;36mPillowPlugin.__init__\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mio_mode \u001b[38;5;241m==\u001b[39m IOMode\u001b[38;5;241m.\u001b[39mread:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;66;03m# Check if it is generally possible to read the image.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;66;03m# This will not read any data and merely try to find a\u001b[39;00m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;66;03m# compatible pillow plugin (ref: the pillow docs).\u001b[39;00m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnidentifiedImageError:\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/imageio/core/request.py:492\u001b[0m, in \u001b[0;36mRequest.get_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 492\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uri_type \u001b[38;5;241m==\u001b[39m URI_ZIPPED:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# Get the correct filename\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     filename, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename_zip\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "r_dim, z_dim, h_dim = np_config.r_dim, np_config.z_dim, np_config.h_dim\n",
    "if (config['experiment_id'] == 0): # Training\n",
    "\n",
    "    neural_processes = NeuralProcessImg(r_dim, z_dim, h_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(neural_processes.parameters(), learning_rate)\n",
    "#     lr_finder_NP =NPLRFinder(neural_processes, optimizer, device=device)\n",
    "#     lr_finder_NP.find_lr(train_loader,input_channel=input_channel, start_lr=1e-5, end_lr=1, num_iter=20)\n",
    "#     best_lr_NP = lr_finder_NP.find_best_lr()\n",
    "#     print(f\"Best Learning Rate for NP: {best_lr_NP}\")\n",
    "\n",
    "#     config['best_lr'] = best_lr_NP\n",
    "    config['best_lr'] = 1e-4\n",
    "    # Run and save the pipeline data\n",
    "    test_losses, r2, experiment_id = run_and_save_pipeline_np(train_loader, val_loader, test_loader,\\\n",
    "                                               input_channel, epochs, val_every_epoch, config, num_runs, device)\n",
    "\n",
    "else: # Testing\n",
    "    experiment_id = config['experiment_id']\n",
    "    if not os.path.exists(f'./results/neural_processes/{experiment_id}'):\n",
    "        raise Exception(f\"Could not find experiment with id: {experiment_id}\")\n",
    "    else:\n",
    "        neural_processes = NeuralProcessImg(r_dim, z_dim, h_dim).to(device)\n",
    "        try:\n",
    "            neural_processes.load_state_dict(torch.load(f'./results/neural_processes/{experiment_id}/best_model_NP.pth'))\n",
    "        except:\n",
    "            raise Exception(\"The model you provided does not correspond with the selected architecture. Please revise and try again.\")\n",
    "        \n",
    "        \n",
    "        filename = f\"test_{folder}_{partial_percent}\"\n",
    "        with open(f\"./results/neural_processes/{experiment_id}/{filename}\", \"w\") as f:\n",
    "            f.write(f\"MSE {best_MSE_test_loss}; NPP {best_NPP_test_loss}, {GP_best_NPP_test_loss} (GP)\")\n",
    "            \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time elapsed:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c87bbb-716b-4bda-a39e-857f2ae356bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  dsk            /home/shi.cheng/.local/share/jupyter/kernels/dsk\n",
      "  jax            /home/shi.cheng/.local/share/jupyter/kernels/jax\n",
      "  local-venv     /home/shi.cheng/.local/share/jupyter/kernels/local-venv\n",
      "  myenv          /home/shi.cheng/.local/share/jupyter/kernels/myenv\n",
      "  pycox          /home/shi.cheng/.local/share/jupyter/kernels/pycox\n",
      "  python3        /home/shi.cheng/.local/share/jupyter/kernels/python3\n",
      "  pytorch_env    /home/shi.cheng/.local/share/jupyter/kernels/pytorch_env\n",
      "  survdata       /home/shi.cheng/.local/share/jupyter/kernels/survdata\n",
      "  tf_env         /home/shi.cheng/.local/share/jupyter/kernels/tf_env\n",
      "  tools          /home/shi.cheng/.local/share/jupyter/kernels/tools\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229220c4-86c2-427c-bb91-57502b26cec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycox",
   "language": "python",
   "name": "pycox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
