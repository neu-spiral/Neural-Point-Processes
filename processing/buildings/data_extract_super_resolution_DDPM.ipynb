{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f69dfd-eb80-4504-8950-8247e590a908",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Lambda\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tools.models import *\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "from argparse import ArgumentParser\n",
    "from tools.plot_utils import show_images, show_forward, generate_new_images\n",
    "from tools.models import Autoencoder\n",
    "from torch.utils.data import Subset\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import tools.sr3 as sr3\n",
    "# from misc.print_diffuse_feats import print_feats\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8b5a9-672d-4945-a9d5-1d79caa4207d",
   "metadata": {},
   "source": [
    "This was only used for RGBNIR and wasn't fully trained due to computational resource limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bde32-5606-4b1f-935f-2e2761b142d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:33:55.942953Z",
     "start_time": "2024-03-18T16:33:55.921349Z"
    }
   },
   "outputs": [],
   "source": [
    "# as in ./json/levir.json\n",
    "# The json was the same as in ddpm-cd: https://github.com/wgcban/ddpm-cd\n",
    "opt = {\n",
    "    \"name\": \"ddpm-RS-CDHead-LEVIR\",\n",
    "    \"phase\": \"test\", \n",
    "    \"gpu_ids\": [\n",
    "        0\n",
    "    ],\n",
    "     \"path\": {\n",
    "        \"resume_state\": \"./history/pretrained_sr3/sr3_50_100\"\n",
    "    },\n",
    "\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 8,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"val\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1 \n",
    "        },\n",
    "        \"test\": {\n",
    "            \"name\": \"LEVIR-CD-256\",\n",
    "            \"dataroot\": \"dataset/LEVIR-CD256/\",\n",
    "            \"resolution\": 256, \n",
    "            \"batch_size\": 4,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": False,\n",
    "            \"data_len\": -1 \n",
    "        }\n",
    "    },\n",
    "    \"model_cd\": {\n",
    "        \"feat_scales\": [2, 5, 8, 11, 14],\n",
    "        \"out_channels\": 2,\n",
    "        \"loss_type\": \"ce\",\n",
    "        \"output_cm_size\": 256,\n",
    "        \"feat_type\": \"dec\", \n",
    "        \"t\": [50, 100]\n",
    "    },\n",
    "\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\", \n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 3,\n",
    "            \"inner_channel\": 128,\n",
    "            \"channel_multiplier\": [\n",
    "                1,\n",
    "                2,\n",
    "                4,\n",
    "                8,\n",
    "                8\n",
    "            ],\n",
    "            \"attn_res\": [\n",
    "                16\n",
    "            ],\n",
    "            \"res_blocks\": 2,\n",
    "            \"dropout\": 0.2\n",
    "        },\n",
    "        \"beta_schedule\": { \n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"val\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 256,\n",
    "            \"channels\": 3, \n",
    "            \"loss\": \"l2\", \n",
    "            \"conditional\": False \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31a885-d47a-461e-b1df-511530aa3272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:00.598239Z",
     "start_time": "2024-03-18T16:34:00.549409Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dataset = \"Building\"\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "batch_size = 16\n",
    "input_channel = 3\n",
    "n = 10\n",
    "resize = Resize256\n",
    "\n",
    "data_folder = f\"random_n_pins_{n}\"\n",
    "transformed_dataset = PinDataset(csv_file=f\"./data/{dataset}/{data_folder}/pins.csv\",\n",
    "                             root_dir=f\"./data/{dataset}/images/\",\n",
    "                             transform=Compose([ToTensor(), resize(), Lambda()]))\n",
    "            \n",
    "data_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f420b7-ce1b-4a94-83ba-b3148fb9c789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:02.254775Z",
     "start_time": "2024-03-18T16:34:02.244764Z"
    }
   },
   "outputs": [],
   "source": [
    "def concat_feature_maps(feature_maps, layers=[5, 6, 7, 8]):\n",
    "    # Define empty list to store upsampled feature maps for specific layers\n",
    "    upsampled_maps = []\n",
    "    \n",
    "    # Upsample and store feature maps for specified layers\n",
    "    for t in range(len(f_A)):\n",
    "        for layer_idx in layers:\n",
    "            fmap = feature_maps[t][layer_idx]\n",
    "            upsampled_fmap = torch.nn.functional.interpolate(fmap, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "            upsampled_maps.append(upsampled_fmap)\n",
    "    \n",
    "    # Concatenate the upsampled feature maps along the channel dimension\n",
    "    concatenated_maps = torch.cat(upsampled_maps, dim=1)\n",
    "    \n",
    "    return concatenated_maps\n",
    "\n",
    "def save_fm_by_batch(opt, data_loader, images_directory, output_directory):\n",
    "    f_A = []\n",
    "    opt = sr3.dict_to_nonedict(opt)\n",
    "    # Loading diffusion model\n",
    "    diffusion = sr3.DDPM(opt)\n",
    "    # Set noise schedule for the diffusion model\n",
    "    diffusion.set_new_noise_schedule(\n",
    "        opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])   \n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    images_directory = os.path.join(images_directory, 'images')\n",
    "\n",
    "    # Create subdirectories for images and count labels\n",
    "    os.makedirs(images_directory, exist_ok=True)\n",
    "\n",
    "    # Save images as \"0.png\" or \"0.npy\", \"1.png\" or \"1.npy\", etc., and dump data to CSV\n",
    "    with open(os.path.join(output_directory, 'pins.csv'), 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row\n",
    "        csv_writer.writerow(['image', 'pins', 'outputs'])\n",
    "\n",
    "        for batch_idx, data in enumerate(data_loader):\n",
    "            images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "            pins = batch['pins']\n",
    "            outputs = batch['outputs']\n",
    "            diffusion.feed_data(train_data)   \n",
    "            for t in opt['model_cd']['t']:\n",
    "                fe_A_t, fd_A_t= diffusion.get_feats(t=t) #np.random.randint(low=2, high=8)\n",
    "                f_A.append(fd_A_t)\n",
    "            concat_fm = concat_feature_maps(f_A)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                # Calculate the overall index\n",
    "                overall_index = batch_idx * len(batch_images) + i\n",
    "\n",
    "                # Save the image as \"overall_index.png\" or \"overall_index.npy\" in the images subdirectory\n",
    "                image_filename = os.path.join(images_directory, f\"{overall_index}\")\n",
    "                # For multi-channel images, save as NPY\n",
    "                image_filename += \".npy\"\n",
    "                if not os.path.exists(image_filename):\n",
    "                    np.save(image_filename, concat_fm[i].detach().cpu().numpy())\n",
    "\n",
    "                # Write data to CSV\n",
    "                csv_writer.writerow([os.path.basename(image_filename), pins[i], outputs[i]])\n",
    "\n",
    "    print(\"Data and images have been saved to the CSV and image files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422475c8-f38e-4cee-8b53-2b168ba11954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T16:34:05.979538Z",
     "start_time": "2024-03-18T16:34:05.956502Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fm_by_batch(opt, data_loader, images_directory=\"./data/Building_ddpm/images\", output_directory=f\"./data/Building_ddpm/{data_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycox",
   "language": "python",
   "name": "pycox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
