{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f69dfd-eb80-4504-8950-8247e590a908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T00:51:53.678041Z",
     "start_time": "2024-02-18T00:51:51.874885Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Lambda\n",
    "from torchvision.datasets.mnist import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from tools.models import *\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "from argparse import ArgumentParser\n",
    "import einops\n",
    "from tools.plot_utils import show_images, show_forward, generate_new_images\n",
    "from tools.models import Autoencoder\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Setting reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Definitions\n",
    "STORE_PATH_MNIST = f\"./history/ddpm_model_mnist.pt\"\n",
    "STORE_PATH_SYNTH = f\"./history/ddpm_model_synth.pt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4f6309-022d-4db3-9b22-0bc481d7b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the input dimensions\n",
    "batch_size = 2\n",
    "channels = 4\n",
    "height = 100\n",
    "width = 100\n",
    "\n",
    "# Generate random inputs for testing\n",
    "input_data = torch.randn(batch_size, channels, height, width)\n",
    "n_steps = 1000\n",
    "time_steps = torch.randint(0, n_steps, (batch_size,))\n",
    "output = unet(input_data, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956c195-0b6c-4fb0-ac09-522c9000278e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T00:51:57.332522Z",
     "start_time": "2024-02-18T00:51:57.326965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "def training_loop(dataset, ddpm, loader, n_epochs, optim, device, display=False, store_path=\"ddpm_model.pt\"):\n",
    "    mse = nn.MSELoss()\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddpm.n_steps\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for data in loader:\n",
    "            # Loading data\n",
    "            if dataset ==\"MNIST\":\n",
    "                x0 = data[0].to(device)\n",
    "            else:\n",
    "                x0 = data[\"image\"].float().to(device)\n",
    "            n = len(x0)\n",
    "\n",
    "            # Picking some noise for each of the images in the batch, a timestep and the respective alpha_bars\n",
    "            eta = torch.randn_like(x0).to(device)\n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "\n",
    "            # Computing the noisy image based on x0 and the time-step (forward process)\n",
    "            noisy_imgs = ddpm(x0, t, eta)\n",
    "\n",
    "            # Getting model estimation of noise based on the images and the time-step\n",
    "            eta_theta, _ = ddpm.backward(noisy_imgs, t.reshape(n, -1))\n",
    "\n",
    "            # Optimizing the MSE between the noise plugged and the predicted noise\n",
    "            loss = mse(eta_theta, eta)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_loss += loss.item() * len(x0) / len(loader.dataset)\n",
    "\n",
    "        # Display images generated at this epoch\n",
    "        if display:\n",
    "            show_images(generate_new_images(ddpm, device=device), f\"Images generated at epoch {epoch + 1}\")\n",
    "\n",
    "        log_string = f\"Loss at epoch {epoch + 1}: {train_loss:.3f}\"\n",
    "    \n",
    "        # Storing the model\n",
    "        if best_loss > train_loss:\n",
    "            best_loss = train_loss\n",
    "            torch.save(ddpm.state_dict(), store_path)\n",
    "            log_string += \" --> Best model ever (stored)\"\n",
    "\n",
    "        print(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31a885-d47a-461e-b1df-511530aa3272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dataset = \"Cars\"\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "input_channel = 1 if dataset == \"PinMNIST\" else 4\n",
    "\n",
    "# Loading the data (converting each image into a tensor and normalizing between [-1, 1])\n",
    "if dataset == \"Building\":\n",
    "    resize = Resize100\n",
    "elif dataset == \"Cars\":\n",
    "    resize = Resize200\n",
    "else:\n",
    "    resize = Resize\n",
    "    \n",
    "if dataset == \"MNIST\":\n",
    "    ds_fn = MNIST\n",
    "    dataset_fn = ds_fn(\"./datasets\", download=True, train=True, transform=transform)\n",
    "    train_dataloader = DataLoader(dataset_fn, batch_size, shuffle=True)\n",
    "elif dataset == \"Synthetic\":\n",
    "    # Use enough images to get great generation\n",
    "    data_folder = \"./data/Synthetic/10images_28by28pixels_4_distanced_grid_pins_4seed\"\n",
    "    dataset_fn = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                  root_dir=f\"{data_folder}/images/\",\n",
    "                                  transform=transforms.Compose([ToTensor(), resize()]))\n",
    "    train_dataloader = DataLoader(dataset_fn, batch_size, shuffle=True)\n",
    "    \n",
    "elif dataset == \"Building\":\n",
    "    transformed_dataset = PinDataset(csv_file=f\"./data/{dataset}/pins_full.csv\",\n",
    "                             root_dir=f\"./data/{dataset}/PS-RGBNIR/\",\n",
    "                             transform=Compose([ToTensor(), resize(), Lambda()]))\n",
    "    \n",
    "else: # Cars\n",
    "    train_data_folder = f\"./data/Cars/train/mesh_20step_800by800pixels_100radius_4seed\"\n",
    "    transformed_dataset = PinDataset(csv_file=f\"{train_data_folder}/pins.csv\",\n",
    "                                     root_dir=\"./data/Cars/images/train\", \n",
    "                                     transform=Compose(ExtractImage(),ToTensor(), Resize200()), n=1000)\n",
    "            \n",
    "if os.path.exists(f\"./data/{dataset}/train_indices.npy\"):\n",
    "    train_indices = np.load(f'./data/{dataset}/train_indices.npy')\n",
    "    val_indices = np.load(f'./data/{dataset}/val_indices.npy')\n",
    "    test_indices = np.load(f'./data/{dataset}/test_indices.npy')\n",
    "    train_indices = np.concatenate((train_indices, np.arange(1000, 1697))) # add all un-used images for DDPM training\n",
    "    # Use the indices to create new datasets\n",
    "    train_dataset = Subset(transformed_dataset, train_indices)\n",
    "    val_dataset = Subset(transformed_dataset, val_indices)\n",
    "    test_dataset = Subset(transformed_dataset, test_indices)\n",
    "else:\n",
    "    dataset_size = len(transformed_dataset)\n",
    "    train_size = int(0.7 * dataset_size)\n",
    "    val_size = int(0.10 * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        transformed_dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    np.save(f'./data/{dataset}/train_indices.npy', train_dataset.indices)\n",
    "    np.save(f'./data/{dataset}/val_indices.npy', val_dataset.indices)\n",
    "    np.save(f'./data/{dataset}/test_indices.npy', test_dataset.indices)\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Initialize the autoencoder\n",
    "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02  # Originally used by the authors\n",
    "if dataset == \"Building\" or dataset == \"Cars\":\n",
    "    model = DDPM(UNet(input_channel, shape=100), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "else:\n",
    "    model = DDPM(UNet(input_channel), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(dataset, model, train_loader, num_epochs, optimizer, device, store_path=store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf741ccb-dba1-47e5-8332-7a8ace92ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "count = 0\n",
    "for batch in train_loader:\n",
    "    images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "    pins = batch['pins']\n",
    "    outputs = batch['outputs']\n",
    "    print(count, len(images))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ce792-3ad7-415c-a9c2-f30cdcea198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "best_model = DDPM(UNet(), n_steps=n_steps, device=device)\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"Model loaded\")\n",
    "\n",
    "print(\"Generating new images\")\n",
    "generated = generate_new_images(\n",
    "        best_model,\n",
    "        n_samples=100,\n",
    "        device=device,\n",
    "        gif_name=\"mnist.gif\"\n",
    "    )\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02adbd-4de1-4b59-8e03-42d94793b676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_forward(model, train_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
