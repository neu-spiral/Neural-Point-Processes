{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f69dfd-eb80-4504-8950-8247e590a908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T00:51:53.678041Z",
     "start_time": "2024-02-18T00:51:51.874885Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Lambda\n",
    "from torchvision.datasets.mnist import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from tools.models import *\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import imageio\n",
    "from argparse import ArgumentParser\n",
    "import einops\n",
    "from tools.plot_utils import show_images, show_forward, generate_new_images\n",
    "from tools.models import Autoencoder\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Setting reproducibility\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Definitions\n",
    "STORE_PATH_MNIST = f\"./history/ddpm_model_mnist.pt\"\n",
    "STORE_PATH_SYNTH = f\"./history/ddpm_model_synth.pt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f6309-022d-4db3-9b22-0bc481d7b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the input dimensions\n",
    "batch_size = 2\n",
    "channels = 4\n",
    "height = 100\n",
    "width = 100\n",
    "\n",
    "# Generate random inputs for testing\n",
    "input_data = torch.randn(batch_size, channels, height, width)\n",
    "n_steps = 1000\n",
    "time_steps = torch.randint(0, n_steps, (batch_size,))\n",
    "output = unet(input_data, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d956c195-0b6c-4fb0-ac09-522c9000278e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T00:51:57.332522Z",
     "start_time": "2024-02-18T00:51:57.326965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "def training_loop(dataset, ddpm, loader, n_epochs, optim, device, display=False, store_path=\"ddpm_model.pt\"):\n",
    "    mse = nn.MSELoss()\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddpm.n_steps\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for data in loader:\n",
    "            # Loading data\n",
    "            if dataset ==\"MNIST\":\n",
    "                x0 = data[0].to(device)\n",
    "            else:\n",
    "                x0 = data[\"image\"].float().to(device)\n",
    "            n = len(x0)\n",
    "\n",
    "            # Picking some noise for each of the images in the batch, a timestep and the respective alpha_bars\n",
    "            eta = torch.randn_like(x0).to(device)\n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "\n",
    "            # Computing the noisy image based on x0 and the time-step (forward process)\n",
    "            noisy_imgs = ddpm(x0, t, eta)\n",
    "\n",
    "            # Getting model estimation of noise based on the images and the time-step\n",
    "            eta_theta, _ = ddpm.backward(noisy_imgs, t.reshape(n, -1))\n",
    "\n",
    "            # Optimizing the MSE between the noise plugged and the predicted noise\n",
    "            loss = mse(eta_theta, eta)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_loss += loss.item() * len(x0) / len(loader.dataset)\n",
    "\n",
    "        # Display images generated at this epoch\n",
    "        if display:\n",
    "            show_images(generate_new_images(ddpm, device=device), f\"Images generated at epoch {epoch + 1}\")\n",
    "\n",
    "        log_string = f\"Loss at epoch {epoch + 1}: {train_loss:.3f}\"\n",
    "    \n",
    "        # Storing the model\n",
    "        if best_loss > train_loss:\n",
    "            best_loss = train_loss\n",
    "            torch.save(ddpm.state_dict(), store_path)\n",
    "            log_string += \" --> Best model ever (stored)\"\n",
    "\n",
    "        print(log_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31a885-d47a-461e-b1df-511530aa3272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 1.000 --> Best model ever (stored)\n",
      "Loss at epoch 2: 0.988 --> Best model ever (stored)\n",
      "Loss at epoch 3: 0.960 --> Best model ever (stored)\n",
      "Loss at epoch 4: 0.914 --> Best model ever (stored)\n",
      "Loss at epoch 5: 0.857 --> Best model ever (stored)\n",
      "Loss at epoch 6: 0.800 --> Best model ever (stored)\n",
      "Loss at epoch 7: 0.766 --> Best model ever (stored)\n",
      "Loss at epoch 8: 0.737 --> Best model ever (stored)\n",
      "Loss at epoch 9: 0.728 --> Best model ever (stored)\n",
      "Loss at epoch 10: 0.709 --> Best model ever (stored)\n",
      "Loss at epoch 11: 0.697 --> Best model ever (stored)\n",
      "Loss at epoch 12: 0.677 --> Best model ever (stored)\n",
      "Loss at epoch 13: 0.655 --> Best model ever (stored)\n",
      "Loss at epoch 14: 0.629 --> Best model ever (stored)\n",
      "Loss at epoch 15: 0.602 --> Best model ever (stored)\n",
      "Loss at epoch 16: 0.580 --> Best model ever (stored)\n",
      "Loss at epoch 17: 0.562 --> Best model ever (stored)\n",
      "Loss at epoch 18: 0.539 --> Best model ever (stored)\n",
      "Loss at epoch 19: 0.514 --> Best model ever (stored)\n",
      "Loss at epoch 20: 0.489 --> Best model ever (stored)\n",
      "Loss at epoch 21: 0.476 --> Best model ever (stored)\n",
      "Loss at epoch 22: 0.458 --> Best model ever (stored)\n",
      "Loss at epoch 23: 0.438 --> Best model ever (stored)\n",
      "Loss at epoch 24: 0.423 --> Best model ever (stored)\n",
      "Loss at epoch 25: 0.414 --> Best model ever (stored)\n",
      "Loss at epoch 26: 0.404 --> Best model ever (stored)\n",
      "Loss at epoch 27: 0.405\n",
      "Loss at epoch 28: 0.403 --> Best model ever (stored)\n",
      "Loss at epoch 29: 0.392 --> Best model ever (stored)\n",
      "Loss at epoch 30: 0.381 --> Best model ever (stored)\n",
      "Loss at epoch 31: 0.374 --> Best model ever (stored)\n",
      "Loss at epoch 32: 0.376\n",
      "Loss at epoch 36: 0.363\n",
      "Loss at epoch 37: 0.397\n",
      "Loss at epoch 38: 0.402\n",
      "Loss at epoch 39: 0.382\n",
      "Loss at epoch 40: 0.367\n",
      "Loss at epoch 41: 0.358 --> Best model ever (stored)\n",
      "Loss at epoch 44: 0.326 --> Best model ever (stored)\n",
      "Loss at epoch 45: 0.326 --> Best model ever (stored)\n",
      "Loss at epoch 46: 0.318 --> Best model ever (stored)\n",
      "Loss at epoch 47: 0.316 --> Best model ever (stored)\n",
      "Loss at epoch 48: 0.307 --> Best model ever (stored)\n",
      "Loss at epoch 49: 0.300 --> Best model ever (stored)\n",
      "Loss at epoch 50: 0.289 --> Best model ever (stored)\n",
      "Loss at epoch 51: 0.281 --> Best model ever (stored)\n",
      "Loss at epoch 52: 0.296\n",
      "Loss at epoch 53: 0.278 --> Best model ever (stored)\n",
      "Loss at epoch 54: 0.261 --> Best model ever (stored)\n",
      "Loss at epoch 55: 0.245 --> Best model ever (stored)\n",
      "Loss at epoch 56: 0.225 --> Best model ever (stored)\n",
      "Loss at epoch 57: 0.208 --> Best model ever (stored)\n",
      "Loss at epoch 58: 0.201 --> Best model ever (stored)\n",
      "Loss at epoch 59: 0.224\n",
      "Loss at epoch 60: 0.253\n",
      "Loss at epoch 61: 0.209\n",
      "Loss at epoch 62: 0.177 --> Best model ever (stored)\n",
      "Loss at epoch 63: 0.158 --> Best model ever (stored)\n",
      "Loss at epoch 64: 0.141 --> Best model ever (stored)\n",
      "Loss at epoch 65: 0.129 --> Best model ever (stored)\n",
      "Loss at epoch 66: 0.117 --> Best model ever (stored)\n",
      "Loss at epoch 69: 0.092 --> Best model ever (stored)\n",
      "Loss at epoch 70: 0.084 --> Best model ever (stored)\n",
      "Loss at epoch 71: 0.082 --> Best model ever (stored)\n",
      "Loss at epoch 72: 0.077 --> Best model ever (stored)\n",
      "Loss at epoch 73: 0.080\n",
      "Loss at epoch 74: 0.077 --> Best model ever (stored)\n",
      "Loss at epoch 75: 0.077\n",
      "Loss at epoch 76: 0.073 --> Best model ever (stored)\n",
      "Loss at epoch 77: 0.068 --> Best model ever (stored)\n",
      "Loss at epoch 78: 0.070\n",
      "Loss at epoch 79: 0.073\n",
      "Loss at epoch 80: 0.064 --> Best model ever (stored)\n",
      "Loss at epoch 81: 0.068\n",
      "Loss at epoch 82: 0.065\n",
      "Loss at epoch 83: 0.059 --> Best model ever (stored)\n",
      "Loss at epoch 84: 0.065\n",
      "Loss at epoch 85: 0.057 --> Best model ever (stored)\n",
      "Loss at epoch 86: 0.053 --> Best model ever (stored)\n",
      "Loss at epoch 87: 0.056\n",
      "Loss at epoch 88: 0.056\n",
      "Loss at epoch 89: 0.072\n",
      "Loss at epoch 90: 0.061\n",
      "Loss at epoch 91: 0.057\n",
      "Loss at epoch 92: 0.054\n",
      "Loss at epoch 93: 0.058\n",
      "Loss at epoch 94: 0.051 --> Best model ever (stored)\n",
      "Loss at epoch 95: 0.053\n",
      "Loss at epoch 96: 0.059\n",
      "Loss at epoch 97: 0.054\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset = \"Cars\"\n",
    "data_dir = \"/work/DNAL/Datasets\" # ./data\n",
    "store_path = f\"../../history/ddpm_model_{dataset}.pt\"\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "if dataset == \"PinMNIST\":\n",
    "    input_channel = 1\n",
    "elif dataset == \"Cars\":\n",
    "    input_channel = 3\n",
    "else:\n",
    "    input_channel = 4\n",
    "\n",
    "# Loading the data (converting each image into a tensor and normalizing between [-1, 1])\n",
    "if dataset == \"Building\":\n",
    "    resize = Resize100\n",
    "elif dataset == \"Cars\":\n",
    "    resize = Resize200\n",
    "else:\n",
    "    resize = Resize\n",
    "    \n",
    "if dataset == \"MNIST\":\n",
    "    ds_fn = MNIST\n",
    "    dataset_fn = ds_fn(\"./datasets\", download=True, train=True, transform=transform)\n",
    "    train_dataloader = DataLoader(dataset_fn, batch_size, shuffle=True)\n",
    "elif dataset == \"Synthetic\":\n",
    "    # Use enough images to get great generation\n",
    "    data_folder = \"./data/Synthetic/10images_28by28pixels_4_distanced_grid_pins_4seed\"\n",
    "    dataset_fn = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                  root_dir=f\"{data_folder}/images/\",\n",
    "                                  transform=transforms.Compose([ToTensor(), resize()]))\n",
    "    train_dataloader = DataLoader(dataset_fn, batch_size, shuffle=True)\n",
    "    \n",
    "elif dataset == \"Building\":\n",
    "    transformed_dataset = PinDataset(csv_file=f\"./data/{dataset}/pins_full.csv\",\n",
    "                             root_dir=f\"./data/{dataset}/PS-RGBNIR/\",\n",
    "                             transform=Compose([ToTensor(), resize(), Lambda()]))\n",
    "    \n",
    "else: # Cars\n",
    "    train_data_folder = os.path.join(data_dir, \"Cars/train/mesh_20step_800by800pixels_100radius_4seed\")\n",
    "    transformed_dataset = PinDataset(csv_file=f\"{train_data_folder}/pins.csv\",\n",
    "                                     root_dir=os.path.join(data_dir, \"Cars/images/train\"), \n",
    "                                     transform=Compose([ExtractImage(),ToTensor(), Resize200()]), n=1000)\n",
    "            \n",
    "if os.path.exists(f\"./data/{dataset}/train_indices.npy\"):\n",
    "    train_indices = np.load(f'{data_dir}/{dataset}/train_indices.npy')\n",
    "    val_indices = np.load(f'{data_dir}/{dataset}/val_indices.npy')\n",
    "    test_indices = np.load(f'{data_dir}/{dataset}/test_indices.npy')\n",
    "    train_indices = np.concatenate((train_indices, np.arange(1000, 1697))) # add all un-used images for DDPM training\n",
    "    # Use the indices to create new datasets\n",
    "    train_dataset = Subset(transformed_dataset, train_indices)\n",
    "    val_dataset = Subset(transformed_dataset, val_indices)\n",
    "    test_dataset = Subset(transformed_dataset, test_indices)\n",
    "else:\n",
    "    dataset_size = len(transformed_dataset)\n",
    "    train_size = int(0.7 * dataset_size)\n",
    "    val_size = int(0.10 * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        transformed_dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    np.save(f'{data_dir}/{dataset}/train_indices.npy', train_dataset.indices)\n",
    "    np.save(f'{data_dir}/{dataset}/val_indices.npy', val_dataset.indices)\n",
    "    np.save(f'{data_dir}/{dataset}/test_indices.npy', test_dataset.indices)\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Initialize the autoencoder\n",
    "n_steps, min_beta, max_beta = 1000, 10 ** -4, 0.02  # Originally used by the authors\n",
    "if dataset == \"Building\":\n",
    "    model = DDPM(UNet(input_channel, shape=100), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "elif dataset == \"Cars\":\n",
    "    model = DDPM(UNet(input_channel, shape=200), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "else:\n",
    "    model = DDPM(UNet(input_channel), n_steps=n_steps, min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "training_loop(dataset, model, train_loader, num_epochs, optimizer, device, store_path=store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf741ccb-dba1-47e5-8332-7a8ace92ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "count = 0\n",
    "for batch in train_loader:\n",
    "    images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "    pins = batch['pins']\n",
    "    outputs = batch['outputs']\n",
    "    print(count, len(images))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ce792-3ad7-415c-a9c2-f30cdcea198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the trained model\n",
    "store_path = f\"./history/ddpm_model_{dataset}.pt\"\n",
    "best_model = DDPM(UNet(), n_steps=n_steps, device=device)\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"Model loaded\")\n",
    "\n",
    "print(\"Generating new images\")\n",
    "generated = generate_new_images(\n",
    "        best_model,\n",
    "        n_samples=100,\n",
    "        device=device,\n",
    "        gif_name=\"mnist.gif\"\n",
    "    )\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02adbd-4de1-4b59-8e03-42d94793b676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_forward(model, train_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
