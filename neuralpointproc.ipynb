{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3836b3f8-f993-415f-b442-f772829e47e6",
   "metadata": {},
   "source": [
    "Neural Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca94db99-f1a0-448f-91d0-d6b98ff5bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from functools import lru_cache\n",
    "from tools.plot_utils import visualize_pins, plot_label_pin, plot_all\n",
    "from tools.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa53412-0c89-4617-9b7e-efffa9b63834",
   "metadata": {},
   "source": [
    "# Dataset and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "000f94a1-69f9-488f-840c-0a0079b1bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for PyTorch\n",
    "seed = 4  # You can use any integer value as the seed\n",
    "torch.manual_seed(seed)\n",
    "# Set a random seed for NumPy (if you're using NumPy operations)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "770be29d-6a82-4394-96c9-8c37bae5e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Synthetic\" \n",
    "n = 100\n",
    "mesh = True\n",
    "d = 10\n",
    "n_pins = 500\n",
    "fixed_pins = True\n",
    "r = 3\n",
    "d1,d2 = 28,28\n",
    "\n",
    "if dataset == \"PinMNIST\":\n",
    "    if mesh:\n",
    "        data_folder = f\"./data/MNIST_{n}images_mesh_{d}step_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "    else:\n",
    "        data_folder = f\"./data/MNIST_{n}images_random_fixed{fixed_pins}_{n_pins}pins_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "\n",
    "if dataset == \"Synthetic\":\n",
    "    if mesh:\n",
    "        data_folder = f\"./data/Synthetic_{n}images_{d1}by{d2}pixels_{d}_distanced_grid_pins_{seed}seed/\"\n",
    "    else:\n",
    "        data_folder = f\"./data/Synthetic_{n}images_{d1}by{d2}pixels_upto{n_pins}pins_{seed}seed/\"\n",
    "        \n",
    "    \n",
    "    \n",
    "# data_folder = f\"./data/MNIST_{n}images_mesh_{d}step_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "# data_folder = \"./data/Synthetic_100images_32by32pixels_upto500pins_4seed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79d8cfc5-3e51-49d0-b091-52a4fc07b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform pipeline that includes the resizing step\n",
    "if dataset == \"PinMNIST\":\n",
    "    transform = transforms.Compose([\n",
    "        ToTensor(),         # Convert to tensor (as you were doing)\n",
    "        Resize()  # Resize to 100x100\n",
    "    ])\n",
    "\n",
    "    transformed_dataset = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                          root_dir=f\"{data_folder}/images/\",\n",
    "                                          transform=transform)\n",
    "elif dataset == \"Synthetic\":\n",
    "    transform = transforms.Compose([\n",
    "        ToTensor(),         # Convert to tensor (as you were doing)\n",
    "        Resize()  # Resize to 100x100\n",
    "    ])\n",
    "\n",
    "    transformed_dataset = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                          root_dir=f\"{data_folder}/images/\",\n",
    "                                          transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7eb005b6-e4cf-46fd-a9e4-b341249662e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(transformed_dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    transformed_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images = [sample['image'] for sample in batch]\n",
    "    pins = [sample['pins'] for sample in batch]\n",
    "    outputs = [sample['outputs'] for sample in batch]\n",
    "\n",
    "\n",
    "    return {\n",
    "        'image': torch.stack(images, dim=0),\n",
    "        'pins': pins,\n",
    "        'outputs': outputs}\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a0924c3f-3735-4c1f-b940-f902f4ccd25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    images = batch['image']  # get RGB instead of RGBA\n",
    "    pins = batch['pins']     \n",
    "    outputs = batch['outputs']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ce377de-650d-4e4c-9520-437fc8752263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAGwCAYAAABGsizmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACZQ0lEQVR4nOzde3wU1f3/8ffu5rIJkHAJJKDhjgKCoNwMRUGbGiwV0ypV28pFCtYSFVOxQhEUbNOiIKhUSltAf5VCaRWt2iiiYP1yqyBVvKAoCIIJIJJIINlkd35/0Gxck8Ce2U12WV5PH/PAzJ7PnDOzl8/O2ZlzHJZlWQIAAAAAAAAAALU4I90AAAAAAAAAAACiFZ3oAAAAAAAAAADUg050AAAAAAAAAADqQSc6AAAAAAAAAAD1oBMdAAAAAAAAAIB60IkOAAAAAAAAAEA96EQHAAAAAAAAAKAedKIDAAAAAAAAAFAPOtEBAAAAAAAAAKgHnehAGDgcDt13332RbgYAAAAAADA0duxYdezYMWAd5/kAvo5OdESNd955R9ddd506dOggt9utc845R9/5znf06KOPRrppja5jx4763ve+F+lmAAAQdh9//LFuueUWde7cWW63WykpKfrWt76lBQsW6MSJE5FuniTp97//vZYtWxZ0eYfDoby8vIZrEAAADSwW83O1o0ePyu12y+Fw6P333w9rm/bs2SOHw6GHHnoorNsFEH3iIt0AQJI2bNigyy+/XO3bt9eECROUkZGhffv2adOmTVqwYIFuu+22SDcRAACE6IUXXtCoUaOUmJio0aNHq1evXvJ4PHrjjTc0ZcoUvfvuu1q8eHGkm6nf//73SktL09ixYyPdFAAAGlys5+dVq1bJ4XAoIyNDTz31lB544IGGaSCAmEYnOqLCr3/9a6Wmpuo///mPmjdvHvDYwYMHI9MoAAAQNrt379YNN9ygDh066NVXX1Xbtm39j02aNEm7du3SCy+8EMEWAgBw9jkb8vNf/vIXffe731WHDh20fPlyOtEB2MJwLogKH3/8sS644IJaHeiS1KZNm4C/ly5dqiuuuEJt2rRRYmKievbsqccff7xWXPWQKOvWrVP//v2VlJSk3r17a926dZKkp59+Wr1795bb7Va/fv301ltvBcSPHTtWTZs21SeffKKcnBw1adJE7dq106xZs2RZ1mn3af/+/br55puVnp6uxMREXXDBBVqyZEnwB+Vrvn6L2MKFC9W5c2clJyfryiuv1L59+2RZlmbPnq1zzz1XSUlJuuaaa3TkyJGAbTz77LMaMWKE2rVrp8TERHXp0kWzZ8+W1+utVV91HUlJSRo4cKD+/e9/a9iwYRo2bFhAuYqKCs2cOVNdu3ZVYmKiMjMzdffdd6uiosLWfgIAYtecOXN07Ngx/fnPfw44Qa/WtWtX3XHHHf6/q6qqNHv2bHXp0kWJiYnq2LGjpk2bVivH1DdeaceOHQOuVFu2bJkcDof+7//+T/n5+WrdurWaNGmi73//+zp06FBA3Lvvvqv169fL4XDI4XDUyn+ns27dOjkcDv3tb3/T/fffr3POOUfNmjXTddddp5KSElVUVGjy5Mlq06aNmjZtqnHjxtXar2C/7/h8Pt13331q166dkpOTdfnll+u9996rtf/SydvZJ0+erMzMTCUmJqpr16763e9+J5/PZ7R/AIDYEev5ee/evfr3v/+tG264QTfccIN2796tDRs2nP7AhKB6n9544w3dfvvtat26tZo3b65bbrlFHo9HR48e1ejRo9WiRQu1aNFCd999d60+hoceekiDBw9Wq1atlJSUpH79+unvf/97rbpOnDih22+/XWlpaWrWrJlGjhyp/fv313n8w9lHAZyNuBIdUaFDhw7auHGjduzYoV69ep2y7OOPP64LLrhAI0eOVFxcnP75z3/q5z//uXw+nyZNmhRQdteuXfrRj36kW265RT/5yU/00EMP6eqrr9aiRYs0bdo0/fznP5ckFRQU6Ic//KF27twpp7PmtyWv16vhw4frkksu0Zw5c1RYWKiZM2eqqqpKs2bNqreNxcXFuuSSS/xjpLZu3Vr/+te/NH78eJWWlmry5Mm2jtNTTz0lj8ej2267TUeOHNGcOXP0wx/+UFdccYXWrVunX/7yl9q1a5ceffRR3XXXXQEJcdmyZWratKny8/PVtGlTvfrqq5oxY4ZKS0v14IMPBhzfvLw8XXrppbrzzju1Z88e5ebmqkWLFjr33HP95Xw+n0aOHKk33nhDEydOVI8ePfTOO+/o4Ycf1ocffqjVq1fb2kcAQGz65z//qc6dO2vw4MFBlf/pT3+qJ554Qtddd51+8YtfaPPmzSooKND777+vZ555xnY7brvtNrVo0UIzZ87Unj17NH/+fOXl5WnlypWSpPnz5+u2225T06ZN9atf/UqSlJ6ebquugoICJSUl6Z577vHn5/j4eDmdTn355Ze67777tGnTJi1btkydOnXSjBkz/LHBft+ZOnWq5syZo6uvvlo5OTn673//q5ycHJWXlwe05fjx4xo6dKj279+vW265Re3bt9eGDRs0depUff7555o/f76tfQQAnNliPT//9a9/VZMmTfS9731PSUlJ6tKli5566qmg9zcUt912mzIyMnT//fdr06ZNWrx4sZo3b64NGzaoffv2+s1vfqMXX3xRDz74oHr16qXRo0f7YxcsWKCRI0fqxz/+sTwej1asWKFRo0bp+eef14gRI/zlxo4dq7/97W+66aabdMkll2j9+vUBj1drqD4K4KxiAVHg5Zdftlwul+VyuaysrCzr7rvvtl566SXL4/HUKnv8+PFa63JycqzOnTsHrOvQoYMlydqwYYN/3UsvvWRJspKSkqxPP/3Uv/4Pf/iDJcl67bXX/OvGjBljSbJuu+02/zqfz2eNGDHCSkhIsA4dOuRfL8maOXOm/+/x48dbbdu2tQ4fPhzQphtuuMFKTU2tcx++2fYRI0b4/969e7clyWrdurV19OhR//qpU6dakqw+ffpYlZWV/vU33nijlZCQYJWXl/vX1VXnLbfcYiUnJ/vLVVRUWK1atbIGDBgQsL1ly5ZZkqyhQ4f61/2///f/LKfTaf373/8O2OaiRYssSdb//d//nXIfAQBnj5KSEkuSdc011wRVfvv27ZYk66c//WnA+rvuusuSZL366qv+dd/MwdU6dOhgjRkzxv/30qVLLUlWdna25fP5/OvvvPNOy+VyBeTXCy64ICDnnY4ka9KkSf6/X3vtNUuS1atXr4DvMjfeeKPlcDisq666KiA+KyvL6tChQ8C6YL7vFBUVWXFxcVZubm5Aufvuu8+SFLD/s2fPtpo0aWJ9+OGHAWXvuecey+VyWXv37g16fwEAsSHW87NlWVbv3r2tH//4x/6/p02bZqWlpQWc71rWyfP/b+bi+vbh66rP1R988MFa+5STkxOwT1lZWZbD4bB+9rOf+ddVVVVZ5557bq39+ub3AI/HY/Xq1cu64oor/Ou2bt1qSbImT54cUHbs2LFh76MAYFkM54Ko8J3vfEcbN27UyJEj9d///ldz5sxRTk6OzjnnHD333HMBZZOSkvz/X1JSosOHD2vo0KH65JNPVFJSElC2Z8+eysrK8v89aNAgSdIVV1yh9u3b11r/ySef1GpbXl6e//+rf7X1eDx65ZVX6twXy7L0j3/8Q1dffbUsy9Lhw4f9S05OjkpKSrRt27ZgD02AUaNGKTU1tVa7f/KTnyguLi5gvcfj0f79+/3rvn7cvvrqKx0+fFiXXnqpjh8/rg8++ECS9Oabb+qLL77QhAkTArb34x//WC1atAhoy6pVq9SjRw917949YB+vuOIKSdJrr71max8BALGntLRUktSsWbOgyr/44ouSpPz8/ID1v/jFLyQppLFZJ06cKIfD4f/70ksvldfr1aeffmp7m/UZPXq04uPj/X8PGjRIlmXp5ptvDig3aNAg7du3T1VVVf51wXzfWbt2raqqqvx31lWra0L2VatW6dJLL1WLFi0C8nZ2dra8Xq9ef/31sOwzAODMEev5+e2339Y777yjG2+80b/uxhtv1OHDh/XSSy/Z3m6wxo8fH7BP1d8Dxo8f71/ncrnUv3//Wn0RX/8e8OWXX6qkpESXXnppQF9CYWGhJJ32e0BD9lEAZxOGc0HUGDBggJ5++ml5PB7997//1TPPPKOHH35Y1113nbZv366ePXtKkv7v//5PM2fO1MaNG3X8+PGAbZSUlAR0Mn+9o1yS/7HMzMw613/55ZcB651Opzp37hyw7rzzzpN0cpzyuhw6dEhHjx7V4sWL653B3O5kqaHsz7vvvqvp06fr1Vdf9X9ZqlZ9Ml79BaVr164Bj8fFxaljx44B6z766CO9//77at26dZ1tZUJYAEC1lJQUSSd/xA3Gp59+KqfTWSsfZWRkqHnz5iGdUH8zl1b/SPzN7wDhYJK3fT6fSkpK1KpVK0nBfd+pL2+3bNmy1o/fH330kd5++23yNgDAL9bz81/+8hc1adJEnTt31q5duyRJbrdbHTt21FNPPVXnsCfhZPI94Jv7+fzzz+uBBx7Q9u3bA8ab/3qnfPXz0alTp4DYbz4/DdlHAZxN6ERH1ElISNCAAQM0YMAAnXfeeRo3bpxWrVqlmTNn6uOPP9a3v/1tde/eXfPmzVNmZqYSEhL04osv6uGHH641MZbL5aqzjvrWW0FMGHo61W34yU9+ojFjxtRZ5sILL7S1bbv7c/ToUQ0dOlQpKSmaNWuWunTpIrfbrW3btumXv/ylrQnFfD6fevfurXnz5tX5+De/GAAAzl4pKSlq166dduzYYRT39RNFU3VNnC017HeAYOs6XRtMv+8Ew+fz6Tvf+Y7uvvvuOh+vvkgAAHD2iOX8bFmW/vrXv6qsrMx/Qd7XHTx4UMeOHVPTpk1tbT8YJt8Dvr6f//73vzVy5Ehddtll+v3vf6+2bdsqPj5eS5cu1fLly43b0ZB9FMDZhE50RLX+/ftLkj7//HNJJyc9qaio0HPPPRfwq25DDR3i8/n0ySefBJxYfvjhh5JU68rsaq1bt1azZs3k9XqVnZ3dIO0ytW7dOn3xxRd6+umnddlll/nX7969O6Bchw4dJJ2ckPXyyy/3r6+qqtKePXsCEmuXLl303//+V9/+9rdD+hIFADg7fO9739PixYu1cePGgKHW6tKhQwf5fD599NFH6tGjh399cXGxjh496s9X0skr1Y4ePRoQ7/F4/N8d7Ih0Xgv2+87X8/bXr0L74osval3R1qVLFx07dixqvpsAAKJDrObn9evX67PPPtOsWbMC2iqdvLp94sSJWr16tX7yk5/Ybk9D+cc//iG3262XXnpJiYmJ/vVLly4NKFf9fOzevVvdunXzr6++6r5aNPZRAGcixkRHVHjttdfq/IW5esy1888/X1LNL7ZfL1tSUlIrmYTTY4895v9/y7L02GOPKT4+Xt/+9rfrLO9yuXTttdfqH//4R52/6B86dKjB2lqfuo6bx+PR73//+4By/fv3V6tWrfTHP/4xYFzWp556qtbJ+A9/+EPt379ff/zjH2vVd+LECZWVlYVzFwAAZ7i7775bTZo00U9/+lMVFxfXevzjjz/WggULJEnf/e53JUnz588PKFN999PXb7/u0qVLrfG8Fy9eXO+VbsFo0qRJrRP/xhTs951vf/vbiouL0+OPPx6w/uvfXar98Ic/1MaNG+scA/bo0aMBeR8AcPaI1fxcPZTLlClTdN111wUsEyZMULdu3fTUU0/ZbktDcrlccjgcAcdqz549Wr16dUC5nJwcSap1Xv/oo4/W2l609VEAZyKuREdUuO2223T8+HF9//vfV/fu3eXxeLRhwwatXLlSHTt21Lhx4yRJV155pRISEnT11Vfrlltu0bFjx/THP/5Rbdq0CekX7fq43W4VFhZqzJgxGjRokP71r3/phRde0LRp0+odU1SSfvvb3+q1117ToEGDNGHCBPXs2VNHjhzRtm3b9Morr+jIkSNhb+upDB48WC1atNCYMWN0++23y+Fw6P/9v/9X64eLhIQE3Xfffbrtttt0xRVX6Ic//KH27NmjZcuWqUuXLgG//N90003629/+pp/97Gd67bXX9K1vfUter1cffPCB/va3v+mll17y30kAAECXLl20fPlyXX/99erRo4dGjx6tXr16+XP+qlWrNHbsWElSnz59NGbMGC1evNg/JNmWLVv0xBNPKDc3N+BuqZ/+9Kf62c9+pmuvvVbf+c539N///lcvvfSS0tLSbLe1X79+evzxx/XAAw+oa9euatOmjX/i7MYQ7Ped9PR03XHHHZo7d65Gjhyp4cOH67///a/+9a9/KS0tLSBvT5kyRc8995y+973vaezYserXr5/Kysr0zjvv6O9//7v27NkT0jEDAJyZYjE/V1RU6B//+Ie+853vyO1217mtkSNHasGCBTp48KDatGlju00NYcSIEZo3b56GDx+uH/3oRzp48KAWLlyorl276u233/aX69evn6699lrNnz9fX3zxhS655BKtX7/ef/f8178HRFsfBXAmohMdUeGhhx7SqlWr9OKLL2rx4sXyeDxq3769fv7zn2v69Olq3ry5pJNXpP/973/X9OnTdddddykjI0O33nqrWrdurZtvvjns7XK5XCosLNStt96qKVOmqFmzZpo5c6ZmzJhxyrj09HRt2bJFs2bN0tNPP63f//73atWqlS644AL97ne/C3s7T6dVq1Z6/vnn9Ytf/ELTp09XixYt9JOf/ETf/va3/b9eV8vLy5NlWZo7d67uuusu9enTR88995xuv/32gC8gTqdTq1ev1sMPP6wnn3xSzzzzjJKTk9W5c2fdcccdjK0KAKhl5MiRevvtt/Xggw/q2Wef1eOPP67ExERdeOGFmjt3riZMmOAv+6c//UmdO3fWsmXL9MwzzygjI0NTp07VzJkzA7Y5YcIE7d69W3/+859VWFioSy+9VGvWrKn3jrFgzJgxQ59++qnmzJmjr776SkOHDm3UTnST7zu/+93vlJycrD/+8Y965ZVXlJWVpZdffllDhgwJyNvJyclav369fvOb32jVqlV68sknlZKSovPOO0/3339/wMTsAICzS6zl5xdeeEFHjx7V1VdfXe+2rr76as2dO1crVqzQ7bffbrtNDeGKK67Qn//8Z/32t7/V5MmT1alTJ/3ud7/Tnj17AjrRJenJJ59URkaG/vrXv+qZZ55Rdna2Vq5cqfPPPz/ge0C09VEAZyKH1RCzKAExYOzYsfr73/+uY8eORbopEefz+dS6dWv94Ac/qHP4FgAAED2OHj2qFi1a6IEHHtCvfvWrSDcHAAA0ou3bt+uiiy7SX/7yF/34xz+OdHOAmMGY6AAClJeX1xrm5cknn9SRI0c0bNiwyDQKAADU6cSJE7XWVY9VS94GACC21fc9wOl06rLLLotAi4DYxXAuAAJs2rRJd955p0aNGqVWrVpp27Zt+vOf/6xevXpp1KhRkW4eAAD4mpUrV2rZsmX67ne/q6ZNm+qNN97QX//6V1155ZX61re+FenmAQCABjRnzhxt3bpVl19+ueLi4vSvf/1L//rXvzRx4kRlZmZGunlATKETHUCAjh07KjMzU4888oiOHDmili1bavTo0frtb3+rhISESDcPAAB8zYUXXqi4uDjNmTNHpaWl/slGH3jggUg3DQAANLDBgwdrzZo1mj17to4dO6b27dvrvvvuYzg3oAEwJjoAAAAAAAAAAPVgTHQAAAAAAAAAAOrBcC4AgIgrLy+Xx+MJy7YSEhLkdrvDsi0AAGCGnA4AQGwgpweKuk50n8+nAwcOqFmzZnI4HJFuDgDgNCzL0ldffaV27drJ6TS/wam8vFydOjRV0UFvWNqTkZGh3bt3n/EJOhaQ0wHgzEJOR33I6QBwZiGnh1/UdaIfOHCAGYQB4Ay0b98+nXvuucZxHo9HRQe92r21g1KahTbKWOlXPnXq96k8Hs8ZnZxjBTkdAM5M5HR8EzkdAM5M5PTwibpO9GbNmkmSOi++U67kxKDjzh3/iXFdjvM7Gcd4k2wcMhtTtzq27DAPkrTrsYvMgyrN3wxd87cZx1gDLzCOscNVZn6rieOzIuOYA4+3NY6xNjQ3jpGkdsveNY6p6tPZvCKfeUjCZ18Yx1RmtDCO8UwrNY6xFrU2jmm6/TPjGE/ndOMYSbZmpYh/d69xzKGR5xnHOK8O/nn1Hq/QO6MX+j+/7Upp5gw5OSO6VL8mPt3WUSlNg39u+y/9aUM1CRGUWbDZOGbf1EEN0BJE2i+ue9o4Zu7ff9AALcE3+SrKtXveLHI6aql+TVyWdK3iHPFBxzntvJbcCcYh3pahvWaD5Yt32YpzWDY6Bezwmddjuczfqw6v+Ymjo8pG2+LM73qwtT+N9fxIsuzcyWEjxOmxcfWwjXrsHG9bbLy25bR314yd5yjui2PmFX1xxDjEezT4fpEqVeoNvUhOD6MG60RfuHChHnzwQRUVFalPnz569NFHNXDgwNPGVd8a5kpONOpEN0nk/rpcwW/fHxNnXo+tTnQb+yNJziQbv+jEmb8Z7BxvK65xfm1yucw/8BwO8y9qJq/PalaivWMQZ6N9snO8bXSixzltHAcbbfM1qTCvJ968njin+bH22X1t28hDdl4LrgTz9jltvL5DvbXXa/nkDfH7q9ey8SLGaYWa01Oamn3xcp3BVyegfna+O/BaiE1JTc1PQXgtNC5yemyym8+lmtdEnCPe6Puo08Z3a9k4v7Bzbm+HL85eF0rMdaI7bHSi23hPWzb6KuhEP8nprbJRj40fLWw8R7ZEeye6q9K8Ihvn9kZ9hVZ1DDk9XBrk1b5y5Url5+dr5syZ2rZtm/r06aOcnBwdPHiwIaoDAMQAn6ywLAgvcjoAwBQ5PfqQzwEAdpDTazRIJ/q8efM0YcIEjRs3Tj179tSiRYuUnJysJUuWNER1AACggZDTAQA485HPAQAITdg70T0ej7Zu3ars7OyaSpxOZWdna+PGjeGuDgAQI3xh+g/hQ04HANhBTo8u5HMAgF3k9BphHxP98OHD8nq9Sk8PnGgvPT1dH3zwQa3yFRUVqqioGeu4tNR88kAAwJnPa1nyhjgeYajxCEROBwDYQU6PLqb5XCKnAwBOIqfXiPj0qgUFBUpNTfUvmZmZkW4SAACwgZwOAEBsIKcDABAo7J3oaWlpcrlcKi4uDlhfXFysjIyMWuWnTp2qkpIS/7Jv375wNwkAcAZgwpLoQ04HANhBTo8upvlcIqcDAE4ip9cIeyd6QkKC+vXrp7Vr1/rX+Xw+rV27VllZWbXKJyYmKiUlJWABAJx9fLLkDXGJleQcLcjpAAA7yOnRxTSfS+R0AMBJ5PQaYR8TXZLy8/M1ZswY9e/fXwMHDtT8+fNVVlamcePGNUR1AACggZDTAQA485HPAQAITYN0ol9//fU6dOiQZsyYoaKiIvXt21eFhYW1JjIBAKBaOG7zipVfuKMJOR0AYIqcHn3I5wAAO8jpNRqkE12S8vLylJeXZzu+efIJxTXxBV3emeQ2rsPyBb/9miAbIXHmo+Y4ExPNK5KU8Hm8cUzbQZ8bx7jatDaOUUm5cUhVqvnzWtUiyTgm7sOK0xf6hsr/tDCOyfzuXuMYSXI+3dI4Jr7oK+OYqlZNjGM8HdOMY+K27TKOOfJSb+OY9nftNo7x3drMOCa+qMQ4RpKqWpvXVXlhR+OYNn9/zzjm88QLgi7r9Zi/t+vcDrN+R61Qc3r/pT+Vy23+eY7Ysve+wZFuAqJEwYofRroJaGDk9OgUaj6XJGfzVDmdwZ+rWqlNjevwJScYx1S0apzvGd4kmyPi2ng5O2x0V9hhuewEmYfEnTDfIV+cwzwmwTzGbv+enefIsvMSsrFLzkrz95HDa16PndePnee10Y61TW4bz5GdDlmXL/gXq2V5pFIblXwDOb1Gg3WiAwBgwve/JdRtAACAyCKnAwAQG8jpNRrxdxkAAAAAAAAAAM4sXIkOAIgK1TN3h7oNAAAQWeR0AABiAzm9Bp3oAICo4LVOLqFuAwAARBY5HQCA2EBOr8FwLgAAAAAAAAAA1IMr0QEAUYEJSwAAiA3kdAAAYgM5vQad6ACAqOCTQ145Qt4GAACILHI6AACxgZxeg+FcAAAAAAAAAACoB1eiAwCigs86uYS6DQAAEFnkdAAAYgM5vQad6ACAqOANw21iocYDAIDQkdMBAIgN5PQaDOcCAIgK1ck51AUAAEQWOR0AgNgQqZy+cOFCdezYUW63W4MGDdKWLVvqLfvuu+/q2muvVceOHeVwODR//vxaZQoKCjRgwAA1a9ZMbdq0UW5urnbu3GnUJjrRAQAAAAAAAAARt3LlSuXn52vmzJnatm2b+vTpo5ycHB08eLDO8sePH1fnzp3129/+VhkZGXWWWb9+vSZNmqRNmzZpzZo1qqys1JVXXqmysrKg2xU7w7kkJhqHOCq95vXYuSDCxk8VzqZNbFQktXzffKChjCtKjWP2DjvPOKb52o+MY6y09sYxjkqfeUyHc41jOi35xDimbKjbOEaSPppc94fAqXSbvNm8oqwLjUMcHvPj7e3V2Tim7byNxjHvdRpoHNPu4UPGMSk/PmocI0lxcS7jmKoWycYxlX1sHO8VHwRdtsrn0bvGNdTmsxzyWSHO+h1iPAAACB05PXZZTZJluYI/965qnmRcR1XTeOOY8pbmXRtOG90BnqaN97p0mJ9m2WI10qWVcSdsVGTjcFclmgfZPQaN9RzZOQ4OG69vp9fGwNV2QlzmO+QzP3W2138n2donh9dGn2SV+QsorrIq+O37KiTz7r5aIpHT582bpwkTJmjcuHGSpEWLFumFF17QkiVLdM8999QqP2DAAA0YMECS6nxckgoLCwP+XrZsmdq0aaOtW7fqsssuC6pdsdOJDgA4ozHWGgAAsYGcDgBAbGjsnO7xeLR161ZNnTrVv87pdCo7O1sbN5pfXFmfkpISSVLLli2DjqETHQAAAAAAAADQYEpLAy+NT0xMVOI3RhY5fPiwvF6v0tPTA9anp6frgw+Cv2P+VHw+nyZPnqxvfetb6tWrV9BxdKIDAKKCV055Q5yqw8ZdiwAAIMzI6QAAxIZw5vTMzMyA9TNnztR9990X0rbtmDRpknbs2KE33njDKI5OdABAVLDCMNaaxfipAABEHDkdAIDYEM6cvm/fPqWkpPjXf/MqdElKS0uTy+VScXFxwPri4uJ6Jw01kZeXp+eff16vv/66zj3XbH7ERppCAgAAAAAAAABwNkpJSQlY6upET0hIUL9+/bR27Vr/Op/Pp7Vr1yorK8t23ZZlKS8vT88884xeffVVderUyXgbXIkOAIgKTEIGAEBsIKcDABAbIpHT8/PzNWbMGPXv318DBw7U/PnzVVZWpnHjxkmSRo8erXPOOUcFBQWSTk5G+t577/n/f//+/dq+fbuaNm2qrl27Sjo5hMvy5cv17LPPqlmzZioqKpIkpaamKikpKah20YkOAIgKXssprxXiWGtWmBoDAABsI6cDABAbIpHTr7/+eh06dEgzZsxQUVGR+vbtq8LCQv9ko3v37pXTWdOmAwcO6KKLLvL//dBDD+mhhx7S0KFDtW7dOknS448/LkkaNmxYQF1Lly7V2LFjg2oXnegAAAAAAAAAgKiQl5envLy8Oh+r7hiv1rFjR1nWqXvqT/d4MOhEBwBEBZ8c8oU4VYdPXLYGAECkkdMBAIgN5PQadKIDAKIC46cCABAbyOkAAMQGcnoNOtEBAFEhPGOtxcYv3AAAnMnI6QAAxAZyeo3QjgIAAGe4hQsXqmPHjnK73Ro0aJC2bNlyyvKrVq1S9+7d5Xa71bt3b7344osBj1uWpRkzZqht27ZKSkpSdna2Pvroo4AyI0eOVPv27eV2u9W2bVvddNNNOnDggP/xPXv2yOFw1Fo2bdoUvh0HAAAAAABBidor0Y9VJMrlSgy6fGpcuXklFZXGIZbLxu8OPvMQR3KyeZCkFv85aBzz4RetjWOO9TW/FaPZ344YxzhPtDOOseLMn6OqtKbGMa5PPzOOKX3motMXqkP7739uHFM+YoBxTJONu4xjKnt1MI5xVJn/Cum8sLtxTLfbTt0ZWpcP/9jPOObgY82MYySpy0/Nj3ecr61xjJ3Xt8nzWlVVLr1hXEUtJ8daC+02L9P4lStXKj8/X4sWLdKgQYM0f/585eTkaOfOnWrTpk2t8hs2bNCNN96ogoICfe9739Py5cuVm5urbdu2qVevXpKkOXPm6JFHHtETTzyhTp066d5771VOTo7ee+89ud1uSdLll1+uadOmqW3bttq/f7/uuusuXXfdddqwYUNAfa+88oouuOAC/9+tWrUyPSQAADS6SOR0NA5fils+lzvo8p7UBOM6Kpuan89VpJq/Xpzm3QHy2KhHkiwbPS8Or52KbIS4bNRj4zDElZkHObzmO+RLMK/Ha/4yjXoOO/1QXhvvIzuvUxt8Nl6nvvjwt6M+Tq95A51VwX+WVnNUBv/Eer0J0qfGVdRCTq/BlegAgKjgk1PeEBfTCU/mzZunCRMmaNy4cerZs6cWLVqk5ORkLVmypM7yCxYs0PDhwzVlyhT16NFDs2fP1sUXX6zHHntM0smr0OfPn6/p06frmmuu0YUXXqgnn3xSBw4c0OrVq/3bufPOO3XJJZeoQ4cOGjx4sO655x5t2rRJlZWBZ3OtWrVSRkaGf4mPb8RvggAA2BSJnA4AAMKPnF4jNvYCAICvKS0tDVgqKipqlfF4PNq6dauys7P965xOp7Kzs7Vx48Y6t7tx48aA8pKUk5PjL797924VFRUFlElNTdWgQYPq3eaRI0f01FNPafDgwbU6yUeOHKk2bdpoyJAheu6554LbeQAAAAAAEFZ0ogMAokL1hCWhLpKUmZmp1NRU/1JQUFCrvsOHD8vr9So9PT1gfXp6uoqKiupsY1FR0SnLV/8bzDZ/+ctfqkmTJmrVqpX27t2rZ5991v9Y06ZNNXfuXK1atUovvPCChgwZotzcXDrSAQBnhHDmdAAAEDnk9BpROyY6AODs4gvDbV6+/w0EuW/fPqWkpPjXJyYGP8dGY5kyZYrGjx+vTz/9VPfff79Gjx6t559/Xg6HQ2lpacrPz/eXHTBggA4cOKAHH3xQI0eOjGCrAQA4vXDmdAAAEDnk9Bp0ogMAYk5KSkpAJ3pd0tLS5HK5VFxcHLC+uLhYGRkZdcZkZGScsnz1v8XFxWrbtm1Amb59+9aqPy0tTeedd5569OihzMxMbdq0SVlZWXXWPWjQIK1Zs+aU+wQAAAAAAMIvNq6nBwCc8byWIyxLsBISEtSvXz+tXbvWv87n82nt2rX1dmRnZWUFlJekNWvW+Mt36tRJGRkZAWVKS0u1efPmerdZXa+kOsdur7Z9+/aAjnkAAKJVY+d0AADQMMjpNbgSHQAQFapn7g5tG2a3ieXn52vMmDHq37+/Bg4cqPnz56usrEzjxo2TJI0ePVrnnHOOf0z1O+64Q0OHDtXcuXM1YsQIrVixQm+++aYWL14sSXI4HJo8ebIeeOABdevWTZ06ddK9996rdu3aKTc3V5K0efNm/ec//9GQIUPUokULffzxx7r33nvVpUsXf0f7E088oYSEBF100UWSpKefflpLlizRn/70p5CODwAAjSESOR0AAIQfOb0GnegAgLPW9ddfr0OHDmnGjBkqKipS3759VVhY6J8YdO/evXI6a74wDB48WMuXL9f06dM1bdo0devWTatXr1avXr38Ze6++26VlZVp4sSJOnr0qIYMGaLCwkK53W5JUnJysp5++mnNnDlTZWVlatu2rYYPH67p06cHjN0+e/Zsffrpp4qLi1P37t21cuVKXXfddY10ZAAAAAAAQDU60QEAUcFnOeULcdZun2X+C3deXp7y8vLqfGzdunW11o0aNUqjRo2qd3sOh0OzZs3SrFmz6ny8d+/eevXVV0/ZpjFjxmjMmDGnLAMAQLSKVE4HAADhRU6vQSc6ACAqcJsYAACxgZwOAEBsIKfXoBMdABAVfFLIE474wtMUAAAQAnI6AACxgZxeI7SfEgAAAAAAAAAAiGFReyX6V18ky3ncbRBRYl6Jp9I8ppF+drCSTfa9hvfDj41jvnrvEuOYqhZe4xhXm9bGMY7PvzSO8XQ2r8cOR/tzjGPa/PE/tura1aW/cYx3hPlvfT3+z/wWm4Q9h41jPB3TjGOqmpu/J+K7djKOOX/SO8YxHxVcZBwjSTt/1+v0hb6h+7T3jWPibXzWedq3NI4JlU9O+UL8kA01HgAAhI6cjsbmrDKPcXls1GOjC0GSvC7zGMtGjJ0RE2wNdWzjolQ79dh5jhwVdoaNsHeVrS/ePMbW82pDiBcOB1+PjcPtsPN+9ZpX5PTaOwjeBBtBsTFaSZ3I6TWithMdAHB28VpOeUOcsCTUeAAAEDpyOgAAsYGcXiM29gIAAAAAAAAAgAbAlegAgKjgk0M+m7dSfn0bAAAgssjpAADEBnJ6Da5EBwBEherbxEJdAABAZDV2Ti8oKNCAAQPUrFkztWnTRrm5udq5c2dAmfLyck2aNEmtWrVS06ZNde2116q4uDjcuw4AQEzhPL1GbOwFAAAAAOCstH79ek2aNEmbNm3SmjVrVFlZqSuvvFJlZWX+Mnfeeaf++c9/atWqVVq/fr0OHDigH/zgBxFsNQAAOJMwnAsAICp45ZQ3xN92Q40HAACha+ycXlhYGPD3smXL1KZNG23dulWXXXaZSkpK9Oc//1nLly/XFVdcIUlaunSpevTooU2bNumSSy4Jqa0AAMQqztNr0IkOAIgKPsshnxXiWGshxgMAgNBFOqeXlJRIklq2bClJ2rp1qyorK5Wdne0v0717d7Vv314bN26kEx0AgHpEOqdHEzrRAQBRwReGX7h9MfILNwAAZ7Jw5vTS0tKA9YmJiUpMTKw/zufT5MmT9a1vfUu9evWSJBUVFSkhIUHNmzcPKJuenq6ioqKQ2gkAQCzjPL1GbOwFAAAAACDmZGZmKjU11b8UFBScsvykSZO0Y8cOrVixopFaCAAAzgZciQ4AiAo+yylfiLN2hxoPAABCF86cvm/fPqWkpPjXn+oq9Ly8PD3//PN6/fXXde655/rXZ2RkyOPx6OjRowFXoxcXFysjIyOkdgIAEMs4T69BJzoAICp45ZBXoY2VFmo8AAAIXThzekpKSkAnel0sy9Jtt92mZ555RuvWrVOnTp0CHu/Xr5/i4+O1du1aXXvttZKknTt3au/evcrKygqpnQAAxDLO02vQiQ4AAAAAOGNNmjRJy5cv17PPPqtmzZr5xzlPTU1VUlKSUlNTNX78eOXn56tly5ZKSUnRbbfdpqysLCYVBQAAQaETHQAQFbhNDACA2NDYOf3xxx+XJA0bNixg/dKlSzV27FhJ0sMPPyyn06lrr71WFRUVysnJ0e9///uQ2ggAQKzjPL1G1Haiu0ri5KwwaF5CvHEdVulXxjHOCq9xjC/eZRyjOBsxNqW9bRnHFF1qXk/ZgI7GMUmF24xj4lo2M46pSnEbx3ibJxvHuJLNYySp2/8rMY7ZeXOqccxnN/cwjmk7b6NxTILT/AO0sl0L45iqNqe+9bcu8ScqjGO6TX3LOEaSPv1lP+OYD2f0NI45/9H9xjHxOz4NuqzD5zHefl28Cv02L/NPaAAAEG6NndMt6/TnM263WwsXLtTChQvtNwryJsXJERf8ebov0fx14LUR47PRs+Gy8RXWbj+Qz7y7Qr4EGzEu83N7q5F6hSyHnc8E8xiHjRMCy+bHlWWj28Zr53lNsPG82nitOnzmMU6P+cFzmZ9y26rHYX7Y/hdoHmLntWDr8yTOIMjWe642ztNrxMZPAQAAAAAAAAAANICovRIdAHB24TYxAABiAzkdAIDYQE6vEfa9uO++++RwOAKW7t27h7saAECM8VrOsCwIH3I6AMAOcnr0IacDAOwgp9dokCvRL7jgAr3yyis1lRiMmQYAAKIHOR0AgNhATgcAwL4GyZpxcXHKyMhoiE0DAGKUJYd8IU5YYoUYj9rI6QAAU+T06EROBwCYIqfXaJBO9I8++kjt2rWT2+1WVlaWCgoK1L59+zrLVlRUqKKiZmre0tLShmgSACDKheM2r1i5TSyakNMBAKbI6dGJnA4AMEVOrxH2vRg0aJCWLVumwsJCPf7449q9e7cuvfRSffXVV3WWLygoUGpqqn/JzMwMd5MAAGcAn+UIy4LwIacDAOwgp0cfcjoAwA5yeo2wd6JfddVVGjVqlC688ELl5OToxRdf1NGjR/W3v/2tzvJTp05VSUmJf9m3b1+4mwQAAGwgpwMAEBvI6QAAhKbBZxJp3ry5zjvvPO3atavOxxMTE5WYmNjQzQAARDmvnPKG+NtuqPE4NXI6ACAY5PToR04HAASDnF6jwffi2LFj+vjjj9W2bduGrgoAcAbjNrHoR04HAASDnB79yOkAgGCQ02uEvRP9rrvu0vr167Vnzx5t2LBB3//+9+VyuXTjjTeGuyoAANCAyOkAAMQGcjoAAKEJ+3Aun332mW688UZ98cUXat26tYYMGaJNmzapdevW4a4KABBDfHLKF+Jvu6HGIxA5HQBgBzk9+pDTAQB2kNNrhL0TfcWKFWHZjuU8uQSrqnWKcR2OffuNY1yH6569/FScTdzGMY7j5cYxJwPNX5hNDnjMq/EkGMccvNi8bZ3+09I4RrvNn9f4c9KNY6wE87ePo0mycYwkef/7vnFM2rYs45hDl1QZx8T97BLjmNZ/2GJez/ETxjFWuvnrx0ptahzjLDtuHCNJnebvMI7Ze2sv45j3p7QzjskstIIuW1VZLhUaV1GL13LIG+JtXqHGI1C4cjoA4OxCTo8+4crpJ1olKC4++HPB8hbm54AVzc2f+8pmxiGKP2Ye40kJ/jvy11U1M4/zuX3mFSV6jUNcCeb1OBzm+3O81LwPIf6oyzjGad69YdT39HU+812S18bzaiXZeI4SzF8LsvG5a1WaHzxHuXmM64SNemwcgpOBjRPk8Jr3KTmrgp+roqrK3ufVN5HTa8TGTwEAAAAAAAAAADSAsF+JDgCAHeGYcCRWJiwBAOBMRk4HACA2kNNr0IkOAIgKluWUz+69lF/bBgAAiCxyOgAAsYGcXoNOdABAVPDKIa+9AegCtgEAACKLnA4AQGwgp9eIjZ8CAAAAAAAAAABoAFyJDgCICj4r9LHSfOGZgBwAAISAnA4AQGwgp9egEx0AEBV8YRhrLdR4AAAQOnI6AACxgZxeIzb2AgAAAAAAAACABsCV6ACAqOCTQ74QJxwJNR4AAISOnA4AQGwgp9egEx0AEBW8lkPeEMdaCzUeAACEjpwOAEBsIKfXYDgXAAAAAAAAAADqQSc6ACAqVE9YEupiauHCherYsaPcbrcGDRqkLVu2nLL8qlWr1L17d7ndbvXu3VsvvvhiwOOWZWnGjBlq27atkpKSlJ2drY8++iigzMiRI9W+fXu53W61bdtWN910kw4cOBBQ5u2339all14qt9utzMxMzZkzx3jfAACIhEjldAAAEF5nwnn6u+++q2uvvVYdO3aUw+HQ/PnzQ95mXaJ2OJfEzGNyJVcGXf7ggFTjOjLeTzKO8e07cPpC3+BMTjavp6rKOOZkoNc4pLKp+cvASgn+uamW1OmYccynlV2NYzou+8Q4xvvRbuMYZ7NmxjGW1/z5sav5R8eNYw5dkmgcE/e9w8Yxu9sPNI7puuyQcYzvnZ3GMa7UFOMYu7xffWUck/nCEeOYXT9pYRxz4tbgn1fv8Qqp0LiKWnxyyBfibV6mY62tXLlS+fn5WrRokQYNGqT58+crJydHO3fuVJs2bWqV37Bhg2688UYVFBToe9/7npYvX67c3Fxt27ZNvXr1kiTNmTNHjzzyiJ544gl16tRJ9957r3JycvTee+/J7XZLki6//HJNmzZNbdu21f79+3XXXXfpuuuu04YNGyRJpaWluvLKK5Wdna1FixbpnXfe0c0336zmzZtr4sSJIR0jAAAaWiRyOhrHiTSnXAnBd4acaGP+PFa0Nj9ncrWqMK/nq3jzepraO09PbWZ+bpaaVG4c0yTeYxzTNN782CU4zY/D58fN+2w+O9LcOKbSY96/4XBYxjGSlJBo3i+SbCMmxW3+WmiRaP6as6PEY96vVlLuNo45XpFgHFNZ6TKOkSSn0/z1UJbYxDjGF2/esWw5g//c8nrC0/90JpynHz9+XJ07d9aoUaN05513hmWbdeHnfQDAWWvevHmaMGGCxo0bp549e2rRokVKTk7WkiVL6iy/YMECDR8+XFOmTFGPHj00e/ZsXXzxxXrssccknbwKff78+Zo+fbquueYaXXjhhXryySd14MABrV692r+dO++8U5dccok6dOigwYMH65577tGmTZtUWXnyS/VTTz0lj8ejJUuW6IILLtANN9yg22+/XfPmzWvwYwIAAAAAQKSYnqcPGDBADz74oG644QYlJtZ9cajpNutCJzoAICpY/5v1O5TFMviF2+PxaOvWrcrOzvavczqdys7O1saNG+uM2bhxY0B5ScrJyfGX3717t4qKigLKpKamatCgQfVu88iRI3rqqac0ePBgxcfH++u57LLLlJBQc8VF9a/kX375ZdD7CABAJDR2TgcAAA0jnDm9tLQ0YKmoqH0njJ3z9NMJ1zbpRAcARAWf5QjLIgWXnA8fPiyv16v09PSA9enp6SoqKqqzjUVFRacsX/1vMNv85S9/qSZNmqhVq1bau3evnn322dPW8/U6AACIVuHM6QAAIHLCmdMzMzOVmprqXwoKCmrVZ+c8/XTCtU060QEAUSGcE5YEk5wjbcqUKXrrrbf08ssvy+VyafTo0bIse+MxAgAQTZhYFACA2BDOnL5v3z6VlJT4l6lTp0Z478xE7cSiAADYtW/fPqWk1EwSW9e4aGlpaXK5XCouLg5YX1xcrIyMjDq3m5GRccry1f8WFxerbdu2AWX69u1bq/60tDSdd9556tGjhzIzM7Vp0yZlZWXVW8/X6wAAAAAA4EyRkpIScJ5eFzvn6acTrm3y8z4AICqE8zax6uRcvdTViZ6QkKB+/fpp7dq1NW3w+bR27VplZWXV2casrKyA8pK0Zs0af/lOnTopIyMjoExpaak2b95c7zar65XkH3YmKytLr7/+un+i0ep6zj//fLVo0eKUxxEAgEhjOBcAAGJDY+d0O+fpjbVNrkQHAESF6klHQt2Gifz8fI0ZM0b9+/fXwIEDNX/+fJWVlWncuHGSpNGjR+ucc87xDwdzxx13aOjQoZo7d65GjBihFStW6M0339TixYslSQ6HQ5MnT9YDDzygbt26qVOnTrr33nvVrl075ebmSpI2b96s//znPxoyZIhatGihjz/+WPfee6+6dOniT+A/+tGPdP/992v8+PH65S9/qR07dmjBggV6+OGHQzo+AAA0hkjkdAAAEH5nwnm6x+PRe++95////fv3a/v27WratKm6du0a1DaDQSc6AOCsdf311+vQoUOaMWOGioqK1LdvXxUWFvonHNm7d6+czpqbtgYPHqzly5dr+vTpmjZtmrp166bVq1erV69e/jJ33323ysrKNHHiRB09elRDhgxRYWGh3G63JCk5OVlPP/20Zs6cqbKyMrVt21bDhw/X9OnT/VfMp6am6uWXX9akSZPUr18/paWlacaMGZo4cWIjHh0AAAAAABqX6Xn6gQMHdNFFF/n/fuihh/TQQw9p6NChWrduXVDbDAad6ACAqBCOW7ftxOfl5SkvL6/Ox6oT7teNGjVKo0aNqnd7DodDs2bN0qxZs+p8vHfv3nr11VdP264LL7xQ//73v09bDgCAaBOpnA4AAMLrTDhP79ixoyzLCmmbwaATHQAQFTjhBgAgNpDTAQCIDeT0GkwsCgAAAAAAAABAPbgSHQAQFfiFGwCA2EBOBwAgNpDTa0RtJ/odPV5VUtPgm/d791DjOg7E9TaOabf2iHGM9h4wDnHE2XtqrKw+xjEHLzavq0/nT41jbsjYYhyzs0Nb45hlXQYbx5xT2ME4JnXTZ8YxvpJS4xhJijunnXFMaYbbvCLH6ceQ+qbsdjuNYy7s+opxzOrLLjp9oW9469VLjGM6/Ou4cUzczn3GMZLkatbMPMjrNQ5pZv52VVXP4G9U8nrDc1MTyRkAgNhATo9dlc0c8iUG/9xUpJl/d01qd8w4pnfG58YxX5Q3MY5p5S4zjpGkDsnm/Qhp8V8Zx7gdVcYx8TZi7PgsqaVxTGpC8BP+VfuyItk4pll8hXGMJLV2m79W27mPGsekxZnX09JGjEs+45h9lebP64dlGcYxh8qbGsd4fC7jGElKcJp/bu3wmPfZVHjM+2ycnuA/f70V4cmj5PQaDOcCAAAAAAAAAEA9ovZKdADA2cWS5FNov1Cb30sBAADCjZwOAEBsIKfXoBMdABAVuE0MAIDYQE4HACA2kNNr0IkOAIgKJGcAAGIDOR0AgNhATq/BmOgAAAAAAAAAANSDK9EBAFGBX7gBAIgN5HQAAGIDOb0GnegAgKhAcgYAIDaQ0wEAiA3k9BoM5wIAAAAAAAAAQD24Eh0AEBUsyyErxF+oQ40HAAChI6cDABAbyOk16EQHAEQFnxzyKcTbxEKMBwAAoSOnAwAQG8jpNRjOBQAAAAAAAACAenAlOgAgKjBhCQAAsYGcDgBAbCCn14jaTvTrmn6ulGbBXyjfvccK4zr+nHaZccz6S7oax1Qd7Gkc4/Aah0iSfC0qjWP6dP7YOOamthuNY3KSDxrH3NDsS+OY67K3Gsc81W+Qccyzn/Q2jjnx+bnGMZLkLDf/wPE2rzKO6dD+sHHMeUlFxjHZyZ8Zx9zQyfy1sHv0c8Yxf72mn3HM6n0XGsdI0qG9LYxjXGXmNxB5m5h/oLR2+YIu6zAoeyqMtQYAQGwgp8cuy3lyCbp8gmVcR0pyuXFMr2YHjGPKm8Qbx6THlxrHSFK3RPNzpubO48YxHrmMY456k41jjnibGsfE2+jkSHCaxyTFmfeJpCScMI6RpK42+jh6Je0zjukYZ34u3NLGsbPTDfVp/BfGMT6TD5H/KatKMI7xeJKMY+yyzD/q5LQR4zA49TYpeyrk9BpR24kOADi78As3AACxgZwOAEBsIKfXYEx0AAAAAAAAAADqwZXoAICowG1iAADEBnI6AACxgZxeg050AEBUsMJwm1isJGcAAM5k5HQAAGIDOb0Gw7kAAAAAAAAAAFAPrkQHAEQFS/ZmNf/mNgAAQGSR0wEAiA3k9Bp0ogMAooJPDjkU4qzfIcYDAIDQkdMBAIgN5PQaDOcCAAAAAAAAAEA9uBIdABAVmPUbAIDYQE4HACA2kNNr0IkOAIgKPsshR4jJNdRZwwEAQOjI6QAAxAZyeg2GcwEAAAAAnNFef/11XX311WrXrp0cDodWr14d8LhlWZoxY4batm2rpKQkZWdn66OPPopMYwEAwBmHTnQAQFSwrPAsAAAgsiKR08vKytSnTx8tXLiwzsfnzJmjRx55RIsWLdLmzZvVpEkT5eTkqLy8PAx7DABAbOI8vUbUDuey0+NTU49JhPnvAeNbv94oMeVWvHFMY3I7Khulnh0e8+PgdlTYqMn8tTAy9S3zmIvMY8r7RvdrwQ47r59dlW7jmM+q7LwWzI/3d5u9bRxzRY/3jGMkST3MQ6Lx86TsK69GhmE7jLUWu94c9yelNAv+s7nH4p83YGsQKTdf95JxzJK/5zRASxBpOVdvMY556Z8DG6AlaCiRyOlXXXWVrrrqqnq2ZWn+/PmaPn26rrnmGknSk08+qfT0dK1evVo33HBDSG09mzgrJafB6ZbDa/46cDnMe1taxJUZxzRxmp9fZMSVGMdIUmbcUeOYZk6vcUyZz/xcuNJyGcccqGxhHFNaZX4OWO4177KqsBFzvCrBOEayd+zsnD+nu3zGMWmupsYx9hwzjihKLDaO2Z/Y3DjmqCfJOEaSymy8HnwnzF93CeXmn49xJ4L/fHR4wtNzzXl6Da5EBwBEherkHOoCAAAiK9py+u7du1VUVKTs7Gz/utTUVA0aNEgbN24MWz0AAMSaaMvpkRS1V6IDAAAAAM5upaWlAX8nJiYqMTHRaBtFRUWSpPT09ID16enp/scAAABOxfhKdCZsAQA0BJ/lCMuC4JDPAQANJZw5PTMzU6mpqf6loKAgwnsXfcjpAICGwnl6DeNOdCZsAQA0BCYsaVzkcwBAQwlnTt+3b59KSkr8y9SpU43bk5GRIUkqLg4ch7e4uNj/2JmMnA4AaCicp9cwHs6FCVsAADjzkc8BAGeClJQUpaSkhLSNTp06KSMjQ2vXrlXfvn0lnRwmZvPmzbr11lvD0MrIIqcDANDwwjqxqJ0JWyoqKlRaWhqwAADOPid/oQ51wpJI70VssDsBGzkdACBFJqcfO3ZM27dv1/bt2yWdzGXbt2/X3r175XA4NHnyZD3wwAN67rnn9M4772j06NFq166dcnNzw77/0YScDgAIBefpNcLaiW5nwpaCgoKAMe4yMzPD2SQAwBmCWb+jh90J2MjpAAApMjn9zTff1EUXXaSLLrpIkpSfn6+LLrpIM2bMkCTdfffduu222zRx4kQNGDBAx44dU2Fhodxud9j3P5qQ0wEAoeA8vUZYO9HtmDp1asAYd/v27Yt0kwAAgA3kdABApAwbNkyWZdVali1bJklyOByaNWuWioqKVF5erldeeUXnnXdeZBsdxcjpAAAEMh4T/VS+PmFL27Zt/euLi4v9Y899U2JiohITE8PZDADAGcj63xLqNhA6O/lcIqcDAE4ip0cPcjoAIBTk9BphvRL96xO2VKuesCUrKyucVQEAYgy3iUUP8jkAIBTk9OhBTgcAhIKcXsP4SvRjx45p165d/r+rJ2xp2bKl2rdv75+wpVu3burUqZPuvffes2LCFgAAziTkcwAAYgM5HQCAhmfcif7mm2/q8ssv9/+dn58vSRozZoyWLVumu+++W2VlZZo4caKOHj2qIUOGnBUTtgAAQsR9Yo2KfA4AaDDk9EZFTgcANBhyup9xJ3r1hC31qZ6wZdasWSE17Mev3CJnUvBJPb55hXEdPdvVPxt5fXLT3zKOyU7+xDjm3LimxjGSVGFVGsdsLDcf6+6fR/sax7y2v5txzJcHmxnHOMpdxjFWkyrjmNZtSo1jstvtNI6RpB82/49xTI8E89GaEh3xxjG7K08Yx7xUdr5xzDOfX2Qc83FRa+MYb6n5MbArsZX5set7zn7jmNw0O59bnwVd9qsEn/H26xSO27xi5DaxxtBY+VyS+i/9qVycqJ/1lvw9J9JNQJR46Z8DI90ENDRyeqNqzJzu9EhOg6fGUWn+PFb5zM9jXDL/PtrSdcw4prXrK+MYSUp2eI1jwjr27imUW+bnPyXeZOOYI5VNjGOOVyUYx/hsfHZU+cz7ECTpy0rz43CoKsU4piSuxDgm1WnnNWd+7OwcuWZO8/PgVvFlxjFF8ebHWpK+KDd/rarK/Ng5zbsx5So3KOwx336dyOl+jfW5DADAKVlWeBZTCxcuVMeOHeV2uzVo0CBt2bLllOVXrVql7t27y+12q3fv3nrxxRe/sR+WZsyYobZt2yopKUnZ2dn66KOP/I/v2bNH48ePV6dOnZSUlKQuXbpo5syZ8ng8AWUcDketZdOmTeY7CABAI4tUTgcAAOFFTq9BJzoA4Ky1cuVK5efna+bMmdq2bZv69OmjnJwcHTx4sM7yGzZs0I033qjx48frrbfeUm5urnJzc7Vjxw5/mTlz5uiRRx7RokWLtHnzZjVp0kQ5OTkqLz952cAHH3wgn8+nP/zhD3r33Xf18MMPa9GiRZo2bVqt+l555RV9/vnn/qVfv34NcyAAAAAAAEC96EQHAESFSMz6PW/ePE2YMEHjxo1Tz549tWjRIiUnJ2vJkiV1ll+wYIGGDx+uKVOmqEePHpo9e7YuvvhiPfbYY//bB0vz58/X9OnTdc011+jCCy/Uk08+qQMHDmj16tWSpOHDh2vp0qW68sor1blzZ40cOVJ33XWXnn766Vr1tWrVShkZGf4lPr7xhhsCAMCuSOR0AAAQfuT0GnSiAwCig+UIzyKptLQ0YKmoqD3gnMfj0datW5Wdne1f53Q6lZ2drY0bN9bZxI0bNwaUl6ScnBx/+d27d6uoqCigTGpqqgYNGlTvNiWppKRELVu2rLV+5MiRatOmjYYMGaLnnnvuFAcPAIAoEsacDgAAIoic7kcnOgAg5mRmZio1NdW/FBQU1Cpz+PBheb1epaenB6xPT09XUVHdE08XFRWdsnz1vybb3LVrlx599FHdcsst/nVNmzbV3LlztWrVKr3wwgsaMmSIcnNz6UgHAAAAACAC4iLdAAAApPBMOFIdv2/fPqWk1MzGnpiYGNqGG8j+/fs1fPhwjRo1ShMmTPCvT0tLU35+vv/vAQMG6MCBA3rwwQc1cuTISDQVAICghTOnAwCAyCGn1+BKdABAdLDCtEhKSUkJWOrqRE9LS5PL5VJxcXHA+uLiYmVkZNTZxIyMjFOWr/43mG0eOHBAl19+uQYPHqzFixfXe1iqDRo0SLt27TptOQAAIi6MOR0AAEQQOd2PTnQAwFkpISFB/fr109q1a/3rfD6f1q5dq6ysrDpjsrKyAspL0po1a/zlO3XqpIyMjIAypaWl2rx5c8A29+/fr2HDhqlfv35aunSpnM7Tp+Pt27erbdu2RvsIAAAAAABCx3AuAICoEI5Zu03j8/PzNWbMGPXv318DBw7U/PnzVVZWpnHjxkmSRo8erXPOOcc/pvodd9yhoUOHau7cuRoxYoRWrFihN998038lucPh0OTJk/XAAw+oW7du6tSpk+699161a9dOubm5kmo60Dt06KCHHnpIhw4d8ren+mr1J554QgkJCbroooskSU8//bSWLFmiP/3pTyEdHwAAGkMkcjoAAAg/cnoNOtEBANGjkW/zuv7663Xo0CHNmDFDRUVF6tu3rwoLC/0Tg+7duzfgKvHBgwdr+fLlmj59uqZNm6Zu3bpp9erV6tWrl7/M3XffrbKyMk2cOFFHjx7VkCFDVFhYKLfbLenkleu7du3Srl27dO655wa0x/raYHGzZ8/Wp59+qri4OHXv3l0rV67Udddd15CHAwCA8ImRW7cBADjrkdMl0YkOAIgSkfqFOy8vT3l5eXU+tm7dulrrRo0apVGjRtW7PYfDoVmzZmnWrFl1Pj527FiNHTv2lG0aM2aMxowZc8oyAABEK65aAwAgNpDTazAmOgAAAAAAAAAA9YjaK9HPf2C34pwJQZe3Mlob11HUt5NxzKxLOhrHFF70kXFMbtpbxjGSFO/wGscUftnbOOaVty4wjknb7DKO6f5WiXGM4/PDxjGqqjKPadncOOSNCy4xr0fS3wd9yzim08B9xjHfb2v+umsd95VxzN6KVsYxHxeZv8ebbUgyjmm9rcw4Jn7vodMXqoNVXm4c81XTJsYxi7v9wDhm1qDEoMt6K8olTTOuo5ZwzNrNbWYAAEQeOT1mxZdZclUG/+TEHTO/+rD0uNs4prgy1TjGznmMV/aupvzKMu96KfeZnz8XVZkfh50V5hPXf1CWYRyzu9T8HLDkhPlrwen0GcfYdcjT1DhmV0V6A7SktqL4L4xj3A7zfpGvfCnGMQeqWhjHHPcF3z8YETY+Ghw2Xqouj0FyNPisPqUI5fSFCxfqwQcfVFFRkfr06aNHH31UAwcOrLf8qlWrdO+992rPnj3q1q2bfve73+m73/2u//Fjx47pnnvu0erVq/XFF1+oU6dOuv322/Wzn/0s6DZxJToAIEo4wrQAAIDIIqcDABAbGj+nr1y5Uvn5+Zo5c6a2bdumPn36KCcnRwcPHqyz/IYNG3TjjTdq/Pjxeuutt5Sbm6vc3Fzt2LHDXyY/P1+FhYX6y1/+ovfff1+TJ09WXl6ennvuuaDbRSc6AAAAAAAAACDi5s2bpwkTJmjcuHHq2bOnFi1apOTkZC1ZsqTO8gsWLNDw4cM1ZcoU9ejRQ7Nnz9bFF1+sxx57zF9mw4YNGjNmjIYNG6aOHTtq4sSJ6tOnj7Zs2RJ0u+hEBwBEBytMCwAAiCxyOgAAsaGRc7rH49HWrVuVnZ3tX+d0OpWdna2NGzfWGbNx48aA8pKUk5MTUH7w4MF67rnntH//flmWpddee00ffvihrrzyyqDbFrVjogMAzjKMnwoAQGwgpwMAEBvCmNNLS0sDVicmJioxMXA+tsOHD8vr9So9PXD+gPT0dH3wwQd1br6oqKjO8kVFRf6/H330UU2cOFHnnnuu4uLi5HQ69cc//lGXXXZZ0LvBlegAAAAAAAAAgAaTmZmp1NRU/1JQUNBodT/66KPatGmTnnvuOW3dulVz587VpEmT9MorrwS9Da5EBwBEB8txcgl1GwAAILLI6QAAxIYw5vR9+/YpJSXFv/qbV6FLUlpamlwul4qLiwPWFxcXKyMjo87NZ2RknLL8iRMnNG3aND3zzDMaMWKEJOnCCy/U9u3b9dBDD9UaCqY+XIkOAIgKlhWeBQAARBY5HQCA2BDOnJ6SkhKw1NWJnpCQoH79+mnt2rX+dT6fT2vXrlVWVladbczKygooL0lr1qzxl6+srFRlZaWczsBucJfLJZ/PF/Sx4Ep0AAAAAAAAAEDE5efna8yYMerfv78GDhyo+fPnq6ysTOPGjZMkjR49Wuecc45/OJg77rhDQ4cO1dy5czVixAitWLFCb775phYvXizpZOf90KFDNWXKFCUlJalDhw5av369nnzySc2bNy/odtGJDgCIDkxCBgBAbCCnAwAQGyKQ06+//nodOnRIM2bMUFFRkfr27avCwkL/5KF79+4NuKp88ODBWr58uaZPn65p06apW7duWr16tXr16uUvs2LFCk2dOlU//vGPdeTIEXXo0EG//vWv9bOf/SzodtGJDgCIDoyfCgBAbCCnAwAQGyKU0/Py8pSXl1fnY+vWrau1btSoURo1alS928vIyNDSpUuN2/F1dKIDAKKCwzq5hLoNAAAQWeR0AABiAzm9BhOLAgAAAAAAAABQj+i9Er2yUnIEf7m/tfMT4ypS3600jmmxo4dxzI6c7sYx2/pmGsdIUpsWXxnHFH2RahyT8r75S6f1pkPGMd73PzKOcdQxu+/pOG3EqPiwcUjyns/M65HUabXHOMbVo5txzONXXmMcUzbwhHFMRqsS4xinM/gZk6t53cYhch03P9ZVBz43r0iSIy7eOMZZWWUc495ifrzb/7si6LJVVqV2GddQB8ZPBQAgNpDTY1bywSrFxQf/fbSqifn33ZKUJsYx61LNz32+aGFeT7ekg8YxkpTsDP67dbWvfOYnM/vKWxrHvF+aYRzz6ZEWxjHHjyQbxzjKza/7tFzmHx5fNjE/x5Kkw6nmr6HPm5n3v7znbmsc0yy+3DjGZeNy4RNeG+9xj/lr+0i5+bEuLbfRzyPpREWCcYyrzPy16jL/WJCrMvjnyDIoe+oNiZz+P9HbiQ4AOLswfioAALGBnA4AQGwgp/sxnAsAAAAAAAAAAPXgSnQAQHTgNjEAAGIDOR0AgNhATvejEx0AEB1IzgAAxAZyOgAAsYGc7sdwLgAAAAAAAAAA1IMr0QEA0YFfuAEAiA3kdAAAYgM53Y9OdABAdGDWbwAAYgM5HQCA2EBO96MTHQAQFRzWySXUbQAAgMgipwMAEBvI6TUYEx0AAAAAAAAAgHpwJToAIDow1hoAALGBnA4AQGwgp/txJToAAAAAAAAAAPWgEx0AAAAAAAAAgHpE7XAu1rltZbkSgy7v+qrMvI4vS4xjvNvfM47JtHoYxxzwtDCOkaT95wV/zKo5POa/pcSVm9+L4Sj3GMfY4UxONg9q1dw4xEq2cax9xiGSJFfZCeMY6/ODxjEZCz4yjnGd39U45vPsDOOYqh5e45hjncxjioaYv/falncxjpEk785d5kFNkoxDHC3N98mR7A6+rLdCMv9orL0dhWHCktCbAQAAQkROj11JB44pzlUZfICjmXEdljPeOOZTl/n5RVGbFOOYd1u0NY6RpNQE8/O5KstlHPPFCfNz4YNHzI+D91Dw5wrVkg6Z9zvEf2UcYktVsr2usROp5n0Cu1LN3xMfN6kyjomLNz8XtqOq0vx1alWYx9jpt3J47GUSh41Dl1Rk3j73F+aJMv6r4BvnqArPa4CcXiNqO9EBAGcZy3FyCXUbAAAgssjpAADEBnK6H8O5AAAAAAAAAABQD65EBwBEB2b9BgAgNpDTAQCIDeR0PzrRAQDRgeQMAEBsIKcDABAbyOl+DOcCAAAAAAAAAEA9uBIdABAVHFYYZv2OkV+4AQA4k5HTAQCIDeT0GnSiAwCiA7eJAQAQG8jpAADEBnK6H53oAIDoQHIGACA2kNMBAIgN5HQ/xkQHAAAAAAAAAKAeXIkOAIgKjLUGAEBsIKcDABAbyOk16EQHAEQHy3FyCXUbAAAgssjpAADEBnK6H8O5AAAAAAAAAABQD65EBwBEByYsAQAgNpDTAQCIDeR0v6jtRPemJMoR5w66vOU23xWXcYTkqKgwjrE++MQ4pnlmH+MYSSpvab5XnjSvcczxdPPjXd4pzTgmft9+4xjL4zGOcfrM39Fed7xxjC/R5luuRZJxiDM91TjG9cUx4xh9ftA4pM3CXcYxrbPM3xP7hzUxjjnaq8o45lhma+MYSWr9lvl7ovlL7xvHePcdMI5xpQe/T06f+ediXRhrDQCA2EBOj13OQ0fldCYEXT7JYX4Lv+VsZh7jMj/POlHa1Djmk1bB91F8XVzTSvOYePPzdK/X/HhXlZmf18afMK8n3sappvuI+QdBXLnPOMZy2RtqojLZPM7TzPy1WtnUPMbrNj92lo3uinjzwy1npflxc9o45XSZdw1JkhzmXQJqUmx+IJIOmn8uJBwsC7pslZfz9HBjOBcAAAAAAAAAAOph3In++uuv6+qrr1a7du3kcDi0evXqgMfHjh0rh8MRsAwfPjxc7QUAxCorTIuhhQsXqmPHjnK73Ro0aJC2bNlyyvKrVq1S9+7d5Xa71bt3b7344ouBu2FZmjFjhtq2baukpCRlZ2fro48+8j++Z88ejR8/Xp06dVJSUpK6dOmimTNnyvONu2jefvttXXrppXK73crMzNScOXPMd+4UyOcAgAYToZx+tiKnAwAaDDndz7gTvaysTH369NHChQvrLTN8+HB9/vnn/uWvf/1rSI0EAJwFrJpbxewupsl55cqVys/P18yZM7Vt2zb16dNHOTk5Oniw7mGKNmzYoBtvvFHjx4/XW2+9pdzcXOXm5mrHjh3+MnPmzNEjjzyiRYsWafPmzWrSpIlycnJUXl4uSfrggw/k8/n0hz/8Qe+++64efvhhLVq0SNOmTfNvo7S0VFdeeaU6dOigrVu36sEHH9R9992nxYsXGx/W+pDPAQANJgI5/WxGTgcANBhyup/xiEdXXXWVrrrqqlOWSUxMVEZGhu1GAQDQGObNm6cJEyZo3LhxkqRFixbphRde0JIlS3TPPffUKr9gwQINHz5cU6ZMkSTNnj1ba9as0WOPPaZFixbJsizNnz9f06dP1zXXXCNJevLJJ5Wenq7Vq1frhhtu0PDhwwOu/urcubN27typxx9/XA899JAk6amnnpLH49GSJUuUkJCgCy64QNu3b9e8efM0ceLEsOw7+RwAgNhATgcAoOE1yJjo69atU5s2bXT++efr1ltv1RdffNEQ1QAAYkkYbxMrLS0NWCrqmBTa4/Fo69atys7O9q9zOp3Kzs7Wxo0b62zixo0bA8pLUk5Ojr/87t27VVRUFFAmNTVVgwYNqnebklRSUqKWLVsG1HPZZZcpIaFm4q6cnBzt3LlTX375Zb3bCTfyOQDAljNkiLazCTkdAGALw7n4hb0Tffjw4XryySe1du1a/e53v9P69et11VVXyeute2bpioqKWp0dAICzUBiTc2ZmplJTU/1LQUFBreoOHz4sr9er9PT0gPXp6ekqKiqqs4lFRUWnLF/9r8k2d+3apUcffVS33HLLaev5eh0NzTSfS+R0AMD/ROCE23SItrMJOR0AYBud6H7Gw7mczg033OD//969e+vCCy9Uly5dtG7dOn3729+uVb6goED3339/uJsBADjD+MdLC3EbkrRv3z6lpKT41ycmJoa24Qayf/9+DR8+XKNGjdKECRMi3ZwApvlcIqcDAE4KZ04PlukQbWcTcjoAwK5I5PRo1SDDuXxd586dlZaWpl27dtX5+NSpU1VSUuJf9u3b19BNAgDEuJSUlIClrk70tLQ0uVwuFRcXB6wvLi6ud8zQjIyMU5av/jeYbR44cECXX365Bg8eXGvC0Prq+Xodje10+VwipwMAIsPOEG1nM3I6AADmGrwT/bPPPtMXX3yhtm3b1vl4YmJirc4OAAAaWkJCgvr166e1a9f61/l8Pq1du1ZZWVl1xmRlZQWUl6Q1a9b4y3fq1EkZGRkBZUpLS7V58+aAbe7fv1/Dhg1Tv379tHTpUjmdgek4KytLr7/+uiorKwPqOf/889WiRQv7Ox2C0+VziZwOAAi/YOY5sTNE29mMnA4AgDnjTvRjx45p+/bt2r59u6STk6ht375de/fu1bFjxzRlyhRt2rRJe/bs0dq1a3XNNdeoa9euysnJCXfbAQCxJAJjreXn5+uPf/yjnnjiCb3//vu69dZbVVZW5r8VfPTo0Zo6daq//B133KHCwkLNnTtXH3zwge677z69+eabysvLkyQ5HA5NnjxZDzzwgJ577jm98847Gj16tNq1a6fc3FxJNR3o7du310MPPaRDhw6pqKgo4CT/Rz/6kRISEjR+/Hi9++67WrlypRYsWKD8/HyzHTwF8jkAoME08jwnZztyOgCgwTAmup/xmOhvvvmmLr/8cv/f1Sf0Y8aM0eOPP663335bTzzxhI4ePap27drpyiuv1OzZs6N2PFoAwNnr+uuv16FDhzRjxgwVFRWpb9++Kiws9F/Jtnfv3oCrxAcPHqzly5dr+vTpmjZtmrp166bVq1erV69e/jJ33323ysrKNHHiRB09elRDhgxRYWGh3G63pJNXlO/atUu7du3SueeeG9Aeyzr57SI1NVUvv/yyJk2apH79+iktLU0zZszQxIkTw7bv5HMAwJkgmHlO7AzRFkvI6QAANDzjTvRhw4b5T/Lr8tJLL4XUIADA2SlSE5bk5eX5ryT/pnXr1tVaN2rUKI0aNar+NjgcmjVrlmbNmlXn42PHjtXYsWNP264LL7xQ//73v09bzi7yOQCgoYQzpwczlMjXh2irvvOreoi2+nJ8LCGnAwAaChOL1jDuRG8sVpxDVpwj6PI+G7vibJpsI6aJcYz3iyPGMcmfHTOOkaT4C5obx1R2qDKPOb/y9IW+4YCSjGMyyy8wjnFs+K95zBHz148r3jzGamX++pEkK958+gJfvMs8pl2qcYyzVVPjmLiDpcYxvrd2Gsdkvukzjin/Th/jmP2XGYdIkg7nnjCO+fw73YxjWmyNN45pW3gg+MI+r/H26xUjyRUAgLNeI+f0/Px8jRkzRv3799fAgQM1f/78gCHaEB6W1yfLCv47tuN47THsTyfhS/Mr5JMOmp8vObzmMRUV5t+rJcnT3PzcrLyJ+XdsR6KNmHjzc6aqZuYxFRXmx8BZFXyfUDWHZR4TV27vAyuxxDwuvsy8fd5E85gqt3GIrXosG72KPvOXgq1OWIf5y9R+nJ32neLHz3pjfAafvwZlT4vzdElR3IkOAAAAAEAwTjdEGwAAQCjoRAcARIdwTDjCL+QAAERehHL6qYZoAwAANnCe7kcnOgAgKjDWGgAAsYGcDgBAbCCn16ATHQAQHfiFGwCA2EBOBwAgNpDT/cxn0gAAAAAAAAAA4CzBlegAgKjAbWIAAMQGcjoAALGBnF6DTnQAQHTgNjEAAGIDOR0AgNhATvdjOBcAAAAAAAAAAOrBlegAgOjAL9wAAMQGcjoAALGBnO5HJzoAICow1hoAALGBnA4AQGwgp9dgOBcAAAAAAAAAAOrBlegAgOjAbWIAAMQGcjoAALGBnO4XtZ3ojipLDoOjbMU5jOvwJZjvvsvtNo5xxJnX4/is2DhGkpKLUo1jyrqZ35CQce4R45jj/Y8bx+xObmkck5nczzhGr243DnF6fcYxcd404xhJqmqdYhxjJZg/r45K832ynObvPU9mC+MYZxvzYxB3sNQ4Jmn9e8YxXV6uMI6RpIrsi4xj9mW7zCu6yvz9WnJN8PVUlbmkHxhXURvJGQCA2EBOj1mOhDg5nPFBl7ecNs5JvOZPfly5eUxCqXmM5TI/95Eky2F+HDw2qrJc5vvkclfZqMf8vLHCFfzrppovwfzcp7KJ+bFOKLH3gRNfZh7j8th4fZ8wP96uCht9ZPHmbfPG2+mLMw6Rz049Nns8feYvVXkTzdvnTTR/fVsG/ZiW12u8/bo3JHL6/zCcCwAAAAAAAAAgKixcuFAdO3aU2+3WoEGDtGXLllOWX7Vqlbp37y63263evXvrxRdfrFXm/fff18iRI5WamqomTZpowIAB2rt3b9BtohMdABAVqicsCXUBAACRRU4HACA2RCKnr1y5Uvn5+Zo5c6a2bdumPn36KCcnRwcPHqyz/IYNG3TjjTdq/Pjxeuutt5Sbm6vc3Fzt2LHDX+bjjz/WkCFD1L17d61bt05vv/227r33XrkNRhyhEx0AEB2sMC0AACCyyOkAAMSGCOT0efPmacKECRo3bpx69uypRYsWKTk5WUuWLKmz/IIFCzR8+HBNmTJFPXr00OzZs3XxxRfrscce85f51a9+pe9+97uaM2eOLrroInXp0kUjR45UmzZtgm4XnegAgKjAVWsAAMQGcjoAALEhnDm9tLQ0YKmoqD2/nMfj0datW5Wdne1f53Q6lZ2drY0bN9bZxo0bNwaUl6ScnBx/eZ/PpxdeeEHnnXeecnJy1KZNGw0aNEirV682OhZ0ogMAAAAAAAAAGkxmZqZSU1P9S0FBQa0yhw8fltfrVXp6esD69PR0FRUV1bndoqKiU5Y/ePCgjh07pt/+9rcaPny4Xn75ZX3/+9/XD37wA61fvz7o9tucqxYAgDALx63bXLUGAEDkkdMBAIgNYczp+/btU0pKin91YmJiiBsOjs/nkyRdc801uvPOOyVJffv21YYNG7Ro0SINHTo0qO3QiQ4AiA6ccAMAEBvI6QAAxIYw5vSUlJSATvS6pKWlyeVyqbi4OGB9cXGxMjIy6ozJyMg4Zfm0tDTFxcWpZ8+eAWV69OihN954I+jdYDgXAAAAAAAAAEBEJSQkqF+/flq7dq1/nc/n09q1a5WVlVVnTFZWVkB5SVqzZo2/fEJCggYMGKCdO3cGlPnwww/VoUOHoNvGlegAgKjg+N8S6jYAAEBkkdMBAIgNkcjp+fn5GjNmjPr376+BAwdq/vz5Kisr07hx4yRJo0eP1jnnnOMfU/2OO+7Q0KFDNXfuXI0YMUIrVqzQm2++qcWLF/u3OWXKFF1//fW67LLLdPnll6uwsFD//Oc/tW7duqDbRSc6ACA6cOs3AACxgZwOAEBsiEBOv/7663Xo0CHNmDFDRUVF6tu3rwoLC/2Th+7du1dOZ83gKoMHD9by5cs1ffp0TZs2Td26ddPq1avVq1cvf5nvf//7WrRokQoKCnT77bfr/PPP1z/+8Q8NGTIk6HbRiQ4AAAAAAAAAiAp5eXnKy8ur87G6rh4fNWqURo0adcpt3nzzzbr55pttt4lOdABAVHBYJ5dQtwEAACKLnA4AQGwgp9eI3k50yzq5BM18hB4r0WUek5RoHONISjKO8X5xxDhGklq8f8w45ti5zYxjvmxhvk/d0g4bx5wYUGYc82FqO+OYjDYDjGNavPShcYz3k73GMZIUfyzNOMaX3tI4pirFbRxjh8PjM46xHObvcc85LYxjHG2bG8e4SsqNYyQp6c1PjGO6vGT+2RB3jvl7onh4+6DLej329r8Wbv0GACA2kNNjV5xLchqcR8eZn3PbGXzX6TV/wcSVm8d4zU9PJUm+ePOd8iWYx1QmOk9f6BssG/W44r3GMWpqHlJpo+fNF2/+mvPaOG6SVGXj9RBv3mWjuBM2niOP+bFzeYxD5Kyy8RxVmtfjjbcRY959J8nee88Oy8bHoxUX/GvVTh9K3RsSOf1/orcTHQBw9omR5AoAwFmPnA4AQGwgp0uS7P3cBgAAAAAAAADAWYAr0QEAUYGx1gAAiA3kdAAAYgM5vQad6ACA6MBYawAAxAZyOgAAsYGc7sdwLgAAAAAAAAAA1IMr0QEAUYHbxAAAiA3kdAAAYgM5vQad6ACA6MBtYgAAxAZyOgAAsYGc7sdwLgAAAAAAAAAA1IMr0QEAUYHbxAAAiA3kdAAAYgM5vQad6ACA6MBtYgAAxAZyOgAAsYGc7sdwLgAAAAAAAAAA1IMr0QEA0YFfuAEAiA3kdAAAYgM53e+s7kS3nA7zoMQE4xBHcpJ5zIkTxjGS5Hj3E+OY9JY9jWMOuFOMYz4yr0bd0g4bx1zQY59xzIfN2xjHlHbobhxzzvoy4xhJ8m551zzoy6PGIQlprYxjfGmpxjHeponGMXberw6vzzjGzoe7N8V8fyTJatXeOMZRea55PV8eN45ps/rDoMtW+TzG268LY60BABAbyOkxzOk8uQTJirNx87vDzvd+82pcHvMXWdwJG30Iknzx5jHeePO6fPHmx9vrtNEtlGweYuNplRLMz+e8TWxUZDXi85pgXldcuXk9LhtdSi4bp3XOSvMYh2X+3nNW2anHPEaSfFV2PhvMX6vOChv9FV6Dttn4XKwLOb3GWd2JDgCIIvzCDQBAbCCnAwAQG8jpfoyJDgAAAAAAAABAPbgSHQAQFRyWZevWvm9uAwAARBY5HQCA2EBOr8GV6ACA6GCFaTG0cOFCdezYUW63W4MGDdKWLVtOWX7VqlXq3r273G63evfurRdffDFwNyxLM2bMUNu2bZWUlKTs7Gx99NFHAWV+/etfa/DgwUpOTlbz5s3rrMfhcNRaVqxYYb6DAAA0tgjldAAAEGbkdD860QEAZ62VK1cqPz9fM2fO1LZt29SnTx/l5OTo4MGDdZbfsGGDbrzxRo0fP15vvfWWcnNzlZubqx07dvjLzJkzR4888ogWLVqkzZs3q0mTJsrJyVF5ec2MQB6PR6NGjdKtt956yvYtXbpUn3/+uX/Jzc0Ny34DAAAAAIDg0YkOAIgK1bN+h7qYmDdvniZMmKBx48apZ8+eWrRokZKTk7VkyZI6yy9YsEDDhw/XlClT1KNHD82ePVsXX3yxHnvsMUknr0KfP3++pk+frmuuuUYXXnihnnzySR04cECrV6/2b+f+++/XnXfeqd69e5+yfc2bN1dGRoZ/cbvdZjsIAEAERCKnAwCA8COn16ATHQAQHcJ4m1hpaWnAUlFRUas6j8ejrVu3Kjs727/O6XQqOztbGzdurLOJGzduDCgvSTk5Of7yu3fvVlFRUUCZ1NRUDRo0qN5tnsqkSZOUlpamgQMHasmSJbJiZCw5AECM49ZvAABiAzndj050AEDMyczMVGpqqn8pKCioVebw4cPyer1KT08PWJ+enq6ioqI6t1tUVHTK8tX/mmyzPrNmzdLf/vY3rVmzRtdee61+/vOf69FHHzXaBgAAAAAACF1cpBsAAIAUntu8quP37dunlJQU//rExMTQNhwB9957r///L7roIpWVlenBBx/U7bffHsFWAQBweuHM6QAAIHLI6TW4Eh0AEB3CeJtYSkpKwFJXJ3paWppcLpeKi4sD1hcXFysjI6POJmZkZJyyfPW/JtsM1qBBg/TZZ5/VOTQNAABRhVu/AQCIDeR0PzrRAQBnpYSEBPXr109r1671r/P5fFq7dq2ysrLqjMnKygooL0lr1qzxl+/UqZMyMjICypSWlmrz5s31bjNY27dvV4sWLc7Iq+oBAAAAADiTMZwLACAqROI2sfz8fI0ZM0b9+/fXwIEDNX/+fJWVlWncuHGSpNGjR+ucc87xj6l+xx13aOjQoZo7d65GjBihFStW6M0339TixYtP1u9waPLkyXrggQfUrVs3derUSffee6/atWun3Nxcf7179+7VkSNHtHfvXnm9Xm3fvl2S1LVrVzVt2lT//Oc/VVxcrEsuuURut1tr1qzRb37zG911112hHSAAABoBt34DABAbyOk1orcT3eE4uTR0HYaseJdxjNNtftWgs2kT4xhJ8paUGsckbdhpHHOup5txzKGjqcYx/+2RZBzTum2JcUy7VuYxXw7yGMfsOifl9IXq0LzPAOOY1luPGcd4//uhcYz1efHpC31DXAvz14JsxPiam7+PvEnxxjF2OaoaJ5NUtTQ/DlabpsFvv6pcesO4ijoqVei3eRnGX3/99Tp06JBmzJihoqIi9e3bV4WFhf6JQffu3Suns+amrcGDB2v58uWaPn26pk2bpm7dumn16tXq1auXv8zdd9+tsrIyTZw4UUePHtWQIUNUWFgot9vtLzNjxgw98cQT/r8vuugiSdJrr72mYcOGKT4+XgsXLtSdd94py7LUtWtXzZs3TxMmTLBzVCLuzXF/Ukqz4G9+67H45w3YGkRKx9VHjWP25DYPezsQeUkXf2Ecc2JbqwZoCRpMBHI6GollnVyijJ3v1S6veUyCzV13WDb6Nhw2Bg6wEeOx0Tavz8b+xPvMY+wcbxtNs+LtPbE+G8ehykZvoi/evB6n20ZMlXGInObdInJWmbfNYeP9apud15DTxj7Z2CWHL/j3kUnZUyKn+0VvJzoA4KwTiV+o8/LylJeXV+dj69atq7Vu1KhRGjVqVL3bczgcmjVrlmbNmlVvmWXLlmnZsmX1Pj58+HANHz683scBAIh2sXLVGQAAZzty+kmMiQ4AAAAAAAAAQD2MOtELCgo0YMAANWvWTG3atFFubq527gwcCqS8vFyTJk1Sq1at1LRpU1177bUqLjYf7gEAcJapvj041AVBIacDABoMOb1RkdMBAA2GnO5n1Im+fv16TZo0SZs2bdKaNWtUWVmpK6+8UmVlZf4yd955p/75z39q1apVWr9+vQ4cOKAf/OAHYW84ACC2VE9YEuqC4JDTAQANhZzeuMjpAICGQk6vYTQmemFhYcDfy5YtU5s2bbR161ZddtllKikp0Z///GctX75cV1xxhSRp6dKl6tGjhzZt2qRLLrkkfC0HAAC2kdMBAIgN5HQAABpeSGOil5SUSJJatmwpSdq6dasqKyuVnZ3tL9O9e3e1b99eGzdurHMbFRUVKi0tDVgAAGchK0wLbCGnAwDChpweUeR0AEDYkNP9bHei+3w+TZ48Wd/61rfUq1cvSVJRUZESEhLUvHnzgLLp6ekqKiqqczsFBQVKTU31L5mZmXabBAA4gzl84VlgjpwOAAgncnrkkNMBAOFETq9huxN90qRJ2rFjh1asWBFSA6ZOnaqSkhL/sm/fvpC2BwAAzJDTAQCIDeR0AAAahtGY6NXy8vL0/PPP6/XXX9e5557rX5+RkSGPx6OjR48G/MpdXFysjIyMOreVmJioxMREO80AAMSScNzmFSO3iTUmcjoAIOzI6RFBTgcAhB053c/oSnTLspSXl6dnnnlGr776qjp16hTweL9+/RQfH6+1a9f61+3cuVN79+5VVlZWeFoMAIhJzPrduMjpAICGQk5vXOR0AEBDIafXMLoSfdKkSVq+fLmeffZZNWvWzD9+WmpqqpKSkpSamqrx48crPz9fLVu2VEpKim677TZlZWUx4zcA4NQs6+QS6jYQFHI6AKDBkNMbFTkdANBgyOl+Rp3ojz/+uCRp2LBhAeuXLl2qsWPHSpIefvhhOZ1OXXvttaqoqFBOTo5+//vfh6WxAAAgPMjpAADEBnI6AAANz6gT3QrilwO3262FCxdq4cKFthslSZbTIcvpCGkbp6/E/JcQK858LlYrMcE4xpGUZBwjSU6v+ZS33q++Mo6J/78dxjHnft7eOKb005bGMV92a20cc/gcr3GMs4XHOCauVblxjCR9OdB8+oLSLk2MY5pk9TOOafFRpXk97xYZx1R9stc4xo74lKbGMY6m5jGSZKWax3mbmH+eWPEu45hICMdtXrFym1hjaMyc3n/pT+Vyu0PaBs58e3KbR7oJiBIntrWKdBPQwKI9p//617/WCy+8oO3btyshIUFHjx6tVWbv3r269dZb9dprr6lp06YaM2aMCgoKFBdna1qxBtWYOV1VXskZ/LmTo9L8PMtOjKvC/Puuw2f+InOVm59vn4wz70dwmZ9uyukx70NxVprHVHrMj3dVso2+lHgbHwQ2upEsm11Plsu8fT47ldn4QPTFN0o1cvhs7I+Nt5HDa16Pw97b1RanebeI4o+bv4/iE4LPQZa3ynj7dYn2nN6You8bAADg7MSEJQAAxIYoz+kej0ejRo1SVlaW/vznP9d63Ov1asSIEcrIyNCGDRv0+eefa/To0YqPj9dvfvObhmsYAADRJspzemMy/ykQAAAAAIAz1P33368777xTvXv3rvPxl19+We+9957+8pe/qG/fvrrqqqs0e/ZsLVy4UB6PjcuDAQDAGY9OdABAVGDWbwAAYsOZntM3btyo3r17Kz093b8uJydHpaWlevfddyPXMAAAGtmZntPDieFcAADRgVm/AQCIDWHM6aWlpQGrExMTlZiYGNq2T6OoqCigA12S/++iIvO5fQAAOGNxnu7HlegAAAAAgKiUmZmp1NRU/1JQUFBnuXvuuUcOh+OUywcffNDIrQcAALGCK9EBAFGBWb8BAIgN4czp+/btU0pKin99fVeh/+IXv9DYsWNPuc3OnTsHVXdGRoa2bNkSsK64uNj/GAAAZwvO02vQiQ4AiA7M+g0AQGwIY05PSUkJ6ESvT+vWrdW6desQKz0pKytLv/71r3Xw4EG1adNGkrRmzRqlpKSoZ8+eYakDAIAzAufpfnSiAwAAAADOGnv37tWRI0e0d+9eeb1ebd++XZLUtWtXNW3aVFdeeaV69uypm266SXPmzFFRUZGmT5+uSZMmNfh47AAAIDrRiQ4AiArcJgYAQGyI9pw+Y8YMPfHEE/6/L7roIknSa6+9pmHDhsnlcun555/XrbfeqqysLDVp0kRjxozRrFmzGq5RAABEoWjP6Y2JTnQAQHTwWSeXULcBAAAiK8pz+rJly7Rs2bJTlunQoYNefPHFBmsDAABnhCjP6Y2JTnQAQHRgrDUAAGIDOR0AgNhATvdzRroBAAAAAAAAAABEq6i9Et3hs+Qwudzfa/6zhqPKZx5T6TWOkcNhHhNn76lxJCYYxzh9ycYxvuPHjWO8H+wyjkkpam4c0+yjDOOY45nNjGO+ynQbx5xobeO1IMmXYv5a9TYxjyntbh7zVWeXcUx81rnGMe7DmcYxzfabv1+T95cbx8TvKTaOkSTv++bvCfnM98lpYwIsZ3LwnwsOy2O8/Tq3ozCMtRaWlgAAgFCQ02OXVVkly2lwLV6V+XdXo36AEGKclebnPrLsvbCdlebXL9o7DubnZg6fnbbZeIfaONxe864K+RJsPEdx9p5Xn51uGxt9V75GOt72PrfNg6zG+oC3W4+N4+CwzN9Hzirz96vTE/y5fVVVeC7/JqfXiNpOdADAWcaybJ+YBGwDAABEFjkdAIDYQE73YzgXAAAAAAAAAEBUWLhwoTp27Ci3261BgwZpy5Ytpyy/atUqde/eXW63W7179z7l5OA/+9nP5HA4NH/+fKM20YkOAIgKDis8CwAAiCxyOgAAsSESOX3lypXKz8/XzJkztW3bNvXp00c5OTk6ePBgneU3bNigG2+8UePHj9dbb72l3Nxc5ebmaseOHbXKPvPMM9q0aZPatWtnfCzoRAcARAcrTAsAAIgscjoAALEhAjl93rx5mjBhgsaNG6eePXtq0aJFSk5O1pIlS+osv2DBAg0fPlxTpkxRjx49NHv2bF188cV67LHHAsrt379ft912m5566inFx8ebNUp0ogMAAAAAAAAAIszj8Wjr1q3Kzs72r3M6ncrOztbGjRvrjNm4cWNAeUnKyckJKO/z+XTTTTdpypQpuuCCC2y1jYlFAQBRwWFZcoQ44Uio8QAAIHTkdAAAYkM4c3ppaWnA+sTERCUmJgasO3z4sLxer9LT0wPWp6en64MPPqhz+0VFRXWWLyoq8v/9u9/9TnFxcbr99ttt7wdXogMAooMvTAsAAIgscjoAALEhjDk9MzNTqamp/qWgoKBRdmHr1q1asGCBli1bJofDYXs7XIkOAAAAAAAAAGgw+/btU0pKiv/vb16FLklpaWlyuVwqLi4OWF9cXKyMjIw6t5uRkXHK8v/+97918OBBtW/f3v+41+vVL37xC82fP1979uwJqv1ciQ4AiArVt4mFugAAgMgipwMAEBvCmdNTUlIClro60RMSEtSvXz+tXbvWv87n82nt2rXKysqqs41ZWVkB5SVpzZo1/vI33XST3n77bW3fvt2/tGvXTlOmTNFLL70U9LHgSnQAQHSwMWt3ndsAAACRRU4HACA2RCCn5+fna8yYMerfv78GDhyo+fPnq6ysTOPGjZMkjR49Wuecc45/OJg77rhDQ4cO1dy5czVixAitWLFCb775phYvXixJatWqlVq1ahVQR3x8vDIyMnT++ecH3S460QEA0cGyTi6hbgMAAEQWOR0AgNgQgZx+/fXX69ChQ5oxY4aKiorUt29fFRYW+icP3bt3r5zOmsFVBg8erOXLl2v69OmaNm2aunXrptWrV6tXr16htfsb6EQHAAAAAAAAAESFvLw85eXl1fnYunXraq0bNWqURo0aFfT2gx0H/euithPddaxCLlfw5R1eG7+KVFYZhziqvI1SjyorzWMkyWtjGnun+dD4jrh44xirynyfvF9+aRzjOH7cOKbpwRbGMcn7zGMqWicbx0jSiTbmx7u8hfnbu6K5cYgqm5m/9ypTzGM8aebvvdIexiGSVXtMrtNxnuhooyIprqyTcUz8MfOZpN1fmB/vpCPBf5ZUVZZLzxlXUYvDOrmEug0AABBZ5PQYltJUcgX/fbmqVVPjKjwtEoxjKlINOg/+x1Vp/iJz2OgOsMtno7fGm2h+rmCnHplXY2tGPl+8+XNkJZs/Sc5Ee0+sK848zmHj2Nm6CNgyr8iyE2McYe/lYyvGbiKxEXdC5n09jirzN0VcefBv2KrK8HT5ktNrRG0nOgDgLMOt3wAAxAZyOgAAsYGc7mfjt0AAAAAAAAAAAM4OXIkOAIgKDt/JJdRtAACAyCKnAwAQG8jpNehEBwBEB24TAwAgNpDTAQCIDeR0P4ZzAQCc1RYuXKiOHTvK7XZr0KBB2rJlyynLr1q1St27d5fb7Vbv3r314osvBjxuWZZmzJihtm3bKikpSdnZ2froo48Cyvz617/W4MGDlZycrObNm9dZz969ezVixAglJyerTZs2mjJliqqqbExUDQAAAAAAQkInOgAgOlhhWgysXLlS+fn5mjlzprZt26Y+ffooJydHBw8erLP8hg0bdOONN2r8+PF66623lJubq9zcXO3YscNfZs6cOXrkkUe0aNEibd68WU2aNFFOTo7Ky8v9ZTwej0aNGqVbb721znq8Xq9GjBghj8ejDRs26IknntCyZcs0Y8YMsx0EACASIpDTAQBAAyCn+9GJDgCICg7LCstiYt68eZowYYLGjRunnj17atGiRUpOTtaSJUvqLL9gwQINHz5cU6ZMUY8ePTR79mxdfPHFeuyxxySdvAp9/vz5mj59uq655hpdeOGFevLJJ3XgwAGtXr3av537779fd955p3r37l1nPS+//LLee+89/eUvf1Hfvn111VVXafbs2Vq4cKE8Ho/RPgIA0NgikdMBAED4kdNr0IkOAIgO1WOthboEyePxaOvWrcrOzvavczqdys7O1saNG+uM2bhxY0B5ScrJyfGX3717t4qKigLKpKamatCgQfVus756evfurfT09IB6SktL9e677wa9HQAAIqKRczoAAGgg5HQ/JhYFAMSc0tLSgL8TExOVmJgYsO7w4cPyer0BHdWSlJ6erg8++KDO7RYVFdVZvqioyP949br6ygSjvnq+XgcAAAAAAGgcXIkOAIgOliRfiMv/fuDOzMxUamqqfykoKGjUXQEA4KwWxpwOAAAiiJzux5XoAICoEI6x0qrj9+3bp5SUFP/6b16FLklpaWlyuVwqLi4OWF9cXKyMjIw6t5+RkXHK8tX/FhcXq23btgFl+vbtG/R+ZGRkaMuWLbXq+XodAABEq3DmdAAAEDnk9BpciQ4AiDkpKSkBS12d6AkJCerXr5/Wrl3rX+fz+bR27VplZWXVud2srKyA8pK0Zs0af/lOnTopIyMjoExpaak2b95c7zbrq+edd97RwYMHA+pJSUlRz549g94OAAAAAAAIHVeiAwCig6XQJxwxDM/Pz9eYMWPUv39/DRw4UPPnz1dZWZnGjRsnSRo9erTOOecc/3Awd9xxh4YOHaq5c+dqxIgRWrFihd58800tXrxYkuRwODR58mQ98MAD6tatmzp16qR7771X7dq1U25urr/evXv36siRI9q7d6+8Xq+2b98uSeratauaNm2qK6+8Uj179tRNN92kOXPmqKioSNOnT9ekSZPq/EEAAICoEoGcDgAAGgA53S9qO9EdnxXJ4UgIPsBn/oxYNl4Els9nHlNVZRxjZ38kyfJ6bQSZ71OjzazrdBmHOBwO4xjL4zGOcR49Zhxjt+vLVeE2jkkojTeOqSgxvznF08z8eHtSzOupbGpeT1UT89epL9nGezzN/PUjSY5zK41jXAnmnyfOePOYCoOy3uMV0nPGVdQWjlm7DeOvv/56HTp0SDNmzFBRUZH69u2rwsJC/ySee/fuldNZ83odPHiwli9frunTp2vatGnq1q2bVq9erV69evnL3H333SorK9PEiRN19OhRDRkyRIWFhXK7a97HM2bM0BNPPOH/+6KLLpIkvfbaaxo2bJhcLpeef/553XrrrcrKylKTJk00ZswYzZo1y9ZhAQCgUUUgp6NxVJyTKm9c8OcmxzPMz0mOtzE/VyhvZf56cXrN63HYON2WdHJMYOPKzEMs89Nn+RLMj53Xbb5D3ibmMa5m5udLzZqeMI5p2eS4cYwktUg0j0uNLzeOSXSZn8/F2X6xmvFZ5u8jn40Xt9ey8YawyeUwf0/8O7GzccxxR8rpC32Dsyr44+2tCNPgI+R0v6jtRAcAoDHk5eUpLy+vzsfWrVtXa92oUaM0atSoerfncDg0a9asU3Z4L1u2TMuWLTtluzp06KAXX3zxlGUAAAAAAEDDoxMdABAdfLJ1xU2tbQAAgMgipwMAEBvI6X50ogMAogKzfgMAEBvI6QAAxAZyeo0wDZADAAAAAAAAAEDs4Up0AEB0YMISAABiAzkdAIDYQE73oxMdABAdSM4AAMQGcjoAALGBnO5HJzoAIDqQnAEAiA3kdAAAYgM53Y8x0QEAAAAAAAAAqAdXogMAooNPkiMM2wAAAJFFTgcAIDaQ0/3oRAcARAWHZckR4m1eocYDAIDQkdMBAIgN5PQaDOcCAAAAAAAAAEA9uBIdABAdmLAEAIDYQE4HACA2kNP9orcT3eE8uQQr3nyAHofDRkx8vHGMnDYu+I9zmcdIsuJtPKU2joOVmGBeT5z5cfAlmB+HqkTzY+CLN2+b121nf+wNJFWVaF5Xldu8Lq/bOERem/tkyllpXk9cmXk9Xp+N57XKxueCpAqPeV2eBPO6KtyVxjHJbk/QZb3eMN3U5LMkR4jJ1RcbyRkAgDMaOT1mxR3zKM7gvC7hKxvnczbOY2ydZ9kYo9dhc1xfW28HOzF2DoPLxvG20f/iK7Vxzn3U/PVTkpRoHHM0uZlxjCS5mpifZyUlBX+eVa1JonlMUryNtsWZx8Q5zd8UThsvbl/Ig3Ib1GWZ13X8mPnrLu64jT6O48EfO4cnTHmUnO7HcC4AAAAAAAAAANTDqBO9oKBAAwYMULNmzdSmTRvl5uZq586dAWWGDRsmh8MRsPzsZz8La6MBADGo+jaxUBcEhZwOAGgw5PRGRU4HADQYcrqfUSf6+vXrNWnSJG3atElr1qxRZWWlrrzySpWVBY6ZMGHCBH3++ef+Zc6cOWFtNAAgFoUjMcdGcm4M5HQAQMMhpzcmcjoAoOGQ06sZDR5dWFgY8PeyZcvUpk0bbd26VZdddpl/fXJysjIyMsLTQgDA2YEJSxoVOR0A0GDI6Y2KnA4AaDDkdL+QxkQvKSmRJLVs2TJg/VNPPaW0tDT16tVLU6dO1fHjx0OpBgAANDByOgAAsYGcDgBA+Bldif51Pp9PkydP1re+9S316tXLv/5HP/qROnTooHbt2untt9/WL3/5S+3cuVNPP/10ndupqKhQRUWF/+/S0lK7TQIAnMl8YbjNK0Zm/W5s5HQAQFiR0yOGnA4ACCtyup/tTvRJkyZpx44deuONNwLWT5w40f//vXv3Vtu2bfXtb39bH3/8sbp06VJrOwUFBbr//vvtNgMAECss38kl1G3AGDkdABBW5PSIIacDAMKKnO5naziXvLw8Pf/883rttdd07rnnnrLsoEGDJEm7du2q8/GpU6eqpKTEv+zbt89OkwAAgA3kdAAAYgM5HQCAhmN0JbplWbrtttv0zDPPaN26derUqdNpY7Zv3y5Jatu2bZ2PJyYmKjEx0aQZAIBYxIQljYqcDgBoMOT0RkVOBwA0GHK6n1En+qRJk7R8+XI9++yzatasmYqKiiRJqampSkpK0scff6zly5fru9/9rlq1aqW3335bd955py677DJdeOGFDbIDAIAYwVhrjYqcDgBoMOT0RkVOBwA0GHK6n1En+uOPPy5JGjZsWMD6pUuXauzYsUpISNArr7yi+fPnq6ysTJmZmbr22ms1ffr0sDUYAACEjpwOAEBsIKcDANDwjIdzOZXMzEytX78+pAYBAM5S3CbWqMjpAIAGQ05vVOR0AECDIaf7GXWiN6YP7+kmZ5I7+ABXbDwh1axo3x9HI9UT10gz+No63uZtczTi8+pspLqczsZ5jpwu83ri7MQYR9irR5JcjXTs7LQvweUNumxVZaXx9utkKQzJOSwtAQAAoSCnxyzX8Uq5XM6gy8cfizeuI8FtfrLpiw++TSGJ9teljfN0y06My8ZzZONEy1dmXk98vI22Jdp7/Xjd5jt1PNGgn+t/jrltnDcmmse4EoM/B6wWF19lHBMfb6MeG+fOjXme7jth/lpwesxfq87K4D+ErDCdppPTazRSpgEAAAAAAAAA4MwTtVeiAwDOMtwmBgBAbCCnAwAQG8jpfnSiAwCig88nO8Mk1d4GAACIKHI6AACxgZzuRyc6ACA68As3AACxgZwOAEBsIKf7MSY6AAAAAAAAAAD14Ep0AEB04BduAABiAzkdAIDYQE7340p0AEB08FnhWQAAQGRFcU7fs2ePxo8fr06dOikpKUldunTRzJkz5fF4Asq9/fbbuvTSS+V2u5WZmak5c+Y0SHsAAIhqUZzTGxtXogMAAAAAzgoffPCBfD6f/vCHP6hr167asWOHJkyYoLKyMj300EOSpNLSUl155ZXKzs7WokWL9M477+jmm29W8+bNNXHixAjvAQAAiAQ60QEAUcGyfLKs0GbtDjUeAACELppz+vDhwzV8+HD/3507d9bOnTv1+OOP+zvRn3rqKXk8Hi1ZskQJCQm64IILtH37ds2bN49OdADAWSWac3pjYzgXAEB0sMJwi1iMjLUGAMAZ7QzL6SUlJWrZsqX/740bN+qyyy5TQkKCf11OTo527typL7/8stHaBQBAxJ1hOb0h0YkOAAAAAIhKpaWlAUtFRUVYt79r1y49+uijuuWWW/zrioqKlJ6eHlCu+u+ioqKw1g8AAM4MdKIDAKJD9azfoS4AACCywpjTMzMzlZqa6l8KCgrqrPKee+6Rw+E45fLBBx8ExOzfv1/Dhw/XqFGjNGHChAY/LAAAnHE4T/eL2jHR/3zVH9WkGX38ABDtyr7y6cpwbMjnkxwhjpUWI2OtAQBwRgtjTt+3b59SUlL8qxMTE+ss/otf/EJjx4495SY7d+7s//8DBw7o8ssv1+DBg7V48eKAchkZGSouLg5YV/13RkZG0LsQixwnyuVwBt8ZEncs4fSFviHe7TKO8cU7jGMs8xD7Gqkuy9k4x8EyeA3UxNiox/ylIF+cjWNgs2fMTl12Xqu+OPODZ2effPHmz6vXRj1VNurx2ajHireZh2y8VhMOmb9Y3YfN63GXBL9PVZVhOjfmPN0vajvRAQAAAABnt5SUlIBO9Pq0bt1arVu3Dmqb+/fv1+WXX65+/fpp6dKlcjoDe0yysrL0q1/9SpWVlYqPj5ckrVmzRueff75atGhhvhMAAOCMx6XeAIDowG1iAADEhijO6fv379ewYcPUvn17PfTQQzp06JCKiooCxjr/0Y9+pISEBI0fP17vvvuuVq5cqQULFig/P///t3f3MVWX/x/HX4AeMG8gJDkcb8lMK0UL82SZtskEaxllZeamOaeroGV043Ip+dPNTWczb5ZrzW62vMnNrKy5iNRqIS3IOVsxZRQWglkTFCOQc/3+ON9z7OQ5ysEDn3PzfGyfCedcH86b97n0Jdc514cuqQkAgLAVxpne3VhEBwCEBeNyheQAAADWCudMLykp0fHjx1VaWqpBgwYpIyPDe3gkJyfr888/V01NjbKzs/X8889r+fLlWrRoUZfUBABAuLIq0zdv3qxhw4YpKSlJTqdT33333WXH79q1S6NGjVJSUpLGjBmjzz77zHtfW1ublixZojFjxqh3795yOByaO3eu6urqgqqJRXQAQHjgFW4AAKJDGGf6E088IWOM3+PfsrKy9PXXX6ulpUW//fablixZ0iX1AAAQ1izI9J07d6qoqEjFxcWqrKzU2LFjlZubq1OnTvkd/+2332r27NlasGCBfvjhB+Xn5ys/P19Hjx6VJJ0/f16VlZVatmyZKisrtXv3blVVVWnGjBlB1cUiOgAAAAAAAADAcq+99poWLlyo+fPn6+abb9aWLVt0zTXXaOvWrX7Hv/7668rLy9OLL76om266SStXrtRtt92mTZs2SXLvMCspKdGjjz6qkSNH6o477tCmTZtUUVGh2traDtfFIjoAIDy4TGiOIIVym5gkGWO0fPlyZWRkqFevXsrJydGxY8d8xvz111+aM2eO+vXrp5SUFC1YsEDnzp3z3v/LL78oLi7ukuPQoUNBf38AAHQ7izIdAACEWAgzvampyef4559/Lnm41tZWVVRUKCcnx3tbfHy8cnJyVFZW5rfEsrIyn/GSlJubG3C8JDU2NiouLk4pKSkdbgWL6ACA8GCMZFxXeVi7TUyS1qxZow0bNmjLli0qLy9X7969lZubq5aWFu+YOXPm6Mcff1RJSYn27t2rr776yu91Vr/44gudPHnSe2RnZwf1/QEAYAkLMh0AAHSBEGb64MGDlZyc7D1Wr159ycOdPn1a7e3tSk9P97k9PT3d55eA/1t9fX1Q41taWrRkyRLNnj1b/fr163ArWEQHAMSsUG8TM8Zo/fr1euWVV/TAAw8oKytL7733nurq6rRnzx5J0k8//aR9+/bprbfektPp1KRJk7Rx40bt2LHjkl9s0r9/f9ntdu/Rs2fPLu0HAAAAAABd4cSJE2psbPQeL7/8crfX0NbWpkcffVTGGL3xxhtBncsiOgAgLBiXCckhWbdNrKamRvX19T5jkpOT5XQ6vWPKysqUkpKi8ePHe8fk5OQoPj5e5eXlPl97xowZGjBggCZNmqSPP/44mHYCAGCZUGY6AACwTigzvV+/fj5HYmLiJY+XlpamhIQENTQ0+Nze0NAgu93ut0a73d6h8Z4F9F9//VUlJSVBvQtdYhEdABAurnqL2P8OWbdNzPPnlcYMGDDA5/4ePXooNTXVO6ZPnz5at26ddu3apU8//VSTJk1Sfn4+C+kAgMgQwkwHAAAW6uZMt9lsys7OVmlpqfc2l8ul0tJSTZw40e85EydO9BkvSSUlJT7jPQvox44d0xdffKH+/fsH2QipR9BnAAAQ5k6cOOHzqrK/V7jDWVpamoqKiryf33777aqrq9PatWs1Y8YMCysDAAAAAKDrFBUVad68eRo/frwmTJig9evXq7m5WfPnz5ckzZ07VwMHDvS+We7ZZ5/VlClTtG7dOt13333asWOHvv/+e7355puS3AvoDz/8sCorK7V37161t7d738CWmpoqm83WobrCbhHd/O9i883neOcBAEQCz7/X5ip/AZhxGZm4q/waxneb2OV0xTYxz58NDQ3KyMjwGTNu3DjvmP/+4tILFy7or7/+Cvi4kuR0OlVSUnLZ7ynceJ4P1z8tVxgJAAgHnn+vwynTER48z8cFV2tQ57W3B/9/gAttQZ+i9raEoM/p1hkW1z0PY+KDfyDTidpMJ65p0Klzgn9a5XJ1ogftwT+OJLk6cZ6rE0tdnXkcc6ET57QH/7fC1YlVxU49TifmgrnQyXXFTsxVV0vwBba3Bj9XL7R1fDK0t0Vups+aNUt//PGHli9frvr6eo0bN0779u3z7viura1VfPzFJ+rOO+/Utm3b9Morr2jp0qUaMWKE9uzZo9GjR0uSfv/9d++ubs/P5R779+/XPffc06G6wm4R/ezZs5KkB+88YXElAIBgnD17VsnJyZ0+/4L556q3bl9Qx3/q+vc2sfz8fEkXt4kVFhb6PcezTWzx4sXe2/69TSwzM1N2u12lpaXecG5qalJ5ebmeeuop79c4c+aMKioqlJ2dLUn68ssv5XK55HQ6A9Z7+PBhn4X5SODJ9JrX/s/iSgAAwYi0TEfX82T6gdo3gzvxl9DXAgDouEjN9MLCwoA/lx84cOCS2x555BE98sgjfscPGzYsJC/Oh90iusPh0IkTJ9S3b1/Fxfm+KtPU1KTBgwdfsk0/ltADN/pADyR64GF1H4wxOnv2rBwOR6fOt9lsstvt+qb+s5DUY7fbO7wdK9TbxOLi4rR48WKtWrVKI0aMUGZmppYtWyaHw+FdqL/pppuUl5enhQsXasuWLWpra1NhYaEee+wxbw/fffdd2Ww23XrrrZKk3bt3a+vWrXrrrbdC0qPuQqZfHj2gBx70gR54WN2HSM50dC0y/fLoAT3woA/0QAqPHpDpoRd2i+jx8fEaNGjQZcd0ZJt+tKMHbvSBHkj0wMPKPlzNK9tJSUmqqalRa2tw24MDsdlsSkpK6tDYUG8Tk6SXXnpJzc3NWrRokc6cOaNJkyZp3759PjW9//77Kiws1NSpUxUfH6+ZM2dqw4YNPrWtXLlSv/76q3r06KFRo0Zp586devjhh6+mNd2OTO8YekAPPOgDPfAg092CyXR0LTK9Y+gBPfCgD/RAsr4HZHpoxZkIuthcU1OTkpOT1djYGLN/EemBG32gBxI98KAPiETMW3og0QMP+kAPPOgDIhHzlh5I9MCDPtADiR5Eq05cLh8AAAAAAAAAgNgQUYvoiYmJKi4uVmJiotWlWIYeuNEHeiDRAw/6gEjEvKUHEj3woA/0wIM+IBIxb+mBRA886AM9kOhBtIqoy7kAAAAAAAAAANCdIuqd6AAAAAAAAAAAdCcW0QEAAAAAAAAACIBFdAAAAAAAAAAAAmARHQAAAAAAAACAACJmEX3z5s0aNmyYkpKS5HQ69d1331ldUrd69dVXFRcX53OMGjXK6rK61FdffaX7779fDodDcXFx2rNnj8/9xhgtX75cGRkZ6tWrl3JycnTs2DFriu1CV+rDE088ccncyMvLs6bYLrJ69Wrdfvvt6tu3rwYMGKD8/HxVVVX5jGlpaVFBQYH69++vPn36aObMmWpoaLCo4tDrSA/uueeeS+bCk08+aVHFQGBkOplOpsdmppPnbmQ6ogmZTqbHYqbHep5LZLoHmR5bImIRfefOnSoqKlJxcbEqKys1duxY5ebm6tSpU1aX1q1uueUWnTx50nt88803VpfUpZqbmzV27Fht3rzZ7/1r1qzRhg0btGXLFpWXl6t3797Kzc1VS0tLN1fata7UB0nKy8vzmRvbt2/vxgq73sGDB1VQUKBDhw6ppKREbW1tmjZtmpqbm71jnnvuOX3yySfatWuXDh48qLq6Oj300EMWVh1aHemBJC1cuNBnLqxZs8aiigH/yHQ3Mt0XmX5RNGc6ee5GpiNakOluZLqvWMj0WM9ziUz3INNjjIkAEyZMMAUFBd7P29vbjcPhMKtXr7awqu5VXFxsxo4da3UZlpFkPvzwQ+/nLpfL2O12s3btWu9tZ86cMYmJiWb79u0WVNg9/tsHY4yZN2+eeeCBByypxyqnTp0ykszBgweNMe7nvmfPnmbXrl3eMT/99JORZMrKyqwqs0v9twfGGDNlyhTz7LPPWlcU0AFkOplOpruR6eS5B5mOSEWmk+lkOnnuQaa7kenRLezfid7a2qqKigrl5OR4b4uPj1dOTo7KysosrKz7HTt2TA6HQ9dff73mzJmj2tpaq0uyTE1Njerr633mRXJyspxOZ8zNC0k6cOCABgwYoJEjR+qpp57Sn3/+aXVJXaqxsVGSlJqaKkmqqKhQW1ubz3wYNWqUhgwZErXz4b898Hj//feVlpam0aNH6+WXX9b58+etKA/wi0y/iEy/iEz3FUuZTp67kemIRGT6RWT6RWT6RbGU5xKZ7kGmR7ceVhdwJadPn1Z7e7vS09N9bk9PT9fPP/9sUVXdz+l06p133tHIkSN18uRJrVixQnfffbeOHj2qvn37Wl1et6uvr5ckv/PCc1+syMvL00MPPaTMzExVV1dr6dKlmj59usrKypSQkGB1eSHncrm0ePFi3XXXXRo9erQk93yw2WxKSUnxGRut88FfDyTp8ccf19ChQ+VwOHTkyBEtWbJEVVVV2r17t4XVAheR6W5kui8y/aJYynTy3I1MR6Qi093IdF9kulss5blEpnuQ6dEv7BfR4TZ9+nTvx1lZWXI6nRo6dKg++OADLViwwMLKYLXHHnvM+/GYMWOUlZWl4cOH68CBA5o6daqFlXWNgoICHT16NOqvNXg5gXqwaNEi78djxoxRRkaGpk6dqurqag0fPry7ywQQAJmOQGIp08lzNzIdiGxkOvyJpTyXyHQPMj36hf3lXNLS0pSQkHDJb/BtaGiQ3W63qCrrpaSk6MYbb9Tx48etLsUSnueeeXGp66+/XmlpaVE5NwoLC7V3717t379fgwYN8t5ut9vV2tqqM2fO+IyPxvkQqAf+OJ1OSYrKuYDIRKb7R6aT6YFEa6aT525kOiIZme4fmU6m+xOteS6R6R5kemwI+0V0m82m7OxslZaWem9zuVwqLS3VxIkTLazMWufOnVN1dbUyMjKsLsUSmZmZstvtPvOiqalJ5eXlMT0vJOm3337Tn3/+GVVzwxijwsJCffjhh/ryyy+VmZnpc392drZ69uzpMx+qqqpUW1sbNfPhSj3w5/Dhw5IUVXMBkY1M949MJ9MDibZMJ8/dyHREAzLdPzKdTPcn2vJcItM9yPTYEhGXcykqKtK8efM0fvx4TZgwQevXr1dzc7Pmz59vdWnd5oUXXtD999+voUOHqq6uTsXFxUpISNDs2bOtLq3LnDt3zueVuZqaGh0+fFipqakaMmSIFi9erFWrVmnEiBHKzMzUsmXL5HA4lJ+fb13RXeByfUhNTdWKFSs0c+ZM2e12VVdX66WXXtINN9yg3NxcC6sOrYKCAm3btk0fffSR+vbt672GWnJysnr16qXk5GQtWLBARUVFSk1NVb9+/fTMM89o4sSJuuOOOyyuPjSu1IPq6mpt27ZN9957r/r3768jR47oueee0+TJk5WVlWVx9cBFZDqZLpHpHrGW6eS5G5mOaEGmk+lSbGZ6rOe5RKZ7kOkxxkSIjRs3miFDhhibzWYmTJhgDh06ZHVJ3WrWrFkmIyPD2Gw2M3DgQDNr1ixz/Phxq8vqUvv37zeSLjnmzZtnjDHG5XKZZcuWmfT0dJOYmGimTp1qqqqqrC26C1yuD+fPnzfTpk0z1113nenZs6cZOnSoWbhwoamvr7e67JDy9/1LMm+//bZ3zN9//22efvppc+2115prrrnGPPjgg+bkyZPWFR1iV+pBbW2tmTx5sklNTTWJiYnmhhtuMC+++KJpbGy0tnDADzKdTCfTYzPTyXM3Mh3RhEwn02Mx02M9z40h0z3I9NgSZ4wxV7sQDwAAAAAAAABANAr7a6IDAAAAAAAAAGAVFtEBAAAAAAAAAAiARXQAAAAAAAAAAAJgER0AAAAAAAAAgABYRAcAAAAAAAAAIAAW0QEAAAAAAAAACIBFdAAAAAAAAAAAAmARHQAAAAAAAACAAFhEBwAAAAAAAAAgABbRAQAAAAAAAAAIgEV0AAAAAAAAAAACYBEdAAAAAAAAAIAA/h8L+bFdegmbOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1500x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_img = images[0][0].squeeze().detach().cpu()/255\n",
    "# print(images.shape)\n",
    "count_image = plot_label_pin(sample_img, pins[0], outputs[0])\n",
    "# label = count_pins(sample_img, pins[0], r)\n",
    "# count_all_image = plot_label_pin(sample_img,pins[0], label)\n",
    "count_all_image = plot_all(sample_img, r=3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # You can adjust the figsize as needed\n",
    "\n",
    "# Plot the sample_img in the first subplot\n",
    "im0 = axes[0].imshow(sample_img)\n",
    "axes[0].set_title('Sample Image')\n",
    "fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Plot the count_image in the second subplot\n",
    "im1 = axes[1].imshow(count_image)\n",
    "axes[1].set_title('Count Image')\n",
    "fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Plot the count_all_image in the third subplot\n",
    "im2 = axes[2].imshow(count_all_image)\n",
    "axes[2].set_title('Count All Image')\n",
    "fig.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Add spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32d3c9-4be0-4212-a456-9b4d674dde30",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d358a39b-4e43-40fe-8a6d-f3b3c4894579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel_matrix(X, Y, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Gaussian kernel matrix between two sets of PyTorch tensors X and Y.\n",
    "\n",
    "    Parameters:\n",
    "    X (torch.Tensor): First set of tensors with shape (n, d), where n is the number of vectors and d is the dimensionality.\n",
    "    Y (torch.Tensor): Second set of tensors with shape (m, d), where m is the number of vectors and d is the dimensionality.\n",
    "    sigma (float): The kernel bandwidth parameter.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The Gaussian kernel matrix of shape (n, m).\n",
    "    \"\"\"\n",
    "    if X.size(1) != Y.size(1):\n",
    "        raise ValueError(\"Input tensors must have the same dimension\")\n",
    "\n",
    "    n, m = X.size(0), Y.size(0)\n",
    "    X = X.unsqueeze(1)  # Shape (n, 1, d)\n",
    "    Y = Y.unsqueeze(0)  # Shape (1, m, d)\n",
    "\n",
    "    diff = torch.norm(X - Y, dim=2)  # Pairwise Euclidean distances between vectors\n",
    "    return torch.exp(- (diff ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "\n",
    "def pseudo_inverse(kernel_matrix, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Calculate the pseudo-inverse of a matrix using Singular Value Decomposition (SVD).\n",
    "\n",
    "    Parameters:\n",
    "    kernel_matrix (torch.Tensor): The matrix for which to compute the pseudo-inverse.\n",
    "    epsilon (float): A small value to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The pseudo-inverse of the input matrix.\n",
    "    \"\"\"\n",
    "    U, S, V = torch.svd(kernel_matrix)\n",
    "    S_inv = 1.0 / (S + epsilon)\n",
    "    pseudo_inv = torch.mm(V, torch.mm(torch.diag(S_inv), U.t()))\n",
    "    return pseudo_inv\n",
    "\n",
    "\n",
    "class NPPLoss(nn.Module):\n",
    "    def __init__(self, identity, sigma=1.0):\n",
    "        super(NPPLoss, self).__init__()\n",
    "        self.identity = identity\n",
    "        self.sigma = sigma  # Add sigma as an instance variable\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def compute_kernel(self, pins):\n",
    "        matrix_list = []\n",
    "        for i in range(len(pins)):\n",
    "            X = Y = pins[i].float()\n",
    "            kernel_matrix = gaussian_kernel_matrix(X, Y, self.sigma)  # Use self.sigma\n",
    "            pseudo_inv_matrix = pseudo_inverse(kernel_matrix)\n",
    "            matrix_list.append(pseudo_inv_matrix)\n",
    "        return matrix_list\n",
    "    \n",
    "    def forward(self, y_true, y_pred, pins):\n",
    "        loss = 0\n",
    "        if self.identity:\n",
    "            for i in range(len(y_true)):\n",
    "                loss += 1/len(y_true[i]) * torch.matmul(\n",
    "                    (y_true[i] - y_pred[i].squeeze()[pins[i][:,0], pins[i][:,1]]).t(),\n",
    "                    (y_true[i] - y_pred[i].squeeze()[pins[i][:,0], pins[i][:,1]])\n",
    "                )\n",
    "        else:\n",
    "            matrix_list = self.compute_kernel(tuple(pins))\n",
    "            for i in range(len(y_true)):\n",
    "                loss += 1/len(y_true[i]) * torch.matmul(\n",
    "                    (y_true[i] - y_pred[i].squeeze()[pins[i][:,0], pins[i][:,1]]).t(),\n",
    "                    torch.matmul(matrix_list[i], y_true[i] - y_pred[i].squeeze()[pins[i][:,0], pins[i][:,1]])\n",
    "                )\n",
    "        loss /= len(y_true)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e8ca4-3587-4153-8e2b-af426245aac5",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8dc7f19e-62c4-407d-a1d0-385f207d3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_kernels_encoder, num_kernels_decoder, input_channel=3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.encoder = self._build_encoder(num_kernels_encoder)\n",
    "        self.decoder = self._build_decoder(num_kernels_decoder, num_kernels_encoder[-1])\n",
    "        \n",
    "    def _build_encoder(self, num_kernels):\n",
    "        layers = []\n",
    "        \n",
    "        for out_channels in num_kernels:\n",
    "            layers.append(nn.Conv2d(self.input_channel, out_channels, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            self.input_channel = out_channels  # Update input_channel for the next layer\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _build_decoder(self, num_kernels, input_channel):\n",
    "        layers = []\n",
    "        \n",
    "        for out_channels in num_kernels:\n",
    "            layers.append(nn.ConvTranspose2d(input_channel, out_channels, kernel_size=2, stride=2))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_channel = out_channels\n",
    "        \n",
    "        layers.append(nn.ConvTranspose2d(input_channel, 1, kernel_size=2, stride=2))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bbe6bfd-3df7-463e-81b3-c54f4bf50dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiffusionStepLayer(nn.Module):\n",
    "    def __init__(self, input_channels, num_steps):\n",
    "        super(DiffusionStepLayer, self).__init__()\n",
    "        # Implement your diffusion model layer here\n",
    "        # This could include multiple steps, such as convolutions, normalization, etc.\n",
    "        self.diffusion_model = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, input_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            # Add more layers as needed\n",
    "        )\n",
    "        self.num_steps = num_steps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for _ in range(self.num_steps):\n",
    "            x = self.diffusion_model(x)\n",
    "        return x\n",
    "    \n",
    "class DiffusionAE(nn.Module):\n",
    "    def __init__(self, num_diffusion_steps, num_kernels_decoder, input_channel=3):\n",
    "        super(DiffusionAE, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "        self.encoder = self._build_diffusion_encoder(num_diffusion_steps)\n",
    "        self.decoder = self._build_decoder(num_kernels_decoder, num_diffusion_steps[-1])\n",
    "        \n",
    "    def _build_diffusion_encoder(self, num_diffusion_steps):\n",
    "        layers = []\n",
    "        \n",
    "        # Assuming each diffusion step reduces the spatial dimensions by half\n",
    "        for diffusion_step in num_diffusion_steps:\n",
    "            # Replace this with your preferred diffusion model layer\n",
    "            layers.append(DiffusionStepLayer(input_channels=self.input_channel, num_steps=diffusion_step))\n",
    "            self.input_channel *= 2  # Update input_channel for the next diffusion step\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _build_decoder(self, num_kernels, input_channel):\n",
    "        layers = []\n",
    "        \n",
    "        for out_channels in num_kernels:\n",
    "            layers.append(nn.ConvTranspose2d(input_channel, out_channels, kernel_size=2, stride=2))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_channel = out_channels\n",
    "        \n",
    "        layers.append(nn.ConvTranspose2d(input_channel, 1, kernel_size=2, stride=2))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da5344f8-0726-4edb-b353-899393e22362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def __call__(self, epoch, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(f\"Early stopping after {epoch} epochs.\")\n",
    "                return True  # Stop training\n",
    "        return False  # Continue training\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c306e1-061a-47bc-8584-46ad8e08ee8b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa39fe1f-e261-4bc3-b8b4-75fc9ca989a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLRFinder:\n",
    "    def __init__(self, model, criterion, optimizer, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.history = {'lr': [], 'loss': []}\n",
    "\n",
    "    def find_lr(self, train_loader, start_lr=1e-4, end_lr=10, num_iter=10,smooth_f=0.05):\n",
    "        model = self.model.to(self.device)\n",
    "        criterion = self.criterion\n",
    "        optimizer = self.optimizer\n",
    "        device = self.device\n",
    "        model.train()\n",
    "\n",
    "        lr_step = (end_lr / start_lr) ** (1 / num_iter)\n",
    "        lr = start_lr\n",
    "\n",
    "        for iteration in range(num_iter):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            total_loss = 0.0\n",
    "            for batch in train_loader:\n",
    "                x_train = batch['image'][:, :input_channel, :, :].to(device)\n",
    "                p_train = [tensor.to(device) for tensor in batch['pins']]\n",
    "                y_train = [tensor.to(device) for tensor in batch['outputs']]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_train.float())\n",
    "                loss = criterion(y_train, outputs, p_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            self.history['lr'].append(lr)\n",
    "            self.history['loss'].append(avg_loss)\n",
    "\n",
    "            lr *= lr_step\n",
    "\n",
    "    def find_best_lr(self, skip_start=10, skip_end=5):\n",
    "        # Find the index of the minimum loss in the specified range\n",
    "        min_loss_index = skip_start + np.argmin(self.history['loss'][skip_start:-skip_end])\n",
    "\n",
    "        # Output the learning rate corresponding to the minimum loss\n",
    "        best_lr = self.history['lr'][min_loss_index]\n",
    "        return best_lr\n",
    "\n",
    "def find_best_lr_multiple_losses(model, train_loader, losses):\n",
    "    best_lrs = {}\n",
    "    \n",
    "    # Store the initial state of the model and optimizer\n",
    "    model_init_state = model.state_dict()\n",
    "    optimizer_init_state = optimizer.state_dict()\n",
    "\n",
    "    for loss_name, criterion in losses.items():\n",
    "        print(f\"Finding best LR for {loss_name}...\")\n",
    "        \n",
    "        # Create an instance of the CustomLRFinder class\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Use a small learning rate for LR finding\n",
    "        lr_finder = CustomLRFinder(model, criterion, optimizer)\n",
    "\n",
    "        # Find the learning rate\n",
    "        lr_finder.find_lr(train_loader, start_lr=1e-4, end_lr=1, num_iter=100)\n",
    "\n",
    "        # Get the best learning rate\n",
    "        best_lr = lr_finder.find_best_lr()\n",
    "        print(f\"Best LR for {loss_name}: {best_lr}\")\n",
    "        best_lrs[loss_name] = best_lr\n",
    "\n",
    "        # Reset the model and optimizer to their initial state\n",
    "        model.load_state_dict(model_init_state)\n",
    "        optimizer.load_state_dict(optimizer_init_state)\n",
    "        \n",
    "    return best_lrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce40744e-f190-427b-a0c9-19a163a1a7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, criterion, optimizer, device, early_stopping):\n",
    "    train_losses = []  # To track train loss for plotting\n",
    "    val_losses = []    # To track validation loss for plotting\n",
    "    best_val_loss = float('inf') \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            x_train = batch['image'][:, :input_channel, :, :].to(device)\n",
    "            p_train = [tensor.to(device) for tensor in batch['pins']]\n",
    "            y_train = [tensor.to(device) for tensor in batch['outputs']] \n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_train.float())\n",
    "            loss = criterion(y_train, outputs, p_train)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        total_loss /= len(train_dataloader.dataset)\n",
    "        # Print train loss\n",
    "        # print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {total_loss:.4f}')\n",
    "        train_losses.append(total_loss)\n",
    "\n",
    "        # Check validation loss every val_every_epoch epochs\n",
    "        if (epoch) % val_every_epoch == 0:\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_dataloader:\n",
    "                    x_val = val_batch['image'][:, :input_channel, :, :].to(device)\n",
    "                    p_val = [tensor.to(device) for tensor in val_batch['pins']]\n",
    "                    y_val = [tensor.to(device) for tensor in val_batch['outputs']]\n",
    "\n",
    "                    val_outputs = model(x_val.float())\n",
    "                    val_loss += criterion(y_val, val_outputs, p_val).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader.dataset)  # Average validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                # Save the model\n",
    "                torch.save(model.state_dict(), './history/best_model.pth')\n",
    "\n",
    "            if early_stopping(epoch, val_loss):\n",
    "                break  # Stop training early\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "    # Reload the best model after training\n",
    "    model.load_state_dict(torch.load('./history/best_model.pth'))\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed8108-2439-4133-aade-e939f78df961",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8552a478-5727-4a45-9b9b-f925506011f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metric = NPPLoss(identity=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x_test = batch['image'][:, :input_channel, :, :].to(device)\n",
    "            p_test = [tensor.to(device) for tensor in batch['pins']]\n",
    "            y_test = [tensor.to(device) for tensor in batch['outputs']]\n",
    "\n",
    "            test_outputs = model(x_test.float())\n",
    "            loss = metric(y_test, test_outputs, p_test)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(dataloader.dataset)\n",
    "    return total_loss\n",
    "\n",
    "def plot_loss(train_losses, val_losses, val_every_epoch, NPP, sigma, dataset, learning_rate, num_kernels_encoder, num_kernels_decoder, save_dir=\"./results/plots\"):\n",
    "    # Create a directory for saving plots if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Construct the filename based on parameters\n",
    "    filename = f\"loss_plot_NPP_{NPP}_sigma_{sigma}_dataset_{dataset}_lr_{learning_rate}_encoder_{num_kernels_encoder}_decoder_{num_kernels_decoder}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "    # Plot the train and validation loss\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Train Loss')\n",
    "    plt.plot(range(val_every_epoch, len(train_losses), val_every_epoch), val_losses, '--', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MSE Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11e9111c-3a3f-498b-9574-56626971725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_ci(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device, num_runs=1):\n",
    "    test_losses_npp_true = []\n",
    "    test_losses_npp_false= []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        test_losses_vs_sigma_npp_true = []\n",
    "        test_loss_npp_false = None\n",
    "\n",
    "        # Run NPP=False once and collect the test loss\n",
    "        early_stopping = EarlyStoppingCallback(patience=5, min_delta=0.001)\n",
    "        criterion = NPPLoss(identity=True).to(device)\n",
    "\n",
    "        autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "        model, train_losses, val_losses = train_model(autoencoder, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, criterion, optimizer, device, early_stopping)\n",
    "\n",
    "        test_loss_npp_false = evaluate_model(autoencoder, test_dataloader, device)\n",
    "        print(f\"Test loss npp_f:{test_loss_npp_false}\")\n",
    "        test_losses_npp_false.append(test_loss_npp_false)\n",
    "\n",
    "        # Run LR Finder for different sigma values\n",
    "        for sigma in sigmas:\n",
    "            early_stopping = EarlyStoppingCallback(patience=5, min_delta=0.001)\n",
    "            criterion = NPPLoss(identity=False, sigma=sigma).to(device)\n",
    "            autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "            optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "            model, train_losses, val_losses = train_model(autoencoder, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, criterion, optimizer, device, early_stopping)\n",
    "            test_loss = evaluate_model(autoencoder, test_dataloader, device)\n",
    "            print(f\"Test loss npp_t:{test_loss}\")\n",
    "            test_losses_vs_sigma_npp_true.append(test_loss)\n",
    "\n",
    "        test_losses_npp_true.append(test_losses_vs_sigma_npp_true)\n",
    "    return test_losses_npp_true, test_losses_npp_false\n",
    "\n",
    "def save_data(data, filename):\n",
    "    np.save(filename, data)\n",
    "\n",
    "# Function to load data\n",
    "def load_data(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "# Function to run the pipeline and save data\n",
    "def run_and_save_pipeline(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device):\n",
    "    # Run the pipeline\n",
    "    test_loss_npp_true, test_loss_npp_false= run_pipeline_ci(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device)\n",
    "    print(\"start saving!\")\n",
    "    # Save the data\n",
    "    save_data(test_loss_npp_true, './history/test_loss_npp_true.npy')\n",
    "    save_data(test_loss_npp_false, './history/test_loss_npp_false.npy')\n",
    "    print(\"saved\")\n",
    "    return test_loss_npp_true, test_loss_npp_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a2467c8e-29b2-4759-927f-85caeeaacf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmas = [0.1, 0.2, 0.5, 1, 2, 5]\n",
    "# losses = {}\n",
    "\n",
    "# # Add the loss for NPP=False to the dictionary\n",
    "# losses['npp_false'] = NPPLoss(identity=True).to(device)\n",
    "\n",
    "# # Add losses for NPP=True with different sigmas to the dictionary\n",
    "# for sigma in sigmas:\n",
    "#     loss_name = f'npp_true_sigma_{sigma}'\n",
    "#     losses[loss_name] = NPPLoss(identity=False, sigma=sigma).to(device)\n",
    "\n",
    "# model = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "# best_lrs = find_best_lr_multiple_losses(model, train_dataloader, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e04a8eba-47fc-4225-a7e9-7442ae7aca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = NPPLoss(identity=False, sigma=sigma).to(device)\n",
    "# autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)       \n",
    "# optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "# lr_finder = CustomLRFinder(autoencoder, criterion, optimizer)\n",
    "# best_lrs = lr_finder.find_best_lr_multiple_losses(train_dataloader, losses)\n",
    "# print(\"Best learning rates:\", best_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c681ad7-b14c-4d02-ad7f-da35693469d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 22.8121\n",
      "Validation Loss: 22.8121\n",
      "Validation Loss: 22.8121\n",
      "Validation Loss: 22.8121\n",
      "Validation Loss: 22.8121\n",
      "Early stopping after 25 epochs.\n",
      "Test loss npp_f:10.166551208496093\n",
      "Validation Loss: 22.5063\n",
      "Validation Loss: 23.8811\n",
      "Validation Loss: 21.8994\n",
      "Validation Loss: 22.6040\n",
      "Validation Loss: 22.2007\n",
      "Validation Loss: 22.3491\n",
      "Validation Loss: 21.9028\n",
      "Validation Loss: 21.6823\n",
      "Validation Loss: 21.8499\n",
      "Validation Loss: 22.1464\n",
      "Validation Loss: 20.7975\n",
      "Validation Loss: 21.3774\n",
      "Validation Loss: 21.5303\n",
      "Validation Loss: 20.5098\n",
      "Validation Loss: 20.4406\n",
      "Validation Loss: 21.4568\n",
      "Validation Loss: 20.7929\n",
      "Validation Loss: 21.1926\n",
      "Validation Loss: 20.8579\n",
      "Early stopping after 95 epochs.\n",
      "Test loss npp_t:7.020404815673828\n",
      "Validation Loss: 22.2537\n",
      "Validation Loss: 21.9067\n",
      "Validation Loss: 21.7308\n",
      "Validation Loss: 21.7006\n",
      "Validation Loss: 22.3779\n",
      "Validation Loss: 21.9500\n",
      "Validation Loss: 21.7923\n",
      "Validation Loss: 22.4491\n",
      "Validation Loss: 21.1236\n",
      "Validation Loss: 22.8038\n",
      "Validation Loss: 20.9086\n",
      "Validation Loss: 20.8842\n",
      "Validation Loss: 19.5520\n",
      "Validation Loss: 20.3291\n",
      "Validation Loss: 19.7595\n",
      "Validation Loss: 19.8634\n",
      "Validation Loss: 19.7546\n",
      "Validation Loss: 19.0752\n",
      "Validation Loss: 19.7185\n",
      "Validation Loss: 19.7675\n",
      "Validation Loss: 19.0992\n",
      "Validation Loss: 19.0743\n",
      "Early stopping after 110 epochs.\n",
      "Test loss npp_t:6.512940216064453\n",
      "Validation Loss: 22.8119\n",
      "Validation Loss: 22.8119\n",
      "Validation Loss: 22.8119\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Run and save the pipeline data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m loss_vs_sigma_data \u001b[38;5;241m=\u001b[39m \u001b[43mrun_and_save_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[101], line 46\u001b[0m, in \u001b[0;36mrun_and_save_pipeline\u001b[0;34m(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_save_pipeline\u001b[39m(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     test_loss_npp_true, test_loss_npp_false\u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline_ci\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart saving!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Save the data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[101], line 28\u001b[0m, in \u001b[0;36mrun_pipeline_ci\u001b[0;34m(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device, num_runs)\u001b[0m\n\u001b[1;32m     26\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel\u001b[38;5;241m=\u001b[39minput_channel)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(autoencoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m---> 28\u001b[0m model, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_every_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m evaluate_model(autoencoder, test_dataloader, device)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss npp_t:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[99], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, criterion, optimizer, device, early_stopping)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      7\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      9\u001b[0m         x_train \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m][:, :input_channel, :, :]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         p_train \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpins\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/scratch/shi.cheng/NPP/Satellite_Fusion/tools/data_utils.py:269\u001b[0m, in \u001b[0;36mPinDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    266\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpins\u001b[39m\u001b[38;5;124m'\u001b[39m: pins, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: outputs}\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m--> 269\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/scratch/shi.cheng/NPP/Satellite_Fusion/tools/data_utils.py:297\u001b[0m, in \u001b[0;36mResize.__call__\u001b[0;34m(self, sample, size)\u001b[0m\n\u001b[1;32m    294\u001b[0m image, pins, outputs \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpins\u001b[39m\u001b[38;5;124m'\u001b[39m], sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Resize the image to desired sized pixels\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpins\u001b[39m\u001b[38;5;124m'\u001b[39m: pins, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: outputs}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:432\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    429\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39msize, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation, max_size\u001b[38;5;241m=\u001b[39mmax_size)\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:496\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Define align_corners to avoid warnings\u001b[39;00m\n\u001b[1;32m    494\u001b[0m align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnew_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_w\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out_dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39muint8:\n\u001b[1;32m    499\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3938\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m antialias:\n\u001b[1;32m   3937\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_upsample_bilinear2d_aa(\u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 3938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_bilinear2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3940\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set your hyperparameters\n",
    "dataset = \"MNIST\"\n",
    "input_channel = 1 if dataset == \"MNIST\" else 3\n",
    "num_epochs = 200\n",
    "sigmas = [0.1, 0.2, 0.5, 1, 2, 5]  # Set the sigma values you want to test\n",
    "num_kernels_encoder = [16, 8]\n",
    "num_kernels_decoder = [16]\n",
    "learning_rate = 0.01\n",
    "val_every_epoch = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run and save the pipeline data\n",
    "loss_vs_sigma_data = run_and_save_pipeline(input_channel, train_dataloader, val_dataloader, num_epochs, val_every_epoch, learning_rate, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b04d7-2308-48e9-9a75-d8071dd3d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss_npp_false = [test_loss_npp_false for i in range((len(sigmas)))]\n",
    "# test_loss_npp_true.pop(1)\n",
    "test_loss_npp_true, test_loss_npp_false = load_data('./history/test_loss_npp_true.npy'), load_data('./history/test_loss_npp_false.npy')\n",
    "test_loss_npp_true, test_loss_npp_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bf364-d010-40de-ad6c-ce837b5dee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate, dataset, model_name=\"Auto encoder\"):\n",
    "    # Unpack the data\n",
    "    test_loss_npp_true, test_loss_npp_false = loss_vs_sigma_data\n",
    "    test_loss_npp_false = [test_loss_npp_false for i in range(len(sigmas))]\n",
    "\n",
    "    # Calculate mean and confidence intervals for NPP=True runs\n",
    "    mean_test_loss_npp_true = np.mean(test_loss_npp_true, axis=0)\n",
    "    ci_test_loss_npp_true = 1.96 * np.std(test_loss_npp_true, axis=0) / np.sqrt(len(test_loss_npp_true))\n",
    "\n",
    "    # Duplicate NPP=False values for plotting\n",
    "    mean_test_loss_npp_false = np.mean(test_loss_npp_false, axis=1)\n",
    "    ci_test_loss_npp_false = 1.96 * np.std(test_loss_npp_false, axis=1) / np.sqrt(len(test_loss_npp_false))\n",
    "\n",
    "    # Plot mean and confidence intervals for NPP=True\n",
    "    plt.plot(sigmas, mean_test_loss_npp_true, marker='o', label='NPP=True', color='blue')\n",
    "\n",
    "    # Plot mean and confidence intervals for duplicated NPP=False\n",
    "    plt.plot(sigmas, mean_test_loss_npp_false, color='red', linestyle='--', label='NPP=False')\n",
    "\n",
    "    # Fill between for NPP=True with blue color\n",
    "    plt.fill_between(sigmas, mean_test_loss_npp_true - ci_test_loss_npp_true, mean_test_loss_npp_true + ci_test_loss_npp_true, color='blue', alpha=0.2)\n",
    "\n",
    "    # Fill between for NPP=False with red color\n",
    "    plt.fill_between(sigmas, mean_test_loss_npp_false - ci_test_loss_npp_false, mean_test_loss_npp_false + ci_test_loss_npp_false, color='red', alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Sigma')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.title(f'Test Loss vs. Sigma:{dataset} dataset with {model_name}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create a directory to save the results if it doesn't exist\n",
    "    results_dir = './results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Generate a filename based on parameters in the title\n",
    "    filename = f\"test_loss_vs_sigma_{dataset}_{model_name}_lr_{learning_rate}.png\"\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(filepath)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate)\n",
    "\n",
    "# Plot and save the plot using the saved data\n",
    "plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a5d16-5dbd-4a42-917e-72b80b9fd9b2",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e275dea-f73a-4c94-a6dd-f2b5def8f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(x, p, y, outputs, r):\n",
    "    plt.figure(figsize=(14, 14))  # Adjust the figure size\n",
    "    n_shows = 4\n",
    "\n",
    "    for i in range(n_shows):\n",
    "        # Original Images\n",
    "        img = x[i].squeeze().detach().cpu() / 255\n",
    "\n",
    "        plt.subplot(4, 4, 4*i+1 )\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.subplot(4, 4, 4*i + 2)  # Transposed the rows and columns\n",
    "        count_all_image = plot_all(img, r=r)\n",
    "        plt.imshow(count_all_image)\n",
    "\n",
    "        # Reconstructed Images (switched with row 3)\n",
    "        plt.subplot(4, 4, 4*i + 3)  # Transposed the rows and columns\n",
    "        count_image = plot_label_pin(img, p[i], y[i])\n",
    "        plt.imshow(count_image)\n",
    "\n",
    "        plt.subplot(4, 4, 4*i + 4)\n",
    "        plt.imshow(outputs[i].squeeze().detach().cpu())\n",
    "\n",
    "    # Add an overall color bar\n",
    "    plt.subplots_adjust(bottom=0.2, hspace=0.4)  # Increase the vertical spacing\n",
    "    cbar_ax = plt.gcf().add_axes([0.15, 0.1, 0.7, 0.03])  # Define the position and size of the color bar\n",
    "    cbar = plt.colorbar(cax=cbar_ax, orientation='horizontal')\n",
    "\n",
    "    # Add titles in the middle of the entire row\n",
    "    plt.subplot(4, 4, 1).set_title(\"images\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 2).set_title(\"Label all map\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 3).set_title(\"Label pins\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 4).set_title(\"Predicted\", position=(0.5, 1.05))\n",
    "\n",
    "    # Define the output folder based on the dataset\n",
    "    output_folder = f\"results/{dataset}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "    # Define the image filename based on parameters\n",
    "    image_filename = f\"NPP{NPP}_LR={learning_rate}_n={n}_mesh={mesh}_d={d}_n_pins={n_pins}_fixedpins={fixed_pins}_r={r}.png\"\n",
    "\n",
    "    # Save the figure as a high-resolution PNG in the specified folder\n",
    "    plt.savefig(os.path.join(output_folder, image_filename), dpi=100)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6564e-cd65-4496-ba82-4784f2cdc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataloader, autoencoder):\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch['image'][:, :input_channel, :, :].to(device)\n",
    "            p = [tensor.to(device) for tensor in batch['pins']]\n",
    "            y = [tensor.to(device) for tensor in batch['outputs']]\n",
    "\n",
    "            outputs = autoencoder(x.float())\n",
    "            break\n",
    "    plot_results(x, p, y, outputs, r=r)\n",
    "    \n",
    "\n",
    "# visualize_samples(test_dataloader, autoencoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycox",
   "language": "python",
   "name": "pycox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
