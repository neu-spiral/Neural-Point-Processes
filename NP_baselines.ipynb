{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3836b3f8-f993-415f-b442-f772829e47e6",
   "metadata": {},
   "source": [
    "Neural Point Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca94db99-f1a0-448f-91d0-d6b98ff5bd87",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from functools import lru_cache\n",
    "from tools.plot_utils import visualize_pins, plot_label_pin, plot_all, plot_and_save, plot_loss\n",
    "from tools.data_utils import *\n",
    "from tools.losses import NPPLoss\n",
    "from tools.models import Autoencoder\n",
    "from tools.optimization import EarlyStoppingCallback, train_model, evaluate_model\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_lr_finder import LRFinder\n",
    "import time\n",
    "from tools.models import *\n",
    "from tools.NPmodels import NeuralProcessImg\n",
    "from tools.NPtrain import NeuralProcessTrainer\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa53412-0c89-4617-9b7e-efffa9b63834",
   "metadata": {},
   "source": [
    "# Dataset and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000f94a1-69f9-488f-840c-0a0079b1bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for PyTorch\n",
    "seed = 4  # You can use any integer value as the seed\n",
    "torch.manual_seed(seed)\n",
    "# Set a random seed for NumPy (if you're using NumPy operations)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770be29d-6a82-4394-96c9-8c37bae5e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"PinMNIST\"\n",
    "feature_extracted = False\n",
    "n = 500\n",
    "mesh = False\n",
    "d = 10\n",
    "n_pins = 100\n",
    "fixed_pins = True\n",
    "r = 3\n",
    "d1,d2 = 28,28\n",
    "\n",
    "partial_label_GP=False\n",
    "partial_percent=0.5\n",
    "\n",
    "if feature_extracted:\n",
    "    folder = f\"{dataset}_ddpm\"\n",
    "else:\n",
    "    folder = f\"{dataset}\"\n",
    "\n",
    "if dataset == \"PinMNIST\":\n",
    "    if mesh:\n",
    "        data_folder = f\"./data/{folder}/{n}images_mesh_{d}step_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "    else:\n",
    "        data_folder = f\"./data/{folder}/{n}images_random_fixed{fixed_pins}_{n_pins}pins_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "\n",
    "if dataset == \"Synthetic\":\n",
    "    if mesh:\n",
    "        data_folder = f\"./data/{folder}/{n}images_{d1}by{d2}pixels_{d}_distanced_grid_pins_{seed}seed/\"\n",
    "    else:\n",
    "        data_folder = f\"./data/{folder}/{n}images_{d1}by{d2}pixels_upto{n_pins}pins_{seed}seed/\"\n",
    "        \n",
    "    \n",
    "    \n",
    "# data_folder = f\"./data/MNIST_{n}images_mesh_{d}step_{28}by{28}pixels_{r}radius_{seed}seed\"\n",
    "# data_folder = \"./data/Synthetic_100images_32by32pixels_upto500pins_4seed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac50a0b-10c2-49d1-a2fc-ed7826a04c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform pipeline that includes the resizing step\n",
    "# if dataset == \"PinMNIST\":\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),         # Convert to tensor (as you were doing)\n",
    "    Resize()  # Resize to 100x100\n",
    "])\n",
    "\n",
    "transformed_dataset = PinDataset(csv_file=f\"{data_folder}/pins.csv\",\n",
    "                                      root_dir=f\"{data_folder}/images/\",\n",
    "                                      transform=transform)\n",
    "\n",
    "dataset_size = len(transformed_dataset)\n",
    "train_size = int(0.6 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    transformed_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images = [sample['image'] for sample in batch]\n",
    "    pins = [sample['pins'] for sample in batch]\n",
    "    outputs = [sample['outputs'] for sample in batch]\n",
    "\n",
    "    return {\n",
    "        'image': torch.stack(images, dim=0),\n",
    "        'pins': pins,\n",
    "        'outputs': outputs}\n",
    "\n",
    "# Create your DataLoader with the custom_collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371fb7d3-e158-435e-94fa-0118817950ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    images = batch['image'].to(device) # get RGB instead of RGBA\n",
    "    pins = batch['pins']\n",
    "    outputs = batch['outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "337773a2-5f25-4c4a-981a-3ff9439c60ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 4.3333335 ],\n",
       "        [19.529411  ],\n",
       "        [ 7.858824  ],\n",
       "        [ 3.5215688 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [25.078432  ],\n",
       "        [12.011765  ],\n",
       "        [ 1.2       ],\n",
       "        [ 4.019608  ],\n",
       "        [ 0.        ],\n",
       "        [ 3.627451  ],\n",
       "        [20.270588  ],\n",
       "        [13.552941  ],\n",
       "        [22.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [12.705882  ],\n",
       "        [ 5.929412  ],\n",
       "        [26.243137  ],\n",
       "        [ 2.309804  ],\n",
       "        [14.533334  ],\n",
       "        [ 7.0784316 ],\n",
       "        [ 0.19215687],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [21.105883  ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [11.568627  ],\n",
       "        [21.082354  ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.05098039],\n",
       "        [16.462746  ],\n",
       "        [ 1.0470588 ],\n",
       "        [ 3.619608  ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [23.556864  ],\n",
       "        [ 0.        ],\n",
       "        [ 9.74902   ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 5.133333  ],\n",
       "        [11.388235  ],\n",
       "        [ 0.        ],\n",
       "        [17.643137  ],\n",
       "        [19.184315  ],\n",
       "        [ 9.466667  ],\n",
       "        [20.478432  ],\n",
       "        [ 8.964706  ],\n",
       "        [ 0.        ],\n",
       "        [20.32157   ],\n",
       "        [15.945098  ],\n",
       "        [ 1.6509805 ],\n",
       "        [22.07059   ],\n",
       "        [ 0.        ],\n",
       "        [11.835294  ],\n",
       "        [ 0.        ],\n",
       "        [ 2.572549  ],\n",
       "        [ 3.7568629 ],\n",
       "        [ 0.8745098 ],\n",
       "        [ 0.        ],\n",
       "        [ 5.388235  ],\n",
       "        [ 0.        ],\n",
       "        [16.568628  ],\n",
       "        [ 1.3215687 ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [27.478432  ],\n",
       "        [17.866667  ],\n",
       "        [20.121569  ],\n",
       "        [19.219608  ],\n",
       "        [11.360785  ],\n",
       "        [ 0.        ],\n",
       "        [21.952942  ],\n",
       "        [16.290195  ],\n",
       "        [ 4.443137  ],\n",
       "        [ 0.        ],\n",
       "        [ 4.247059  ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 9.094118  ],\n",
       "        [12.705882  ],\n",
       "        [ 2.709804  ],\n",
       "        [11.992157  ],\n",
       "        [ 7.8313727 ],\n",
       "        [ 0.        ],\n",
       "        [ 9.152942  ],\n",
       "        [ 7.666667  ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [15.690196  ]], dtype=float32),\n",
       " tensor([ 0.0000,  0.0000,  4.3333, 19.5294,  7.8588,  3.5216,  0.0000,  0.0000,\n",
       "         25.0784, 12.0118,  1.2000,  4.0196,  0.0000,  3.6275, 20.2706, 13.5529,\n",
       "         22.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.7059,  5.9294, 26.2431,\n",
       "          2.3098, 14.5333,  7.0784,  0.1922,  0.0000,  0.0000,  0.0000, 21.1059,\n",
       "          0.0000,  0.0000, 11.5686, 21.0824,  0.0000,  0.0000,  0.0510, 16.4627,\n",
       "          1.0471,  3.6196,  0.0000,  0.0000, 23.5569,  0.0000,  9.7490,  0.0000,\n",
       "          0.0000,  5.1333, 11.3882,  0.0000, 17.6431, 19.1843,  9.4667, 20.4784,\n",
       "          8.9647,  0.0000, 20.3216, 15.9451,  1.6510, 22.0706,  0.0000, 11.8353,\n",
       "          0.0000,  2.5725,  3.7569,  0.8745,  0.0000,  5.3882,  0.0000, 16.5686,\n",
       "          1.3216,  0.0000,  0.0000,  0.0000, 27.4784, 17.8667, 20.1216, 19.2196,\n",
       "         11.3608,  0.0000, 21.9529, 16.2902,  4.4431,  0.0000,  4.2471,  0.0000,\n",
       "          0.0000,  9.0941, 12.7059,  2.7098, 11.9922,  7.8314,  0.0000,  9.1529,\n",
       "          7.6667,  0.0000,  0.0000, 15.6902]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(pins)\n",
    "\n",
    "# np_pins = np.dstack(pins).transpose((2, 0, 1))\n",
    "np_outputs = np.dstack(outputs).transpose((2, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce377de-650d-4e4c-9520-437fc8752263",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Display the figure\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/IPython/core/formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    175\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/IPython/core/formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/backend_bases.py:2346\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2346\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2348\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pad_inches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2349\u001b[0m             pad_inches \u001b[38;5;241m=\u001b[39m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.pad_inches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/figure.py:1785\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# some axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m# need this conditional....\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1785\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1787\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1788\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/axes/_base.py:4385\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[1;32m   4383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   4384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;129;01mand\u001b[39;00m axis\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[0;32m-> 4385\u001b[0m         ba \u001b[38;5;241m=\u001b[39m \u001b[43mmartist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tightbbox_for_layout_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ba:\n\u001b[1;32m   4387\u001b[0m             bb\u001b[38;5;241m.\u001b[39mappend(ba)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/artist.py:1415\u001b[0m, in \u001b[0;36m_get_tightbbox_for_layout_only\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;124;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;124;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;124;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfor_layout_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/axis.py:1328\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[0;32m-> 1328\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_offset_text_position(tlb1, tlb2)\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mset_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mget_offset())\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/axis.py:1306\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1305\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m-> 1306\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1307\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/axis.py:1306\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1305\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m-> 1306\u001b[0m         [\u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/text.py:959\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m--> 959\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[1;32m    961\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[0;32m~/anaconda3/envs/pycox/lib/python3.8/site-packages/matplotlib/text.py:477\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    475\u001b[0m     offsety \u001b[38;5;241m=\u001b[39m ymin \u001b[38;5;241m+\u001b[39m descent\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m valign \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_baseline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 477\u001b[0m     offsety \u001b[38;5;241m=\u001b[39m \u001b[43mymin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     offsety \u001b[38;5;241m=\u001b[39m ymin\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_img = images[0][0].squeeze().detach().cpu()/255\n",
    "count_image = plot_label_pin(sample_img, pins[0], outputs[0])\n",
    "count_all_image = plot_all(sample_img, r=3)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot the sample_img in the first subplot\n",
    "im0 = axes[0].imshow(sample_img)\n",
    "axes[0].set_title('Sample Image')\n",
    "fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Plot the count_image in the second subplot\n",
    "im1 = axes[1].imshow(count_image)\n",
    "axes[1].set_title('Count Image')\n",
    "fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Plot the count_all_image in the third subplot\n",
    "im2 = axes[2].imshow(count_all_image)\n",
    "axes[2].set_title('Count All Image')\n",
    "fig.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)  # Add colorbar\n",
    "\n",
    "# Add spacing between subplots\n",
    "plt.tight_layout()\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c306e1-061a-47bc-8584-46ad8e08ee8b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39fe1f-e261-4bc3-b8b4-75fc9ca989a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLRFinder:\n",
    "    def __init__(self, model, criterion, optimizer, device='cuda'):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.history = {'lr': [], 'loss': []}\n",
    "\n",
    "    def find_lr(self, train_loader, start_lr=1e-4, end_lr=1, num_iter=20,smooth_f=0.05):\n",
    "        model = self.model.to(self.device)\n",
    "        criterion = self.criterion\n",
    "        optimizer = self.optimizer\n",
    "        device = self.device\n",
    "        model.train()\n",
    "\n",
    "        lr_step = (end_lr / start_lr) ** (1 / num_iter)\n",
    "        lr = start_lr\n",
    "\n",
    "        for iteration in range(num_iter):\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "\n",
    "            total_loss = 0.0\n",
    "            for batch in train_loader:\n",
    "                x_train = batch['image'][:, :input_channel, :, :].to(device)\n",
    "                p_train = [tensor.to(device) for tensor in batch['pins']]\n",
    "                y_train = [tensor.to(device) for tensor in batch['outputs']]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_train.float())\n",
    "                loss = criterion(y_train, outputs, p_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            self.history['lr'].append(lr)\n",
    "            self.history['loss'].append(avg_loss)\n",
    "\n",
    "            lr *= lr_step\n",
    "            \n",
    "    def plot_lr_finder(self):\n",
    "        plt.plot(self.history['lr'], self.history['loss'])\n",
    "        plt.xscale('log')  # Use a logarithmic scale for better visualization\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Finder Curve')\n",
    "        plt.show()\n",
    "        \n",
    "    def find_best_lr(self, skip_start=3, skip_end=3):\n",
    "        # Find the index of the minimum loss in the specified range\n",
    "        min_loss_index = skip_start + np.argmin(self.history['loss'][skip_start:-skip_end])\n",
    "\n",
    "        # Output the learning rate corresponding to the minimum loss\n",
    "        best_lr = self.history['lr'][min_loss_index]\n",
    "        return best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a8eba-47fc-4225-a7e9-7442ae7aca97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Case 1: identity=True\n",
    "# Set your hyperparameters\n",
    "input_channel = 1 if dataset == \"PinMNIST\" else 3\n",
    "num_epochs = 20\n",
    "sigmas = [0.1, 0.2, 0.5, 1, 2, 5]  # Set the sigma values you want to test\n",
    "num_kernels_encoder = [32, 16]\n",
    "num_kernels_decoder = [32]\n",
    "learning_rate = 0.01\n",
    "val_every_epoch = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "criterion_MSE = NPPLoss(identity=True).to(device)\n",
    "lr_finder_MSE = CustomLRFinder(model, criterion_MSE, optimizer, device=device)\n",
    "lr_finder_MSE.find_lr(train_loader, start_lr=1e-5, end_lr=1, num_iter=20)\n",
    "best_lr_MSE = lr_finder_MSE.find_best_lr()\n",
    "print(f\"Best Learning Rate for MSE: {best_lr_MSE}\")\n",
    "\n",
    "\n",
    "# Cases 2-6: identity=False, varying sigmas\n",
    "best_lrs = [(0,best_lr_MSE)]\n",
    "\n",
    "sigmas = [0.1, 0.2, 0.5, 1, 2]\n",
    "\n",
    "for sigma in sigmas:\n",
    "    criterion_NPP = NPPLoss(identity=False, sigma=sigma).to(device)\n",
    "    lr_finder_NPP = CustomLRFinder(model, criterion_NPP, optimizer, device=device)\n",
    "    lr_finder_NPP.find_lr(train_loader, start_lr=1e-4, end_lr=1, num_iter=10)\n",
    "    best_lr_NPP = lr_finder_NPP.find_best_lr()\n",
    "    best_lrs.append((sigma, best_lr_NPP))\n",
    "    print(f\"Best Learning Rate for NPP sigma={sigma}: {best_lr_NPP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9111c-3a3f-498b-9574-56626971725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_ci(sigmas, num_kernels_encoder, num_kernels_decoder, train_loader, val_loader, \n",
    "                    test_loader, input_channel, num_epochs, val_every_epoch, learning_rates, device, num_runs=3):\n",
    "    test_losses_npp_true = []\n",
    "    GP_test_losses_npp_true = []\n",
    "    test_losses_npp_false= []\n",
    "    experiment_id = int(time.time())\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        count = 0\n",
    "        test_losses_vs_sigma_npp_true = []\n",
    "        GP_test_losses_vs_sigma_npp_true = []\n",
    "        test_loss_npp_false = None\n",
    "\n",
    "        # Run NPP=False once and collect the test loss\n",
    "        early_stopping = EarlyStoppingCallback(patience=10, min_delta=0.001)\n",
    "        criterion = NPPLoss(identity=True).to(device)\n",
    "\n",
    "        autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rates[count])\n",
    "        model, train_losses, val_losses = train_model(autoencoder, train_loader, val_loader, input_channel, num_epochs,\\\n",
    "                                                      val_every_epoch, learning_rates[count], criterion, optimizer, device, early_stopping, experiment_id)\n",
    "\n",
    "        test_loss_npp_false = evaluate_model(autoencoder, test_loader, input_channel, device, partial_label_GP=False, partial_percent=partial_percent)\n",
    "        print(f\"MSE Test loss:{test_loss_npp_false:.3f}\")\n",
    "        test_losses_npp_false.append(test_loss_npp_false)\n",
    "        \n",
    "        count += 1\n",
    "        # Run LR Finder for different sigma values\n",
    "        for sigma in sigmas:\n",
    "            early_stopping = EarlyStoppingCallback(patience=5, min_delta=0.001)\n",
    "            criterion = NPPLoss(identity=False, sigma=sigma).to(device)\n",
    "            autoencoder = Autoencoder(num_kernels_encoder, num_kernels_decoder, input_channel=input_channel).to(device)\n",
    "            optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rates[count])\n",
    "            model, train_losses, val_losses = train_model(autoencoder, train_loader, val_loader, input_channel, num_epochs,\\\n",
    "                                                          val_every_epoch, learning_rates[count], criterion, optimizer, device, early_stopping, experiment_id)\n",
    "            test_loss = evaluate_model(autoencoder, test_loader, input_channel, device, partial_label_GP=False, partial_percent=partial_percent, sigma=sigma)\n",
    "            GP_test_loss = evaluate_model(autoencoder, test_loader, input_channel, device, partial_label_GP=True, partial_percent=partial_percent, sigma=sigma)\n",
    "            print(f\"NPP sigma={sigma} Test loss:{test_loss:.3f}, GP Test loss:{GP_test_loss:.3f}\")\n",
    "            test_losses_vs_sigma_npp_true.append(test_loss)\n",
    "            GP_test_losses_vs_sigma_npp_true.append(GP_test_loss)\n",
    "            count += 1\n",
    "\n",
    "        test_losses_npp_true.append(test_losses_vs_sigma_npp_true)\n",
    "        GP_test_losses_npp_true.append(GP_test_losses_vs_sigma_npp_true)\n",
    "    return GP_test_losses_npp_true, test_losses_npp_true, test_losses_npp_false\n",
    "\n",
    "    \n",
    "# Function to run the pipeline and save data\n",
    "def run_and_save_pipeline(sigmas, num_kernels_encoder, num_kernels_decoder, train_loader, val_loader, test_loader, input_channel, num_epochs, val_every_epoch, learning_rates, device, num_runs):\n",
    "    # Run the pipeline\n",
    "    GP_test_loss_npp_true, test_loss_npp_true, test_loss_npp_false= run_pipeline_ci(sigmas, num_kernels_encoder, num_kernels_decoder, train_loader, val_loader, test_loader, input_channel, num_epochs, val_every_epoch, learning_rates, device,num_runs)\n",
    "    print(\"start saving!\")\n",
    "    # Save the data\n",
    "    save_loss(test_loss_npp_true, './history/test_loss_npp_true.npy')\n",
    "    save_loss(GP_test_loss_npp_true, './history/GP_test_loss_npp_true.npy')\n",
    "    save_loss(test_loss_npp_false, './history/test_loss_npp_false.npy')\n",
    "    print(\"saved\")\n",
    "    return GP_test_loss_npp_true, test_loss_npp_true, test_loss_npp_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c681ad7-b14c-4d02-ad7f-da35693469d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a unique experiment_id using a timestamp\n",
    "  # Using timestamp as experiment_id\n",
    "\n",
    "# Set your hyperparameters\n",
    "# dataset = \"MNIST\"\n",
    "input_channel = 1 if dataset == \"PinMNIST\" else 3\n",
    "num_epochs = 200\n",
    "sigmas = [0.1, 0.2, 0.5, 1, 2]  # Set the sigma values you want to test\n",
    "# best_lrs = [0.05, 0.05, 0.05, 0.05, 0.05, 0.001] #MNIST\n",
    "best_lrs = [0.1, 0.001, 0.001, 0.001, 0.001, 0.001] #Synthetic\n",
    "num_kernels_encoder = [32, 16]\n",
    "num_kernels_decoder = [32]\n",
    "# learning_rate = 0.01\n",
    "val_every_epoch = 5\n",
    "num_runs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run and save the pipeline data\n",
    "loss_vs_sigma_data = run_and_save_pipeline(sigmas, num_kernels_encoder, num_kernels_decoder, train_loader, val_loader, test_loader,\\\n",
    "                                           input_channel, num_epochs, val_every_epoch, best_lrs, device, num_runs=num_runs)\n",
    "\n",
    "\n",
    "# Plot and save the plot using the saved data\n",
    "plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b7484-3290-43cb-a85e-39cca0f9e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vs_sigma_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b04d7-2308-48e9-9a75-d8071dd3d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss_npp_false = [test_loss_npp_false for i in range((len(sigmas)))]\n",
    "# test_loss_npp_true.pop(1)\n",
    "test_loss_npp_true, test_loss_npp_false = load_data('./history/test_loss_npp_true.npy'), load_data('./history/test_loss_npp_false.npy')\n",
    "test_loss_npp_true, test_loss_npp_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8bf364-d010-40de-ad6c-ce837b5dee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate, dataset, model_name=\"Auto encoder\"):\n",
    "    # Unpack the data\n",
    "    test_loss_npp_true, test_loss_npp_false = loss_vs_sigma_data\n",
    "    test_loss_npp_false = [test_loss_npp_false for i in range(len(sigmas))]\n",
    "\n",
    "    # Calculate mean and confidence intervals for NPP=True runs\n",
    "    mean_test_loss_npp_true = np.mean(test_loss_npp_true, axis=0)\n",
    "    ci_test_loss_npp_true = 1.96 * np.std(test_loss_npp_true, axis=0) / np.sqrt(len(test_loss_npp_true))\n",
    "\n",
    "    # Duplicate NPP=False values for plotting\n",
    "    mean_test_loss_npp_false = np.mean(test_loss_npp_false, axis=1)\n",
    "    ci_test_loss_npp_false = 1.96 * np.std(test_loss_npp_false, axis=1) / np.sqrt(len(test_loss_npp_false))\n",
    "\n",
    "    # Plot mean and confidence intervals for NPP=True\n",
    "    plt.plot(sigmas, mean_test_loss_npp_true, marker='o', label='NPP=True', color='blue')\n",
    "\n",
    "    # Plot mean and confidence intervals for duplicated NPP=False\n",
    "    plt.plot(sigmas, mean_test_loss_npp_false, color='red', linestyle='--', label='NPP=False')\n",
    "\n",
    "    # Fill between for NPP=True with blue color\n",
    "    plt.fill_between(sigmas, mean_test_loss_npp_true - ci_test_loss_npp_true, mean_test_loss_npp_true + ci_test_loss_npp_true, color='blue', alpha=0.2)\n",
    "\n",
    "    # Fill between for NPP=False with red color\n",
    "    plt.fill_between(sigmas, mean_test_loss_npp_false - ci_test_loss_npp_false, mean_test_loss_npp_false + ci_test_loss_npp_false, color='red', alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Sigma')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.title(f'Test Loss vs. Sigma:{dataset} dataset with {model_name}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create a directory to save the results if it doesn't exist\n",
    "    results_dir = './results'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Generate a filename based on parameters in the title\n",
    "    filename = f\"test_loss_vs_sigma_{dataset}_{model_name}_lr_{learning_rate}.png\"\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(filepath)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate)\n",
    "\n",
    "# Plot and save the plot using the saved data\n",
    "plot_and_save(loss_vs_sigma_data, sigmas, dataset, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a5d16-5dbd-4a42-917e-72b80b9fd9b2",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e275dea-f73a-4c94-a6dd-f2b5def8f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(x, p, y, outputs, r):\n",
    "    plt.figure(figsize=(14, 14))  # Adjust the figure size\n",
    "    n_shows = 4\n",
    "\n",
    "    for i in range(n_shows):\n",
    "        # Original Images\n",
    "        img = x[i].squeeze().detach().cpu() / 255\n",
    "\n",
    "        plt.subplot(4, 4, 4*i+1 )\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.subplot(4, 4, 4*i + 2)  # Transposed the rows and columns\n",
    "        count_all_image = plot_all(img, r=r)\n",
    "        plt.imshow(count_all_image)\n",
    "\n",
    "        # Reconstructed Images (switched with row 3)\n",
    "        plt.subplot(4, 4, 4*i + 3)  # Transposed the rows and columns\n",
    "        count_image = plot_label_pin(img, p[i], y[i])\n",
    "        plt.imshow(count_image)\n",
    "\n",
    "        plt.subplot(4, 4, 4*i + 4)\n",
    "        plt.imshow(outputs[i].squeeze().detach().cpu())\n",
    "\n",
    "    # Add an overall color bar\n",
    "    plt.subplots_adjust(bottom=0.2, hspace=0.4)  # Increase the vertical spacing\n",
    "    cbar_ax = plt.gcf().add_axes([0.15, 0.1, 0.7, 0.03])  # Define the position and size of the color bar\n",
    "    cbar = plt.colorbar(cax=cbar_ax, orientation='horizontal')\n",
    "\n",
    "    # Add titles in the middle of the entire row\n",
    "    plt.subplot(4, 4, 1).set_title(\"images\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 2).set_title(\"Label all map\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 3).set_title(\"Label pins\", position=(0.5, 1.05))\n",
    "    plt.subplot(4, 4, 4).set_title(\"Predicted\", position=(0.5, 1.05))\n",
    "\n",
    "    # Define the output folder based on the dataset\n",
    "    output_folder = f\"results/{dataset}\"\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "    # Define the image filename based on parameters\n",
    "    image_filename = f\"NPP{NPP}_LR={learning_rate}_n={n}_mesh={mesh}_d={d}_n_pins={n_pins}_fixedpins={fixed_pins}_r={r}.png\"\n",
    "\n",
    "    # Save the figure as a high-resolution PNG in the specified folder\n",
    "    plt.savefig(os.path.join(output_folder, image_filename), dpi=100)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6564e-cd65-4496-ba82-4784f2cdc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataloader, autoencoder):\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x = batch['image'][:, :input_channel, :, :].to(device)\n",
    "            p = [tensor.to(device) for tensor in batch['pins']]\n",
    "            y = [tensor.to(device) for tensor in batch['outputs']]\n",
    "\n",
    "            outputs = autoencoder(x.float())\n",
    "            break\n",
    "    plot_results(x, p, y, outputs, r=r)\n",
    "    \n",
    "\n",
    "visualize_samples(test_loader, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9cf4ef-34ad-473e-9e19-ba16e5307025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycox",
   "language": "python",
   "name": "pycox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
